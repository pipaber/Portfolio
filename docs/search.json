[
  {
    "objectID": "posts/python test/test.html",
    "href": "posts/python test/test.html",
    "title": "test",
    "section": "",
    "text": "Code\nprint(5)\n\n\n5"
  },
  {
    "objectID": "bioinformatics.html",
    "href": "bioinformatics.html",
    "title": "Bioinformatics Projects",
    "section": "",
    "text": "The analysis of RNA-Seq data involves two distinct parts. The first one needs the use of servers or HPC (high performance computers) and has to do with quality control. pre-processing, alignment-mapping (usually with the STAR software) and counting (can be done using RSEM software). The second one is called downstream analysis and this part involves differential gene expression, gene sets analysis, etc. To see how to do the downstream analysis click here\n\n\n\n\n\n\nNetwork analysis of genes and ontologies\n\n\n\n\n\n\n\n\n\n\nMethylated DNA between Cancer and Normal\n\n\n\n\n\nEpigenetics is the study of how your behaviors and environment can cause changes that affect the way your genes work. Unlike genetic changes, epigenetic changes are reversible and do not change your DNA sequence, but they can change how your body reads a DNA sequence (CDC,2024). To learn how to analyze 450k Illumina Arrays and Whole Genome Bisulfite Sequencing data click here\n\n\n\n\n\nIn recent years the integration of Omics data has become important to understand the biological procesess more broadly. To learn how to use the GWAS Catalog with ChIP-Seq data or how to retrieve and analyze data from The Cancer Genome Atlas (TCGA) click here\n\n\n\n\n\n\nNumber of predited mutation effect per gene\n\n\n\n\n\n\n\n\n\n\nKEGG\n\n\n\n\n\nAn example of a proper use of interactive plots on a RNA-Seq data report can be founded here.\n\nThis repository doesn’t have any code, is only to showcase what is possible using Quarto and Bioconductor\n\n\n\n\n\n\nNetwork analysis of genes and ontologies\nMethylated DNA between Cancer and Normal\nNumber of predited mutation effect per gene\nKEGG"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Piero Palacios",
    "section": "",
    "text": "Hi! My name is Piero, and I’m a Biologist (with main formation in biotechnology) from Peru. I have specializations in data analysis and bioinformatics from Harvard University and MIT. Also, I love writing reproducible interactive reports using Quarto as a hobby.\nWithin my bioinformatic experience you can find RNA-Seq, Methyl-Seq, WGBS-Seq, Illumina Methylation Array and Multi-omics analyses. Also, I have experience on machine learning (OLS, ridge and lasso regression, SVM, Kernels, collaborative filtering, network analysis, high-dimensional reduction, etc) and deep learning models (Feed forward NN, Recurrent NN, Convolutional NN, Graph NN, Transformers, etc)."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Data Science Projects",
    "section": "",
    "text": "Regression and Gradient Descent\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUntitled\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Regression_and_Gradient_Descent/regression_and_gradient_descent.html",
    "href": "posts/Regression_and_Gradient_Descent/regression_and_gradient_descent.html",
    "title": "Regression and Gradient Descent",
    "section": "",
    "text": "Code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy as sc\nimport seaborn as sns\n\n\nThe file gamma-ray.csv contains a small quantity of data collected from the Compton Gamma Ray Observatory, a satellite launched by NASA in 1991 (http://cossc.gsfc.nasa.gov/). For each of 100 sequential time intervals of variable lengths (given in seconds), the number of gamma rays originating in a particular area of the sky was recorded.\nFor this analysis, we would like to check the assumption that the emission rate is constant.\nFirst, let’s check the distribution of the number of gamma rays\n\n\nCode\ndf = pd.read_csv(\"gamma-ray.csv\", sep=\",\")\n\nsns.set_theme(style=\"darkgrid\")\nsns.displot(df,x=\"count\")\n\n\n\n\n\n\n\n\n\nThe number of these gamma rays is discrete and non-negative. We can assume that the gamma rays emerge independently of one another, and at constant rate in each time interval. Based on this assumption, a Poisson model is a good model assumption. Each observation \\(G_i\\) follows a poisson distribution with rate \\(\\lambda_i\\) times the time interval \\(t_i\\).\n\\[G_i \\thicksim Poisson(\\lambda_i * t_i)\\]\nTHe hypothesis that we wanna test is that the emission rate is constat so:\n\\(H_0: \\lambda_0 = \\lambda_1 = ... = \\lambda_{99}\\)\nAnd the alternative hypothesis is that the emisison rates are different:\n\\(H_A: \\lambda_i \\neq \\lambda_j\\) for some i and j\nThe most plausible parameter for \\(\\lambda\\) under the null hypothesis is the maximun likelihood estimator (MLE).\nGiven the poisson distribution, the derivation goes as follows:\n\\[f(G_0,G_1,...,G_{99} | \\lambda) = \\prod_{i=0}^{99} \\frac{e^{-\\lambda*t_i}*(\\lambda*t_i)^{G_i}}{G_i!}\\]\n\\[ln(f) = -\\lambda \\sum_{i=0}^{99} t_i + ln(\\lambda) \\sum_{i=0}^{99} G_i + ln(\\prod_{i=0}^{99} t_i^{G_i})) - ln(\\prod_{i=0}^{99} G_i!)\\]\nThen, we derivate w.r.t parameter \\(\\lambda\\) and set the derivative to 0 to find the optimal \\(\\lambda\\).\n\\[0 = -\\sum_{i=0}^{99}t_i + \\sum_{i=0}^{99} \\frac{G_i}{\\lambda}\\]\n\\[\\hat{\\lambda} = \\frac{\\sum_{i=0}^{99} G_i}{\\sum_{i=0}^{99} t_i}\\]\n\n\nCode\nlambda_null = df[\"count\"].sum() / df[\"seconds\"].sum()\n\nlambda_null\n\n\n0.0038808514969907496\n\n\nSimilarly, we can calculate a plausible value for the alternative hypothesis with MLE.\n\\[ln(f) = -\\sum_{i=0}^{99} \\lambda_i*t_i + \\sum_{i=0}^{99} G_i*ln(\\lambda_i) + ln(\\prod_{i=0}^{99} G_i*ln(t_i)) - ln(\\prod_{i=0}^{99} G_i!)\\]\nWE take the partial derivative w.r.t each parameter \\(\\lambda_i\\) to find the optimal \\(\\lambda_i\\)\n\\[0 = -t_i + \\frac{G_i}{\\lambda_i}\\]\n\\[\\hat{\\lambda_i} = \\frac{G_i}{t_i}\\]\n\n\nCode\nlambdas_alt = df[\"count\"]/df[\"seconds\"]\n\nlambdas_alt\n\n\n0     0.000000\n1     0.000000\n2     0.000000\n3     0.000000\n4     0.009804\n        ...   \n95    0.025840\n96    0.000000\n97    0.000000\n98    0.000000\n99    0.000000\nLength: 100, dtype: float64"
  },
  {
    "objectID": "posts/Regression_and_Gradient_Descent/regression_and_gradient_descent.html#regression",
    "href": "posts/Regression_and_Gradient_Descent/regression_and_gradient_descent.html#regression",
    "title": "Regression and Gradient Descent",
    "section": "",
    "text": "Code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy as sc\nimport seaborn as sns\n\n\nThe file gamma-ray.csv contains a small quantity of data collected from the Compton Gamma Ray Observatory, a satellite launched by NASA in 1991 (http://cossc.gsfc.nasa.gov/). For each of 100 sequential time intervals of variable lengths (given in seconds), the number of gamma rays originating in a particular area of the sky was recorded.\nFor this analysis, we would like to check the assumption that the emission rate is constant.\nFirst, let’s check the distribution of the number of gamma rays\n\n\nCode\ndf = pd.read_csv(\"gamma-ray.csv\", sep=\",\")\n\nsns.set_theme(style=\"darkgrid\")\nsns.displot(df,x=\"count\")\n\n\n\n\n\n\n\n\n\nThe number of these gamma rays is discrete and non-negative. We can assume that the gamma rays emerge independently of one another, and at constant rate in each time interval. Based on this assumption, a Poisson model is a good model assumption. Each observation \\(G_i\\) follows a poisson distribution with rate \\(\\lambda_i\\) times the time interval \\(t_i\\).\n\\[G_i \\thicksim Poisson(\\lambda_i * t_i)\\]\nTHe hypothesis that we wanna test is that the emission rate is constat so:\n\\(H_0: \\lambda_0 = \\lambda_1 = ... = \\lambda_{99}\\)\nAnd the alternative hypothesis is that the emisison rates are different:\n\\(H_A: \\lambda_i \\neq \\lambda_j\\) for some i and j\nThe most plausible parameter for \\(\\lambda\\) under the null hypothesis is the maximun likelihood estimator (MLE).\nGiven the poisson distribution, the derivation goes as follows:\n\\[f(G_0,G_1,...,G_{99} | \\lambda) = \\prod_{i=0}^{99} \\frac{e^{-\\lambda*t_i}*(\\lambda*t_i)^{G_i}}{G_i!}\\]\n\\[ln(f) = -\\lambda \\sum_{i=0}^{99} t_i + ln(\\lambda) \\sum_{i=0}^{99} G_i + ln(\\prod_{i=0}^{99} t_i^{G_i})) - ln(\\prod_{i=0}^{99} G_i!)\\]\nThen, we derivate w.r.t parameter \\(\\lambda\\) and set the derivative to 0 to find the optimal \\(\\lambda\\).\n\\[0 = -\\sum_{i=0}^{99}t_i + \\sum_{i=0}^{99} \\frac{G_i}{\\lambda}\\]\n\\[\\hat{\\lambda} = \\frac{\\sum_{i=0}^{99} G_i}{\\sum_{i=0}^{99} t_i}\\]\n\n\nCode\nlambda_null = df[\"count\"].sum() / df[\"seconds\"].sum()\n\nlambda_null\n\n\n0.0038808514969907496\n\n\nSimilarly, we can calculate a plausible value for the alternative hypothesis with MLE.\n\\[ln(f) = -\\sum_{i=0}^{99} \\lambda_i*t_i + \\sum_{i=0}^{99} G_i*ln(\\lambda_i) + ln(\\prod_{i=0}^{99} G_i*ln(t_i)) - ln(\\prod_{i=0}^{99} G_i!)\\]\nWE take the partial derivative w.r.t each parameter \\(\\lambda_i\\) to find the optimal \\(\\lambda_i\\)\n\\[0 = -t_i + \\frac{G_i}{\\lambda_i}\\]\n\\[\\hat{\\lambda_i} = \\frac{G_i}{t_i}\\]\n\n\nCode\nlambdas_alt = df[\"count\"]/df[\"seconds\"]\n\nlambdas_alt\n\n\n0     0.000000\n1     0.000000\n2     0.000000\n3     0.000000\n4     0.009804\n        ...   \n95    0.025840\n96    0.000000\n97    0.000000\n98    0.000000\n99    0.000000\nLength: 100, dtype: float64"
  },
  {
    "objectID": "posts/test/aa.html",
    "href": "posts/test/aa.html",
    "title": "Untitled",
    "section": "",
    "text": "Code\nplot(iris)"
  }
]