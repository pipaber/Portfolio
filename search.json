[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Piero Palacios",
    "section": "",
    "text": "Hi! My name is Piero, and I’m a Biologist (with main formation in biotechnology) from Peru. I have specializations in data analysis and bioinformatics from Harvard University and MIT. Also, I love writing reproducible interactive reports using Quarto as a hobby.\nWithin my bioinformatic experience you can find RNA-Seq, Methyl-Seq, WGBS-Seq, Illumina Methylation Array and Multi-omics analyses. Also, I have experience on machine learning (OLS, ridge and lasso regression, SVM, Kernels, collaborative filtering, network analysis, high-dimensional reduction, etc) and deep learning models (Feed forward NN, Recurrent NN, Convolutional NN, Graph NN, Transformers, etc)."
  },
  {
    "objectID": "posts/time_series/time_series_analysis.html",
    "href": "posts/time_series/time_series_analysis.html",
    "title": "Analysis of Time-series Data",
    "section": "",
    "text": "On this project we’ll analyze a time-series data. Specifically, we’ll analyze the annual average temperature from Junin, Peru. The objective is build a model that can helps us predict the annual temprature for future years.\nCode\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom scipy.interpolate import interp1d\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom bokeh.io import output_notebook, show, export_png\n# from bokeh.io import output_file\nfrom bokeh.plotting import figure\nfrom itertools import chain \nfrom sklearn.metrics import mean_squared_error\nimport datetime as dt\nimport statsmodels.api as sm\nfrom statsmodels.graphics.tsaplots import plot_acf,plot_pacf\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom statsmodels.tsa.arima.model import ARIMA\nimport pmdarima as pm\nimport seaborn as sns\nimport math\nimport pmdarima as pm\nimport statsmodels.api as sm\ndef mean_absolute_percentage_error(y_true, y_pred): \n     return np.mean(np.abs((y_true - y_pred) / y_true)) *100\noutput_notebook()\n\n\n    \n    \n        \n        Loading BokehJS ..."
  },
  {
    "objectID": "posts/time_series/time_series_analysis.html#removing-the-trend",
    "href": "posts/time_series/time_series_analysis.html#removing-the-trend",
    "title": "Analysis of Time-series Data",
    "section": "Removing the Trend",
    "text": "Removing the Trend\n\nLinear Trend\nFirst let’s define the functions to calculate the Akaike Information Criteria and the Bayesian Information Criteria to test the performance of our models.\n\n\nCode\nfrom scipy.stats import norm \ndef evaluate_AIC(k, residuals):\n  \"\"\"\n  Finds the AIC given the number of parameters estimated and \n  the residuals of the model. Assumes residuals are distributed \n  Gaussian with unknown variance. \n  \"\"\"\n  standard_deviation = np.std(residuals)\n  log_likelihood = norm.logpdf(residuals, 0, scale=standard_deviation)\n  return 2 * k - 2 * np.sum(log_likelihood)\n\ndef evaluate_BIC(k, residuals):\n  \"\"\"\n  Finds the AIC given the number of parameters estimated and \n  the residuals of the model. Assumes residuals are distributed \n  Gaussian with unknown variance. \n  \"\"\"\n  standard_deviation = np.std(residuals)\n  log_likelihood = norm.logpdf(residuals, 0, scale=standard_deviation)\n  return k * np.log(len(residuals)) - 2 * np.sum(log_likelihood)\n\n\nNow, we can begin fitting a linear trend to the data.\n\n\nCode\nX = subset_df[\"Year\"].values.reshape(-1,1)\ny = subset_df[\"Temp_annual_mean\"].values.reshape(-1,1)\n\n\nlinear_model = LinearRegression()\nlinear_model.fit(X, y)\n\nprint(linear_model.coef_)\n\ny_hat = linear_model.predict(X)\n\nplt.plot(X, y, label='original data')\nplt.plot(X, y_hat, 'r', label='fitted line')\nplt.legend()\n\n\n\n[[0.01386713]]\n\n\n\n\n\n\n\n\n\nAnd plot the residuals of the model.\n\n\nCode\nlinear_residuals = y - y_hat\nplt.plot(X, linear_residuals,'o')\nsns.regplot(x=X, y=linear_residuals)\n\nprint(\"MSE with linear fit:\", np.mean((linear_residuals)**2))\nprint(\"AIC:\", evaluate_AIC(1, linear_residuals))\nprint(\"BIC:\", evaluate_BIC(1, linear_residuals))\n\n\nMSE with linear fit: 0.12615193027776006\nAIC: 57.2678309969092\nBIC: 59.54449711592525\n\n\n\n\n\n\n\n\n\nThe plot shows a good distribution of the residuals.\nLet’s check the autocorrelation and partial autocorralation of the residuals.\n\n\nCode\nsm.graphics.tsa.plot_acf(linear_residuals, lags=20)\nplt.show()\nsm.graphics.tsa.plot_pacf(linear_residuals, lags=20)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt seems there is an autocorrelation structure on the data.\n\n\nQuadratic Trend\nTo check that the linear trend is a good choice, let’sw compare it with a quadratic fit.\n\n\nCode\ndegree=2\nquadratic_model=LinearRegression()\n\nnew_x = np.hstack((X, X **2))\n\nquadratic_model.fit(new_x, y)\nquadratic = quadratic_model.predict(new_x)\n\nprint(quadratic_model.coef_)\n\ny_hat_quad = quadratic_model.predict(new_x)\n\nplt.plot(X, y, label='original data')\nplt.plot(X, y_hat_quad, 'r', label='fitted line')\nplt.legend()\n\n\n[[ 5.74495264e-01 -1.41109523e-04]]\n\n\n\n\n\n\n\n\n\nThe residuals:\n\n\nCode\nquadratic_residuals = y - y_hat_quad\nplt.plot(X, quadratic_residuals,'o')\nsns.regplot(x=X, y=quadratic_residuals)\n\nprint(\"MSE with linear fit:\", np.mean((quadratic_residuals)**2))\nprint(\"AIC:\", evaluate_AIC(2, quadratic_residuals))\nprint(\"BIC:\", evaluate_BIC(2, quadratic_residuals))\n\n\nMSE with linear fit: 0.12318196679493859\nAIC: 57.55248071646069\nBIC: 62.105812954492805\n\n\n\n\n\n\n\n\n\nAnd the autocorrelation plots.\n\n\nCode\nsm.graphics.tsa.plot_acf(quadratic_residuals, lags=20)\nplt.show()\nsm.graphics.tsa.plot_pacf(quadratic_residuals, lags=20)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThese plots (ACF and PACF) shows that there might be a autocorrelation of order 16 (AR(16)) and possibly a moving average of order 13. Let’s make a grid search over possible values to corroborate this.\n\n\nCode\ndef grid_search_ARIMA(data, AR_range, MA_range, verbose=False):\n  min_aic = np.inf \n  min_bic = np.inf\n  min_aic_index = None\n  min_bic_index = None \n  aic_matrix = np.zeros((len(AR_range), len(MA_range)))\n  bic_matrix = np.zeros((len(AR_range), len(MA_range)))\n  for AR_order in AR_range:\n    for MA_order in MA_range:\n      arma = ARIMA(data, order=(AR_order, 0, MA_order)).fit()\n      aic_matrix[AR_order, MA_order] = arma.aic\n      bic_matrix[AR_order, MA_order] = arma.bic\n      if arma.aic &lt; min_aic:\n        min_aic = arma.aic\n        min_aic_index = (AR_order, 0, MA_order)\n      if arma.bic &lt; min_bic:\n        min_bic = arma.bic\n        min_bic_index = (AR_order, 0, MA_order)\n  if verbose:\n    print(\"Minimizing AIC order: \", min_aic_index)\n    print(\"Minimizing BIC order: \", min_bic_index )\n    print(\"matrix of AIC\", aic_matrix)\n    print(\"Matrix of BIC\", bic_matrix)\n  return min_aic_index, min_bic_index, aic_matrix, bic_matrix\n\n\nLuckily, statsmodels give us the BIC and AIC scores for each models we are building. We are using these scores to get the best model in our grid search.\n\n\nCode\nmin_aic_index, min_bic_index, _, _ = grid_search_ARIMA(linear_residuals, range(20), range(20), verbose=True)\nif min_aic_index == min_bic_index:\n  arma = ARIMA(linear_residuals, order=min_bic_index).fit()\n  print(arma.summary())\n  arma_predictions = arma.predict()\n  arma_residuals = linear_residuals - arma_predictions\n  arma_residuals = arma_residuals # Fitting AR 1 model means removing one observation\n  plt.plot(linear_residuals, label='Residuals from fitted quadratic line')\n  plt.plot(arma_predictions, 'r', label='fitted ARMA process')\n  plt.legend()\n  plt.show()\n  plt.plot(arma_residuals, 'o')\n  plt.show()\n  print(\"Automatic selection finds model with AR {0}, MA {2}\".format(*min_aic_index))\n  print(\"MSE with selected model:\", np.mean(arma_residuals**2))\nelse:\n  print(\"AIC, BIC do not agree.\")\n\n\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n  warn('Non-invertible starting MA parameters found.'\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n  warn('Non-stationary starting autoregressive parameters'\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\n\n\nMinimizing AIC order:  (2, 0, 9)\nMinimizing BIC order:  (0, 0, 0)\nmatrix of AIC [[59.26783104 58.54992334 56.88970575 57.79945966 59.13858623 61.06132125\n  60.10357216 56.70724639 58.53031492 58.79141029 56.50215466 53.83056416\n  55.53360818 55.23182903 56.25011347 58.29607542 59.22370895 60.69622205\n  62.22647076 64.27980123]\n [60.01838137 59.01196539 54.78314438 58.68975059 58.21367941 58.11925325\n  59.0577748  59.45027904 60.73655131 59.9252463  57.17792233 55.7365912\n  57.5279835  56.6732098  58.58560271 59.49982214 61.03576455 62.8378866\n  64.5385872  66.80960379]\n [55.60204822 57.44397806 55.93590971 55.28516924 59.26120688 56.7676285\n  56.48409178 57.10386856 56.64832604 52.86203264 54.153882   54.80353584\n  54.92519604 57.89801211 59.59621413 61.05672236 62.98633782 64.98255721\n  64.98545754 68.24167112]\n [57.3687478  59.32047137 60.25882172 56.45016306 54.39221592 54.65960306\n  64.22394424 60.57746518 57.70426024 54.70458015 55.95799305 56.65596753\n  57.6468255  58.81023372 60.48193877 61.72053194 65.92771418 67.04341717\n  70.63721548 71.18084068]\n [59.14942574 60.16696732 55.43512106 54.60174117 59.66358505 56.90480476\n  59.81984521 61.72126301 53.78122065 54.47597726 56.43000237 58.33943936\n  59.79851906 60.74759539 61.9397838  62.61877092 67.76229664 69.2277279\n  72.87708691 72.62363139]\n [60.40981264 62.39919653 59.42642447 61.54330408 57.78042654 58.96114785\n  61.09524713 61.63167538 53.60862951 54.66052224 55.9339392  60.1296563\n  62.18164813 62.99282536 66.0525596  65.26549479 69.14330159 70.87240071\n  68.02871147 72.67504957]\n [62.40170224 64.39927888 60.62995123 63.6825648  59.7051804  61.33200669\n  59.13415    62.02401831 57.66308719 61.11610053 60.06519047 60.26112098\n  64.19789296 61.2653695  64.85471283 65.67339349 69.7437752  72.95251941\n  69.57430322 74.94677503]\n [64.34447628 60.05935422 62.3969647  63.67303358 64.07209862 65.60416731\n  62.05504141 64.51656351 66.05892528 59.65529841 61.98584232 61.35293391\n  65.47289344 64.66384057 64.41897783 62.29931871 69.36109345 72.72596842\n  68.78138574 69.50693126]\n [64.41545455 61.71415914 63.54795097 65.66333692 60.10808786 59.90569828\n  62.10370484 58.32770199 61.4240911  59.83238655 63.13851866 64.06893123\n  62.06925577 64.08994125 66.73659766 69.73560144 72.76526793 74.67639407\n  72.32997535 72.5167611 ]\n [58.88763152 60.62032348 56.32174956 58.37109165 57.18127799 57.9979968\n  60.13371869 61.8217613  62.45246858 63.26705539 63.28433601 65.33991341\n  64.15416778 65.80591849 70.40735139 71.09551673 73.70837078 76.31432766\n  74.15964268 74.54904043]\n [60.46185714 62.33316031 57.97652193 59.98767802 60.01699452 59.91525829\n  62.02879216 62.3272774  61.43014887 63.45995718 64.57083238 66.79380038\n  66.72756485 62.78569633 65.79729765 69.1037027  74.05271602 73.91032018\n  68.89454402 75.9429185 ]\n [61.97041927 63.91206891 59.64344611 61.37400935 59.57250674 61.58339273\n  62.7480419  63.38369221 63.97563916 64.35159438 64.63662196 68.0292894\n  69.88978561 65.25591315 65.13319861 67.43781895 75.88506935 75.93701685\n  75.14617187 76.36974229]\n [63.63597058 62.35808653 60.84634222 63.04798246 61.54304906 63.55419996\n  64.79509909 62.54784339 65.39007171 65.64030002 65.31843543 70.37120629\n  70.72790305 68.9481488  72.08035365 75.70498209 72.73480547 75.58563942\n  73.68754741 84.29162461]\n [62.98285503 64.80495154 65.32919463 60.45838337 62.96135175 62.08647299\n  64.51344513 64.89266037 66.59345037 67.44881901 66.7480505  66.31208872\n  70.37463005 72.42160464 72.37227087 76.39744907 77.08760943 75.30260452\n  75.91255923 76.75954076]\n [64.76611924 66.75592971 64.61713126 62.71140589 65.36156186 67.48855684\n  65.42719093 67.81803452 68.75615495 69.4207174  69.759826   70.60916283\n  72.37711488 74.19570454 73.67777429 78.21254447 77.36334509 79.6251962\n  77.72553906 78.9407086 ]\n [66.66293554 67.77980308 65.4544313  64.58883831 67.92109901 66.55639664\n  69.36610887 70.43391218 71.42742349 70.20057968 70.55349007 73.33025119\n  74.52506171 71.74668773 73.83554345 78.81700438 75.63752456 84.31020079\n  78.81331696 80.25713868]\n [64.05594172 65.94136223 67.58710883 69.04508423 65.47736499 71.29129912\n  69.14330891 69.09748835 69.53539203 69.88838457 71.5360232  73.17185656\n  72.45100046 72.30233633 78.24445035 75.79644228 82.82074378 79.51804671\n  79.82388504 79.81846245]\n [65.88340344 67.31991573 69.24121591 71.03278703 68.52191482 70.5365999\n  70.43184559 70.42099772 71.33343091 71.80401553 73.80889981 74.70363714\n  72.4465451  75.79010158 80.5398399  77.62198717 84.90464036 81.8517004\n  81.86401746 80.84358572]\n [67.46843461 68.93356711 71.14867163 71.50327634 69.79037073 71.63167747\n  70.42909044 72.42562339 72.59689936 72.7441992  73.6218613  75.96098587\n  78.51198994 79.27065894 82.11453555 78.47673277 86.52803398 82.67852269\n  83.09122525 84.83274228]\n [68.49571987 70.38710021 72.13463923 74.21073296 69.51714758 70.5919664\n  74.10239936 74.12004659 74.02198301 74.31395149 75.73698092 78.07651132\n  80.45214899 78.70575615 83.66879418 80.77171565 82.83606246 84.96232135\n  85.25326334 87.06597314]]\nMatrix of BIC [[ 63.82116328  65.3799217   65.99637023  69.18279025  72.79858294\n   76.99798408  78.31690112  77.19724146  81.29697612  83.8347376\n   83.82214809  83.4272237   87.40693385  89.38182081  92.67677138\n   96.99939945 100.20369909 103.95287831 107.75979314 112.08978973]\n [ 66.84837973  68.11862987  66.16647497  72.3497473   74.15034224\n   76.3325822   79.54776987  82.21694023  85.77987862  87.24523973\n   86.77458187  87.60991686  91.67797528  93.09986771  97.28892673\n  100.47981228 104.29242081 108.37120898 112.3485757  116.8962584 ]\n [ 64.7087127   68.82730865  69.59590642  71.22183207  77.47453583\n   77.25762357  79.25075297  82.14719587  83.96831946  82.45869219\n   86.02720766  88.95352763  91.35185395  96.60133613 100.57620427\n  104.31337862 108.5196602  112.79254571 115.07211216 120.60499185]\n [ 68.75207839  72.98046809  76.19548456  74.66349201  74.88221099\n   77.42626425  89.26727155  87.89745861  87.30091979  86.57790582\n   90.10798483  93.08262544  96.35014952  99.79022387 103.73859503\n  107.25385432 113.73770268 117.13007179 123.00053622 125.82082754]\n [ 72.80942245  76.10363015  73.64845002  75.09173625  82.43024624\n   81.94813207  87.13983863  91.31792256  85.65454631  88.62596904\n   92.85666027  97.04276338 100.7785092  104.00425165 107.47310618\n  110.42875942 117.84895126 121.59104863 127.51707377 129.54028437]\n [ 76.34647547  80.61252548  79.91641954  84.30996527  82.82375385\n   86.28114128  90.69190667  93.50500105  87.7586213   91.08718014\n   94.63726322 101.10964645 105.43830439 108.52614774 113.8625481\n  115.35214941 121.50662232 125.51238756 124.94536444 131.86836866]\n [ 80.61503119  84.88927395  83.39661242  88.72589211  87.02517383\n   90.92866623  91.00747567  96.17401009  94.08974509  99.81942455\n  101.04518061 103.51777724 109.73121534 109.075358   114.94136745\n  118.03671422 124.38376205 129.86917238 128.76762232 136.41676025]\n [ 84.83447135  82.82601541  87.44029201  90.993027    93.66875817\n   97.47749297  96.2050332  100.94322142 104.7622493  100.63528855\n  105.24249858 106.88625629 113.28288194 114.75049518 116.78229856\n  116.93930556 126.27774643 131.91928751 130.25137096 133.25358259]\n [ 87.18211574  86.75748645  90.8679444   95.25999647  91.98141352\n   94.05569006  98.53036274  97.03102601 102.40408124 103.08904281\n  108.67184104 111.87891973 112.15591039 116.45326198 121.37658451\n  126.65225441 131.95858702 136.14637929 136.07662668 138.54007855]\n [ 83.93095883  87.94031691  85.91840911  90.24441732  91.33126978\n   94.4246547   98.83704271 102.80175144 105.70912484 108.80037777\n  111.09432451 115.42656803 116.51748852 120.44590535 127.32400437\n  130.28883582 135.17835599 140.060979   140.18296014 142.849024  ]\n [ 87.78185057  91.92981986  89.8498476   94.13766981  96.44365243\n   98.61858231 103.00878231 105.58393366 106.96347125 111.26994568\n  114.657487   119.15712111 121.36755171 119.70234931 124.99061675\n  130.57368792 137.79936735 139.93363763 137.19452759 146.51956819]\n [ 91.56707882  95.78539457  93.7934379   97.80066725  98.27583076\n  102.56338287 106.00469816 108.91701459 111.78562766 114.43824899\n  116.99994269 122.66927626 126.80643859 124.44923224 126.60318382\n  131.18447028 141.9083868  144.23700042 145.72282155 149.2230581 ]\n [ 95.50929625  96.50807831  97.27300013 101.75130648 102.5230392\n  106.81085622 110.32842147 110.35783189 115.47672633 118.00362076\n  119.95842229 127.28785927 129.92122214 130.41813401 135.82700499\n  141.72829954 141.03478904 146.16228911 146.54086321 159.42160654]\n [ 97.13284681 101.23160944 104.03251865 101.43837351 106.21800801\n  107.61979537 112.32343363 114.97931498 118.95677111 122.08880587\n  123.66470348 125.50540782 131.84461527 136.16825597 138.39558832\n  144.69743264 147.66425912 148.15592033 151.04254115 154.1661888 ]\n [101.19277714 105.45925373 105.5971214  105.96806216 110.89488424\n  115.29854534 115.51384555 120.18135525 123.39614181 126.33737037\n  128.9531451  132.07914804 136.12376621 140.21902199 141.97775786\n  148.78919416 150.2166609  154.75517812 155.1321871  158.62402277]\n [105.36625956 108.75979323 108.71108756 110.12216069 115.73108751\n  116.64305126 121.72942961 125.07389904 128.34407646 129.39389877\n  132.02347528 137.07690252 140.54837916 140.0466713  144.41219314\n  151.67032019 150.76750649 161.71684884 158.49663112 162.21711897]\n [105.03593186 109.19801849 113.12043121 116.85507273 115.56401961\n  123.65461985 123.78329577 126.01414133 128.72871113 131.35836978\n  135.28267454 139.19517401 140.75098403 142.87898602 151.09776615\n  150.92642421 160.22739182 159.20136088 161.78386532 164.05510885]\n [109.1400597  112.85323811 117.05120441 121.11944165 120.88523556\n  125.17658676 127.34849856 129.61431681 132.80341612 135.55066687\n  139.83221727 143.00362071 143.02319479 148.64341738 155.66982183\n  155.02863522 164.58795452 163.81168069 166.10066386 167.35689825]\n [113.00175699 116.74355561 121.23532625 123.86659708 124.43035759\n  128.54833044 129.62240953 133.89560861 136.34355069 138.76751665\n  141.92184487 146.53763555 151.36530575 154.40064086 159.52118359\n  158.16004693 168.48801427 166.91516909 169.60453777 173.62272092]\n [116.30570837 120.47375483 124.49795997 128.85071981 126.43380055\n  129.78528549 135.57238458 137.86669792 140.04530046 142.61393506\n  146.31363061 150.92982713 155.58213092 156.1124042  163.35210835\n  162.73169593 167.07270886 171.47563387 174.04324199 178.1326179 ]]\nAIC, BIC do not agree.\n\n\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\n\n\nWe see that the grid search output an ARMA(2,9) model. Let’s work with this model and form forecasts.\nTo evaluate the model we will use a rolling window cross-validation. This will help us view how the model improve as we include more time series data. The window we are gonna use is 20 years and we’ll forecast 20 years.\n\n\nCode\nwindow_size = 20\n\nfor i in range(20,72,window_size):\n    \n    train_temp, test_temp = quadratic_residuals[:i], quadratic_residuals[i:i+window_size]\n    train_date, test_date = X[:i], X[i:i+window_size]\n    arma = ARIMA(train_temp, order=min_aic_index).fit()\n    # print(arma.summary())\n    fig, ax = plt.subplots(figsize=(15, 5))\n    fcast = arma.get_forecast(len(test_temp)).summary_frame()\n\n    arma_predictions = arma.predict()\n    ax.plot(X, quadratic_residuals, label='annual mean T°C, converted to stationary time series')\n    predicted_values = arma_predictions.reshape(-1,1)\n    ax.plot(train_date, predicted_values, 'r', label='fitted line')\n    forecast_means = fcast['mean'].values.reshape(-1,1)\n    test_set_mse = np.mean((forecast_means.reshape(test_temp.shape) - test_temp)**2)\n    ax.plot(test_date, forecast_means, 'k--', label='mean forecast')\n    ax.fill_between(test_date.flatten(), fcast['mean_ci_lower'], fcast['mean_ci_upper'], color='k', alpha=0.1);\n    plt.legend();\n    print(\"Test set mean squared error: \", test_set_mse)\n\n\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n  warn('Too few observations to estimate starting parameters%s.'\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n  warn('Non-stationary starting autoregressive parameters'\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n  warn('Non-invertible starting MA parameters found.'\n\n\nTest set mean squared error:  0.20590924950605077\n\n\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n  warn('Non-invertible starting MA parameters found.'\n\n\nTest set mean squared error:  0.09063865739126532\n\n\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\n\n\nTest set mean squared error:  0.039150953597273795\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the first plot, we can see that only using 20 values for training, the forecast converge to the mean of the series. And, as we continue including data, the forcast improve.\nLet’s see if using an external variable (in this case the annual mean precipitation) improve our model.\n\n\nCode\nwindow_size = 20\n\nfor i in range(20,72,window_size):\n    \n    train_temp, test_temp = quadratic_residuals[:i], quadratic_residuals[i:i+window_size]\n    train_date, test_date = X[:i], X[i:i+window_size]\n\n    train_prec, test_prec = subset_df[\"Prec_annual_mean\"].values.reshape(-1,1)[:i], subset_df[\"Prec_annual_mean\"].values.reshape(-1,1)[i:i+window_size]\n\n\n    arma = ARIMA(train_temp, order=min_aic_index, exog=train_prec).fit()\n    # print(arma.summary())\n    fig, ax = plt.subplots(figsize=(15, 5))\n    fcast = arma.get_forecast(len(test_temp), exog=test_prec).summary_frame()\n\n    arma_predictions = arma.predict()\n    ax.plot(X, quadratic_residuals, label='annual mean T°C, converted to stationary time series')\n    predicted_values = arma_predictions.reshape(-1,1)\n    ax.plot(train_date, predicted_values, 'r', label='fitted line')\n    forecast_means = fcast['mean'].values.reshape(-1,1)\n    test_set_mse = np.mean((forecast_means.reshape(test_temp.shape) - test_temp)**2)\n    ax.plot(test_date, forecast_means, 'k--', label='mean forecast')\n    ax.fill_between(test_date.flatten(), fcast['mean_ci_lower'], fcast['mean_ci_upper'], color='k', alpha=0.1);\n    plt.legend();\n    print(\"Test set mean squared error: \", test_set_mse)\n\n\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n  warn('Too few observations to estimate starting parameters%s.'\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n  warn('Non-stationary starting autoregressive parameters'\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n  warn('Non-invertible starting MA parameters found.'\n\n\nTest set mean squared error:  0.18613318748268368\nTest set mean squared error:  0.11609711371821685\n\n\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n  warn('Non-invertible starting MA parameters found.'\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\n\n\nTest set mean squared error:  0.07317563428347647\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can see that including the precipitation doesn’t improve the predictions of temperature on this ARMA(2,9) model. This analysis use the autoregressive models to get forecasts on time series data but, nowadays this methods can be extenden with deep learning models like recurrent neural networks or transformers to have better predictions. Also, is possible to make a temporal-spatial analysis using gaussian processes plus deep learning models."
  },
  {
    "objectID": "posts/Regression_and_Gradient_Descent/regression_and_gradient_descent.html",
    "href": "posts/Regression_and_Gradient_Descent/regression_and_gradient_descent.html",
    "title": "Likelihood Ratio Test, Regression and Gradient Descent",
    "section": "",
    "text": "Code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy as sc\nimport seaborn as sns\n\n\nThe file gamma-ray.csv contains a small quantity of data collected from the Compton Gamma Ray Observatory, a satellite launched by NASA in 1991 (http://cossc.gsfc.nasa.gov/). For each of 100 sequential time intervals of variable lengths (given in seconds), the number of gamma rays originating in a particular area of the sky was recorded.\nFor this analysis, we would like to check the assumption that the emission rate is constant.\nFirst, let’s check the distribution of the number of gamma rays\n\n\nCode\ndf = pd.read_csv(\"gamma-ray.csv\", sep=\",\")\n\nsns.set_theme(style=\"darkgrid\")\nsns.displot(df,x=\"count\")\n\n\n\n\n\n\n\n\n\nThe number of these gamma rays is discrete and non-negative. We can assume that the gamma rays emerge independently of one another, and at constant rate in each time interval. Based on this assumption, a Poisson model is a good model assumption. Each observation \\(G_i\\) follows a poisson distribution with rate \\(\\lambda_i\\) times the time interval \\(t_i\\).\n\\[G_i \\thicksim Poisson(\\lambda_i * t_i)\\]\nTHe hypothesis that we wanna test is that the emission rate is constat so:\n\\(H_0: \\lambda_0 = \\lambda_1 = ... = \\lambda_{99}\\)\nAnd the alternative hypothesis is that the emisison rates are different:\n\\(H_A: \\lambda_i \\neq \\lambda_j\\) for some i and j\nThe most plausible parameter for \\(\\lambda\\) under the null hypothesis is the maximun likelihood estimator (MLE).\nGiven the poisson distribution, the derivation goes as follows:\n\\[f(G_0,G_1,...,G_{99} | \\lambda) = \\prod_{i=0}^{99} \\frac{e^{-\\lambda*t_i}*(\\lambda*t_i)^{G_i}}{G_i!}\\]\n\\[ln(f) = -\\lambda \\sum_{i=0}^{99} t_i + ln(\\lambda) \\sum_{i=0}^{99} G_i + ln(\\prod_{i=0}^{99} t_i^{G_i})) - ln(\\prod_{i=0}^{99} G_i!)\\]\nThen, we derivate w.r.t parameter \\(\\lambda\\) and set the derivative to 0 to find the optimal \\(\\lambda\\).\n\\[0 = -\\sum_{i=0}^{99}t_i + \\sum_{i=0}^{99} \\frac{G_i}{\\lambda}\\]\n\\[\\hat{\\lambda} = \\frac{\\sum_{i=0}^{99} G_i}{\\sum_{i=0}^{99} t_i}\\]\n\n\nCode\nlambda_null = df[\"count\"].sum() / df[\"seconds\"].sum()\n\nlambda_null\n\n\n0.0038808514969907496\n\n\nSimilarly, we can calculate a plausible value for the alternative hypothesis with MLE.\n\\[ln(f) = -\\sum_{i=0}^{99} \\lambda_i*t_i + \\sum_{i=0}^{99} G_i*ln(\\lambda_i) + ln(\\prod_{i=0}^{99} G_i*ln(t_i)) - ln(\\prod_{i=0}^{99} G_i!)\\]\nWE take the partial derivative w.r.t each parameter \\(\\lambda_i\\) to find the optimal \\(\\lambda_i\\)\n\\[0 = -t_i + \\frac{G_i}{\\lambda_i}\\]\n\\[\\hat{\\lambda_i} = \\frac{G_i}{t_i}\\]\n\n\nCode\nlambdas_alt = df[\"count\"]/df[\"seconds\"]\n\nlambdas_alt\n\n\n0     0.000000\n1     0.000000\n2     0.000000\n3     0.000000\n4     0.009804\n        ...   \n95    0.025840\n96    0.000000\n97    0.000000\n98    0.000000\n99    0.000000\nLength: 100, dtype: float64\n\n\nNow to test these hypotheses, we are gonna use the likelihood ratio test:\n\\[\\Lambda(x) = -2ln(\\frac{argmax f(G_0,G_1,...,G_{99}| \\lambda)}{argmax f(G_0,G_1,...,G_{99}| \\lambda_0,...,\\lambda_{99})})\\]\nwhich asymptotic distribution \\(X_{100-1 = 99}^{2}\\)\n\n\nCode\nlh_null = sc.stats.poisson.pmf(k=df[\"count\"], mu=lambda_null)\n\nlh_alt = sc.stats.poisson.pmf(k=df[\"count\"], mu=lambdas_alt)\n\nllh_test = -2*np.log(lh_null.prod() / lh_alt.prod())\n\nllh_test\n\n\n104.33272117042188\n\n\nWe can see the distribution of the chi-squared pdf at 99 degrees of freedom\n\n\nCode\nplot_Xs = np.arange(50,150,0.1)\nplt.plot(plot_Xs, sc.stats.chi2.pdf(plot_Xs, 99))\nplt.show()\n\n\n\n\n\n\n\n\n\nAnd see the value that give a p-value of 0.05\n\n\nCode\n# We can calculate the Lambda that would give a p-value of 0.05 by using the inverse survival function\nsc.stats.chi2.isf(0.05, 99)\n\n\n123.22522145336181\n\n\nCalculating our p-value:\n\n\nCode\npvalue = sc.stats.chi2.sf(llh_test, 99)\nprint(pvalue)\n\n\n0.337398546433923\n\n\nWe can conclude that we cannot reject our null hypothesis, emission rate of gamma rays appear to be constant."
  },
  {
    "objectID": "posts/Regression_and_Gradient_Descent/regression_and_gradient_descent.html#likelihood-ratio-test",
    "href": "posts/Regression_and_Gradient_Descent/regression_and_gradient_descent.html#likelihood-ratio-test",
    "title": "Likelihood Ratio Test, Regression and Gradient Descent",
    "section": "",
    "text": "Code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy as sc\nimport seaborn as sns\n\n\nThe file gamma-ray.csv contains a small quantity of data collected from the Compton Gamma Ray Observatory, a satellite launched by NASA in 1991 (http://cossc.gsfc.nasa.gov/). For each of 100 sequential time intervals of variable lengths (given in seconds), the number of gamma rays originating in a particular area of the sky was recorded.\nFor this analysis, we would like to check the assumption that the emission rate is constant.\nFirst, let’s check the distribution of the number of gamma rays\n\n\nCode\ndf = pd.read_csv(\"gamma-ray.csv\", sep=\",\")\n\nsns.set_theme(style=\"darkgrid\")\nsns.displot(df,x=\"count\")\n\n\n\n\n\n\n\n\n\nThe number of these gamma rays is discrete and non-negative. We can assume that the gamma rays emerge independently of one another, and at constant rate in each time interval. Based on this assumption, a Poisson model is a good model assumption. Each observation \\(G_i\\) follows a poisson distribution with rate \\(\\lambda_i\\) times the time interval \\(t_i\\).\n\\[G_i \\thicksim Poisson(\\lambda_i * t_i)\\]\nTHe hypothesis that we wanna test is that the emission rate is constat so:\n\\(H_0: \\lambda_0 = \\lambda_1 = ... = \\lambda_{99}\\)\nAnd the alternative hypothesis is that the emisison rates are different:\n\\(H_A: \\lambda_i \\neq \\lambda_j\\) for some i and j\nThe most plausible parameter for \\(\\lambda\\) under the null hypothesis is the maximun likelihood estimator (MLE).\nGiven the poisson distribution, the derivation goes as follows:\n\\[f(G_0,G_1,...,G_{99} | \\lambda) = \\prod_{i=0}^{99} \\frac{e^{-\\lambda*t_i}*(\\lambda*t_i)^{G_i}}{G_i!}\\]\n\\[ln(f) = -\\lambda \\sum_{i=0}^{99} t_i + ln(\\lambda) \\sum_{i=0}^{99} G_i + ln(\\prod_{i=0}^{99} t_i^{G_i})) - ln(\\prod_{i=0}^{99} G_i!)\\]\nThen, we derivate w.r.t parameter \\(\\lambda\\) and set the derivative to 0 to find the optimal \\(\\lambda\\).\n\\[0 = -\\sum_{i=0}^{99}t_i + \\sum_{i=0}^{99} \\frac{G_i}{\\lambda}\\]\n\\[\\hat{\\lambda} = \\frac{\\sum_{i=0}^{99} G_i}{\\sum_{i=0}^{99} t_i}\\]\n\n\nCode\nlambda_null = df[\"count\"].sum() / df[\"seconds\"].sum()\n\nlambda_null\n\n\n0.0038808514969907496\n\n\nSimilarly, we can calculate a plausible value for the alternative hypothesis with MLE.\n\\[ln(f) = -\\sum_{i=0}^{99} \\lambda_i*t_i + \\sum_{i=0}^{99} G_i*ln(\\lambda_i) + ln(\\prod_{i=0}^{99} G_i*ln(t_i)) - ln(\\prod_{i=0}^{99} G_i!)\\]\nWE take the partial derivative w.r.t each parameter \\(\\lambda_i\\) to find the optimal \\(\\lambda_i\\)\n\\[0 = -t_i + \\frac{G_i}{\\lambda_i}\\]\n\\[\\hat{\\lambda_i} = \\frac{G_i}{t_i}\\]\n\n\nCode\nlambdas_alt = df[\"count\"]/df[\"seconds\"]\n\nlambdas_alt\n\n\n0     0.000000\n1     0.000000\n2     0.000000\n3     0.000000\n4     0.009804\n        ...   \n95    0.025840\n96    0.000000\n97    0.000000\n98    0.000000\n99    0.000000\nLength: 100, dtype: float64\n\n\nNow to test these hypotheses, we are gonna use the likelihood ratio test:\n\\[\\Lambda(x) = -2ln(\\frac{argmax f(G_0,G_1,...,G_{99}| \\lambda)}{argmax f(G_0,G_1,...,G_{99}| \\lambda_0,...,\\lambda_{99})})\\]\nwhich asymptotic distribution \\(X_{100-1 = 99}^{2}\\)\n\n\nCode\nlh_null = sc.stats.poisson.pmf(k=df[\"count\"], mu=lambda_null)\n\nlh_alt = sc.stats.poisson.pmf(k=df[\"count\"], mu=lambdas_alt)\n\nllh_test = -2*np.log(lh_null.prod() / lh_alt.prod())\n\nllh_test\n\n\n104.33272117042188\n\n\nWe can see the distribution of the chi-squared pdf at 99 degrees of freedom\n\n\nCode\nplot_Xs = np.arange(50,150,0.1)\nplt.plot(plot_Xs, sc.stats.chi2.pdf(plot_Xs, 99))\nplt.show()\n\n\n\n\n\n\n\n\n\nAnd see the value that give a p-value of 0.05\n\n\nCode\n# We can calculate the Lambda that would give a p-value of 0.05 by using the inverse survival function\nsc.stats.chi2.isf(0.05, 99)\n\n\n123.22522145336181\n\n\nCalculating our p-value:\n\n\nCode\npvalue = sc.stats.chi2.sf(llh_test, 99)\nprint(pvalue)\n\n\n0.337398546433923\n\n\nWe can conclude that we cannot reject our null hypothesis, emission rate of gamma rays appear to be constant."
  },
  {
    "objectID": "posts/Regression_and_Gradient_Descent/regression_and_gradient_descent.html#regression-and-gradient-descent",
    "href": "posts/Regression_and_Gradient_Descent/regression_and_gradient_descent.html#regression-and-gradient-descent",
    "title": "Likelihood Ratio Test, Regression and Gradient Descent",
    "section": "Regression and Gradient Descent",
    "text": "Regression and Gradient Descent\n\nRegression\nWe are gonna use a dataset from General Motors about mortality. This data is from 59 US cities where it was studied the contribution of air pollution to mortality.\nThe dependen variable is the age adjusted mortality (Mortality). Also, the data includes variables measuring climate characteristics (JanTemp, JulyTemp, RelHum, Rain), demographic characteristics of the cities (Educ, Dens, NonWhite, WhiteCollar, Pop, House, Income), and variables recording the pollution potential of three diferent air pollutants (HC, NOx, SO2).\nLet’s load the data:\n\n\nCode\ndf = pd.read_csv(\"mortality.csv\", sep=\",\")\ndf.head()\n\n\n\n\n\n\n\n\n\nCity\nMortality\nJanTemp\nJulyTemp\nRelHum\nRain\nEduc\nDens\nNonWhite\nWhiteCollar\nPop\nHouse\nIncome\nHC\nNOx\nSO2\n\n\n\n\n0\nAkron, OH\n921.87\n27\n71\n59\n36\n11.4\n3243\n8.8\n42.6\n660328\n3.34\n29560\n21\n15\n59\n\n\n1\nAlbany-Schenectady-Troy, NY\n997.87\n23\n72\n57\n35\n11.0\n4281\n3.5\n50.7\n835880\n3.14\n31458\n8\n10\n39\n\n\n2\nAllentown, Bethlehem,PA-NJ\n962.35\n29\n74\n54\n44\n9.8\n4260\n0.8\n39.4\n635481\n3.21\n31856\n6\n6\n33\n\n\n3\nAtlanta, GA\n982.29\n45\n79\n56\n47\n11.1\n3125\n27.1\n50.2\n2138231\n3.41\n32452\n18\n8\n24\n\n\n4\nBaltimore, MD\n1071.29\n35\n77\n55\n43\n9.6\n6441\n24.4\n43.7\n2199531\n3.44\n32368\n43\n38\n206\n\n\n\n\n\n\n\nLet’s write two helper function that adds the intercept to the data and perform the ordinary least squares estimation based on the formula:\n\\[\\hat{\\beta}=(X^{T}X)^{-1}X^{T}y\\]\n\n\nCode\ndef add_intercept(X: np.array):\n  return np.concatenate((np.ones_like(X[:,:1]), X), axis=1)\n\ndef OLS(X: np.array, y: np.array):\n  return np.linalg.inv(X.T.dot(X)).dot(X.T.dot(y))\n\n\nAlso we need to declare the matrix X and the dependent variable y and convert them to numpy objects.\n\n\nCode\ny = df[\"Mortality\"]\nX = df.loc[:,\"JanTemp\":\"SO2\"]\n\n# Now lets add the intercept to X\n\nX = X.to_numpy()\ny = y.to_numpy()\n\n\nNow, can calculate the betas:\n\n\nCode\nbetas = OLS(add_intercept(X), y)\n\nbetas\n\n\narray([ 1.40003471e+03, -1.44112034e+00, -2.95025005e+00,  1.36009551e-01,\n        9.69507928e-01, -1.10466624e+01,  4.71706516e-03,  5.30271368e+00,\n       -1.49231882e+00,  3.40228581e-06, -3.80416445e+01, -4.25186359e-04,\n       -6.71247478e-01,  1.17850768e+00,  8.45829777e-02])\n\n\nGreat! This was an easy way to compute the OLS regression. We also can do the same with sklearn:\n\n\nCode\nfrom sklearn.linear_model import LinearRegression\n\nreg = LinearRegression()\n\nreg.fit(add_intercept(X),y)\n\nprint(reg.intercept_, reg.coef_)\n\n\n1400.0347123466809 [ 0.00000000e+00 -1.44112034e+00 -2.95025005e+00  1.36009551e-01\n  9.69507928e-01 -1.10466624e+01  4.71706516e-03  5.30271368e+00\n -1.49231882e+00  3.40228581e-06 -3.80416445e+01 -4.25186359e-04\n -6.71247478e-01  1.17850768e+00  8.45829777e-02]\n\n\n\n\nGradient Descent\nWe also can do the regression task via optimization with the gradient descent algorithm. Let’s write some helper functions that will helps us to do the gradient descent algorithm.\n\n\nCode\ndef loss_fn(beta, X, y):\n  # (y - X beta)^T (y - X beta)\n  return np.sum(np.square(y - X.dot(beta)))\n\ndef loss_grad(beta, X, y):\n  # -2*(y - X beta)^T X\n  return -2*(y - X.dot(beta)).T.dot(X)\n\ndef gradient_step(beta, step_size, X, y):\n  loss, grads = loss_fn(beta, X, y), loss_grad(beta, X, y)\n  \n  beta = beta - step_size * grads.T\n  return loss, beta\n\ndef gradient_descent(X, y, step_size, precision, max_iter=10000, warn_max_iter=True):\n  beta = np.zeros_like(X[0])\n  \n  losses = [] # Array for recording the value of the loss over the iterations.\n  graceful = False\n  for _ in range(max_iter):\n    beta_last = beta # Save last values of beta for later stopping criterion\n    loss, beta = gradient_step(beta, step_size, X, y)\n    losses.append(loss)\n    # Use the euclidean norm of the difference between the new beta and the old beta as a stopping criteria\n    if np.sqrt(np.sum(np.square((beta - beta_last)))) &lt; precision:\n      graceful = True\n      break\n  if not graceful and warn_max_iter:\n    print(\"Reached max iterations.\")\n  return beta, np.array(losses)\n\n\nBefore applying the gradient descent, we need to standardize the data because the loss explote due to some outliers. &gt; You can try it without the standardization\n\n\nCode\n# Standardize the data\n\nX_scaled = (X - X.mean(axis=0))/X.std(axis=0, ddof=1)\nY_scaled = (y - y.mean())/y.std(ddof=1)\nX_inter = add_intercept(X_scaled)\n\n# Apply the gradient descent\n\nbeta_gd, losses = gradient_descent(X_inter, Y_scaled, 0.001, 1e-8, max_iter=10000)\nprint(\"BetaHat = {}\".format(beta_gd))\nprint(\"Final loss value = {}\".format(losses[-1]))\nplt.plot(range(len(losses)), losses)\nplt.title(\"Iteration vs Loss\")\nplt.show()\n\n# As a sanity check, we can also do the matrix inversion with OLS\nprint(\"Matrix inverse BetaHat = {}\".format(OLS(X_inter, Y_scaled)))\n\n\n\nReached max iterations.\nBetaHat = [ 9.99200722e-19 -2.34387032e-01 -2.17491727e-01  1.17191047e-02\n  1.79800652e-01 -1.50530629e-01  1.08943031e-01  7.64357603e-01\n -1.21223518e-01  8.40179286e-02 -1.11464155e-01 -3.04603568e-02\n -9.95161696e-01  8.80002697e-01  8.62630571e-02]\nFinal loss value = 13.809259921735789\n\n\n\n\n\n\n\n\n\nMatrix inverse BetaHat = [ 3.21984155e-17 -2.34377091e-01 -2.17496828e-01  1.17238925e-02\n  1.79754504e-01 -1.50544513e-01  1.08945825e-01  7.64348559e-01\n -1.21202349e-01  8.40325965e-02 -1.11479218e-01 -3.04687337e-02\n -9.96190618e-01  8.81043305e-01  8.61146149e-02]\n\n\nNote that the betas changed because we standardized the data, thats why at the end we are checking with the OLS function."
  },
  {
    "objectID": "posts/Naive_scRNA-Seq_analysis/naive_scrnaseq_analysis.html",
    "href": "posts/Naive_scRNA-Seq_analysis/naive_scrnaseq_analysis.html",
    "title": "Analysis of Hyper-parameters on Single Cell RNA-Seq Data",
    "section": "",
    "text": "Code\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import MDS\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.metrics import silhouette_score, silhouette_samples\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.metrics import silhouette_score, silhouette_samples\nimport scanpy as sc\nfrom sklearn.model_selection import train_test_split\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff"
  },
  {
    "objectID": "posts/Naive_scRNA-Seq_analysis/naive_scrnaseq_analysis.html#getting-the-data",
    "href": "posts/Naive_scRNA-Seq_analysis/naive_scrnaseq_analysis.html#getting-the-data",
    "title": "Analysis of Hyper-parameters on Single Cell RNA-Seq Data",
    "section": "Getting the Data",
    "text": "Getting the Data\nWe will analyze three types of hyper-parameters: Perplexity on t-SNE, number of clusters chosen from an unsupervised method and how these affect the quality of the selected features and how the number of PC’s affect the t-SNE.\nTo performs these three tasks we are gonna work with real data. Specifically, we’re gonna use scRNA-Seq data from a brain sample (GSM6900730). The data is available on this link.\nIn our case, let’s do a basic web scrapping code to get the data.\n\n\nCode\n# download the data and load it for the posterior analysis\nimport urllib.parse\nimport requests\nimport urllib\nfrom bs4 import BeautifulSoup\nimport os\nfrom ftplib import FTP\n\nurl = \"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM6900730\"\n\nresponse = requests.get(url)\n\nsoup = BeautifulSoup(response.text, 'html.parser')\n\ntable = soup.find('table')\nlinks = table.find_all('a')\n\ndownload_dir = os.getcwd()\n\nfor link in links:\n    # Get the URL of the link\n    link_url = link.get('href')\n    # Check if the link contains 'ftp'\n    if link_url and 'ftp' in link_url:\n        # Parse the FTP URL\n        link_url = urllib.parse.unquote(link_url)\n        parsed_url = urllib.parse.urlparse(link_url)\n        hostname = parsed_url.hostname\n        path = parsed_url.path\n        \n        # Connect to the FTP server\n        ftp = FTP(hostname)\n        ftp.login()\n        ftp.cwd(os.path.dirname(path))\n    \n        # Extract the file name from the path\n        file_name = os.path.basename(path)\n        local_file_path = os.path.join(download_dir, file_name)\n        \n        with open(local_file_path, \"wb\") as local_file:\n            ftp.retrbinary(f\"RETR {file_name}\", local_file.write)\n    \n        ftp.quit()\n        print(f\"Downloaded {file_name}\")\n        \n\n\nDownloaded GSM6900730_JLE16_B1_barcodes.tsv.gz\nDownloaded GSM6900730_JLE16_B1_features.tsv.gz\nDownloaded GSM6900730_JLE16_B1_matrix.mtx.gz\n\n\nNow, let’s load the data (is a sparse matrix) with scanpy:\n\n\nCode\nscdata = sc.read_10x_mtx('D:/Data Analysis Statistical Modeling and Computation in Applications/data/scrnaseq data/',\n                         var_names = 'gene_symbols',\n                         cache=False)\n\nX_sc = scdata.X.toarray()\nprint(X_sc.shape)\n\n\n(5154, 36601)\n\n\nOk, now we are gonna tranform the data with (log(x+1)) due to the presence of genes with extremely high magnitudes of expression in only a few cells.\n\n\nCode\nX_sc_transformed = np.log2(X_sc + 1)\n\n\nWe can use the principal components analysis to get the top components that explains the 85% variability of the data.\n\n\nCode\n# PCA\n\npca = PCA()\npca_axes = pca.fit_transform(X_sc_transformed)\n\n\ncsum = np.cumsum(pca.explained_variance_ratio_)\nplt.plot(np.arange(0,X_sc_transformed.shape[0]),csum)\nplt.xlabel('Component #')\nplt.ylabel('% of Variance Explained')\nplt.title('% Variance explained by # Components')\nplt.show()\n\nprint(f'Variance explained 85%: {np.where(csum &gt;= 0.85)[0][0]}')\n\n\n\n\n\n\n\n\n\nVariance explained 85%: 1758\n\n\nLet’s save the number of components on a variable.\n\n\nCode\ntop_pca_components = np.where(csum &gt;= 0.85)[0][0]"
  },
  {
    "objectID": "posts/Naive_scRNA-Seq_analysis/naive_scrnaseq_analysis.html#analysis-of-perplexities",
    "href": "posts/Naive_scRNA-Seq_analysis/naive_scrnaseq_analysis.html#analysis-of-perplexities",
    "title": "Analysis of Hyper-parameters on Single Cell RNA-Seq Data",
    "section": "Analysis of Perplexities",
    "text": "Analysis of Perplexities\nFor the first part of the analysis, we are gonna analyze the following perplexities: 10,20,30,40,50 and see how this change the output of the t-SNE analysis.\n\n\nCode\n# let's write a helper function for the tsne\n\ndef tsne_plotter(data=None,per=40):\n\n    tsne = TSNE(n_components=2, perplexity=per)\n\n    x_tsne = tsne.fit_transform(data)\n\n    ax.scatter(x_tsne[:, 0], x_tsne[:, 1])\n    ax.set_xlabel('tSNE 1')\n    ax.set_ylabel('tSNE 2')\n    ax.set_title(f't-SNE Plot for log2\\nTransformed Data, Perplexity:{per}')\n\n\n\n\nCode\nperplexities = [10,20,30,40,50]\n\nnum_plots = len(perplexities)\nnum_rows = 2\nnum_cols = 3\nfig, axes = plt.subplots(num_rows, num_cols, figsize=(10,8))\n\nfor i,perplexity in enumerate(perplexities):\n\n    row = i // num_cols\n    col = i % num_cols\n    ax = axes[row, col]\n\n    tsne_plotter(pca_axes[:,0:50], per= perplexity)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nWe can see that increasing the perplexity values make the clusters more defined. This is in consonance with the definition of the perplexity parameter which says: “The perplexity is related to the number of nearest neighbors that is used in other manifold learning algorithms. Larger datasets usually require a larger perplexity. Consider selecting a value between 5 and 50. Different values can result in significantly different results. The perplexity must be less than the number of samples”. Also, we can notice that from the perplexity value 30 to 50 there are more defined clusters; specifically, for perplexity 50 we see six more defined clusters so, this is the perplexity value chosen for the following analyses."
  },
  {
    "objectID": "posts/Naive_scRNA-Seq_analysis/naive_scrnaseq_analysis.html#number-of-clusters-chosen-from-an-unsupervised-method",
    "href": "posts/Naive_scRNA-Seq_analysis/naive_scrnaseq_analysis.html#number-of-clusters-chosen-from-an-unsupervised-method",
    "title": "Analysis of Hyper-parameters on Single Cell RNA-Seq Data",
    "section": "Number of Clusters Chosen from an Unsupervised Method",
    "text": "Number of Clusters Chosen from an Unsupervised Method\nFor this part of the analysis on the scRNA-Seq data, we are gonna use the Gaussian Mixture algorithm to get predictec clusters on the data. Then, using these clusters as “labels” we can perform a logistic regression and see how the test score changes when we change the number of clusters.\nFor this part, we are gonna use the first 2256 principal components with the objective of a precise analysis.\n\n\nCode\nnp.where(csum &gt;= 0.9)[0][0]\n\n\n2256\n\n\nWith 2256 PC’s we achieve 90% of explained variability.\nNow, let’s perform the clustering with the GMM model from 2 to 20 clusters. Also, let’s plot the BIC (Bayesian Information Criterion) and the Silhouette plot to see how many clusters we can select.\n\n\nCode\n## Clustering elbow plot GMM\n\nn_components_range = range(2, 21)\nbic_scores = []\n\nfor n_components in n_components_range:\n    gmm = GaussianMixture(n_components=n_components, random_state=0, init_params='kmeans')\n    gmm.fit(pca_axes[:,0:2256])\n    # print(f'# comp: {n_components}')\n    bic_scores.append(gmm.bic(pca_axes[:,0:2256]))\n\nplt.plot(n_components_range, bic_scores, marker='o', linestyle='-')\nplt.xlabel('Number of Components')\nplt.ylabel('BIC Score')\nplt.title('Elbow Plot for Gaussian Mixture Model')\nplt.xticks(n_components_range)\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nThe BIC score tells us that between 4 and 5 clusters can be a good choice.\n\n\nCode\n## Silhouette plot\n#\nn_components_range = range(2, 21)  # Start from 2 components (minimum required for silhouette score)\nsilhouette_scores = []\n\nfor n_components in n_components_range:\n    gmm = GaussianMixture(n_components=n_components, random_state=0, init_params='kmeans')\n    gmm.fit(pca_axes[:, 0:2256])\n    # print(f'# comp: {n_components}')\n    labels = gmm.predict(pca_axes[:, 0:2256])\n    silhouette_avg = silhouette_score(pca_axes[:, 0:2256], labels)\n    silhouette_scores.append(silhouette_avg)\n\nplt.plot(n_components_range, silhouette_scores, marker='o', linestyle='-')\nplt.xlabel('Number of Components')\nplt.ylabel('Silhouette Score')\nplt.title('Silhouette Score Plot for Gaussian Mixture Model')\nplt.xticks(n_components_range)\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nThe silhouette plot shows that 4, 8 and 9 can be good choices for number of clusters.\nLet’s work with 4, 5, 8 and 9 clusters andd see how these perform.\n\nClusters Analysis\nFirst, let’s write a helper function to plot the t-SNE and to manage some hyper-parameters.\n\n\nCode\ndef tsne_plotter_pca(n_clusters:int, pca_dim:int, perplexity:int = 50):\n\n    gmm = GaussianMixture(n_components=n_clusters, random_state=0, init_params=\"kmeans\")\n    clusters_gmm = gmm.fit_predict(pca_axes[:,0:pca_dim])\n\n    tsne = TSNE(n_components=2, perplexity=perplexity)\n\n    x_tsne = tsne.fit_transform(pca_axes[:,0:pca_dim])\n\n    plt.scatter(x_tsne[:,0], x_tsne[:,1], c=clusters_gmm)\n    plt.xlabel('tSNE 1')\n    plt.ylabel('tSNE 2')\n    plt.title(f\"t-SNE Plot for log2 Transformed Data with GMM\\nwith {pca_dim} PC's, {n_clusters} clusters and perplexity: {perplexity}\")\n    plt.axis('equal')\n    plt.show()\n\n    return clusters_gmm\n\n\n\n\nCode\nres_train = {}\nres_test = {}\n\n\n\nNumber of Clusters: 4Number of Clusters: 5Number of Clusters: 8Number of Clusters: 9\n\n\n\n\nCode\nnp.random.seed(123)\nclust = 4\n\nclusters_gmm = tsne_plotter_pca(n_clusters=clust,\n                    pca_dim=2256,\n                    perplexity=50)    \n    \nX_train, X_test, y_train, y_test = train_test_split(X_sc_transformed, clusters_gmm, test_size=0.2, random_state=42)\n    \nlog_reg = LogisticRegressionCV(cv=10,Cs=[0.01,0.1,1,10],penalty=\"l1\",solver=\"liblinear\",multi_class=\"ovr\")\n\nlog_reg.fit(X_train,y_train)\n\nres_train[\"Cluster \"+str(clust)] = log_reg.score(X_train,y_train)\nres_test[\"Cluster \"+str(clust)] = log_reg.score(X_test,y_test)\n\nprint(f\"Train score: {log_reg.score(X_train,y_train)}\")\nprint(f\"Test score: {log_reg.score(X_test,y_test)}\")\n\n\n\n\n\n\n\n\n\nTrain score: 1.0\nTest score: 0.9903006789524733\n\n\n\n\n\n\nCode\nnp.random.seed(123)\nclust = 5\n\nclusters_gmm = tsne_plotter_pca(n_clusters=clust,\n                    pca_dim=2256,\n                    perplexity=50)    \n    \nX_train, X_test, y_train, y_test = train_test_split(X_sc_transformed, clusters_gmm, test_size=0.2, random_state=42)\n    \nlog_reg = LogisticRegressionCV(cv=10,Cs=[0.01,0.1,1,10],penalty=\"l1\",solver=\"liblinear\",multi_class=\"ovr\")\n\nlog_reg.fit(X_train,y_train)\n\nres_train[\"Cluster \"+str(clust)] = log_reg.score(X_train,y_train)\nres_test[\"Cluster \"+str(clust)] = log_reg.score(X_test,y_test)\n\nprint(f\"Train score: {log_reg.score(X_train,y_train)}\")\nprint(f\"Test score: {log_reg.score(X_test,y_test)}\")\n\n\n\n\n\n\n\n\n\nTrain score: 0.9997574581615328\nTest score: 0.9408341416100873\n\n\n\n\n\n\nCode\nnp.random.seed(123)\nclust = 8\n\nclusters_gmm = tsne_plotter_pca(n_clusters=clust,\n                    pca_dim=2256,\n                    perplexity=50)    \n    \nX_train, X_test, y_train, y_test = train_test_split(X_sc_transformed, clusters_gmm, test_size=0.2, random_state=42)\n    \nlog_reg = LogisticRegressionCV(cv=10,Cs=[0.01,0.1,1,10],penalty=\"l1\",solver=\"liblinear\",multi_class=\"ovr\")\n\nlog_reg.fit(X_train,y_train)\n\nres_train[\"Cluster \"+str(clust)] = log_reg.score(X_train,y_train)\nres_test[\"Cluster \"+str(clust)] = log_reg.score(X_test,y_test)\n\nprint(f\"Train score: {log_reg.score(X_train,y_train)}\")\nprint(f\"Test score: {log_reg.score(X_test,y_test)}\")\n\n\n\n\n\n\n\n\n\nTrain score: 0.9997574581615328\nTest score: 0.9369544131910766\n\n\n\n\n\n\nCode\nnp.random.seed(123)\nclust = 9\n\nclusters_gmm = tsne_plotter_pca(n_clusters=clust,\n                    pca_dim=2256,\n                    perplexity=50)    \n    \nX_train, X_test, y_train, y_test = train_test_split(X_sc_transformed, clusters_gmm, test_size=0.2, random_state=42)\n    \nlog_reg = LogisticRegressionCV(cv=10,Cs=[0.01,0.1,1,10],penalty=\"l1\",solver=\"liblinear\",multi_class=\"ovr\")\n\nlog_reg.fit(X_train,y_train)\n\nres_train[\"Cluster \"+str(clust)] = log_reg.score(X_train,y_train)\nres_test[\"Cluster \"+str(clust)] = log_reg.score(X_test,y_test)\n\nprint(f\"Train score: {log_reg.score(X_train,y_train)}\")\nprint(f\"Test score: {log_reg.score(X_test,y_test)}\")\n\n\n\n\n\n\n\n\n\nTrain score: 0.9980596652922629\nTest score: 0.933074684772066\n\n\n\n\n\n\n\nCode\nplt.plot([4,5,8,9], list(res_train.values()),c=\"r\",label=\"Train\")\nplt.plot([4,5,8,9], list(res_test.values()),c=\"b\", label=\"Test\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nWe can see that the best train and test score achieved was using 4 clusters.\nNow, working only with four clusters we can see the effect on the clustering choosing different number of PC’s to build the t-SNE plot.\n\nEffect of PC’s on t-SNE\nWe cann choose the number of PC’s based on percentage of variance explained. LEt’s work with three values: 50, 70 and 90.\n\n\nCode\npercentages_to_test = [0.5, 0.7, 0.9]\n\npcs_to_test = [np.where(csum &gt;= i)[0][0] for i in percentages_to_test]\n\npcs_to_test\n\n\n[90, 811, 2256]\n\n\n\n\nCode\nnp.random.seed(123)\n\nfor pcas in pcs_to_test:\n    \n    tsne_plotter_pca(n_clusters=4, pca_dim=pcas, perplexity=50)\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn practice, the analysis of scRNA-Seq data involves additional steps before and after the dimention reduction. For example, filtering and normalizing, validate the clusters with especific genes (this is because cell types have a specific expression of certain genes and we can identify these cell types with the gene expression related to the cluster) and do downstream analysis like differential gene expression per cell type, gene-set analysis per cell type and more advanced analysis like cell-cell communiation analysis."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Data Science Projects",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nEvaluating ProteinBERT-GraphSAGE\n\n\n\n\n\n\nLLM\n\n\nBERT\n\n\nDeep learning\n\n\nGNN\n\n\n\n\n\n\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPredict Protein-Protein Interactions with GraphSAGE\n\n\n\n\n\n\nLLM\n\n\nBERT\n\n\nDeep learning\n\n\nGNN\n\n\n\n\n\n\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nProtein Embedding with ProteinBERT and STRING\n\n\n\n\n\n\nDeep learning\n\n\nBERT\n\n\nLLM\n\n\n\n\n\n\n\n\n\nMay 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of Time-series Data\n\n\n\n\n\n\nstatistics\n\n\ntime-series\n\n\n\n\n\n\n\n\n\nMay 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of Hyper-parameters on Single Cell RNA-Seq Data\n\n\n\n\n\n\nscrnaseq\n\n\nhigh-dimensional\n\n\nstatistics\n\n\nregression\n\n\n\n\n\n\n\n\n\nMay 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLikelihood Ratio Test, Regression and Gradient Descent\n\n\n\n\n\n\nstatistics\n\n\nregression\n\n\n\n\n\n\n\n\n\nMay 2, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi! My name is Piero, and I’m a Biologist (with main formation in biotechnology) from Peru. I have specializations in data analysis and bioinformatics from Harvard University and MIT. Also, I love writing reproducible interactive reports using Quarto as a hobby.\nWithin my bioinformatic experience you can find RNA-Seq, Methyl-Seq, WGBS-Seq, Illumina Methylation Array and Multi-omics analyses. Also, I have experience on machine learning (OLS, ridge and lasso regression, SVM, Kernels, collaborative filtering, network analysis, high-dimensional reduction, etc) and deep learning models (Feed forward NN, Recurrent NN, Convolutional NN, Graph NN, Transformers, etc)."
  },
  {
    "objectID": "posts/proteinbert_coffea_arabica_thesis/aplication_to_coffea_arabica_thesis.html",
    "href": "posts/proteinbert_coffea_arabica_thesis/aplication_to_coffea_arabica_thesis.html",
    "title": "Evaluating ProteinBERT-GraphSAGE",
    "section": "",
    "text": "Code\nfrom Bio import Entrez, SeqIO\nimport pandas as pd\nimport zipfile\nimport os\nimport os.path as osp\nimport io\nimport numpy as np"
  },
  {
    "objectID": "posts/proteinbert_coffea_arabica_thesis/aplication_to_coffea_arabica_thesis.html#data-preparation",
    "href": "posts/proteinbert_coffea_arabica_thesis/aplication_to_coffea_arabica_thesis.html#data-preparation",
    "title": "Evaluating ProteinBERT-GraphSAGE",
    "section": "Data Preparation",
    "text": "Data Preparation\nThis is the third part of the series using ProtenBERT and Graph neural networks (GNNs). On this part, we’re gonna use the trained model and see if the protein-protein predictions have sense with a specific dataset. The datset we are gonna use comes from a transcriptomic analysis from my thesis (Functional analysis of transcriptomes of Coffea arabica L. related to thermal stress) where I identified genes with high expression that belongs to the Unfolded protein binding gene ontology.\nTo use the trained model, we need aminoacids sequences which we dont have at the moment. So, first we need to get all the proteins related to the identified genes from the NCBI proteins database.\nFirst, let’s load a csv with the genes:\n\n\nCode\ngene_names_df = pd.read_csv(\"coffea_arabica_thesis_unfolded_protein_binding.csv\", sep=\",\")\ngene_names = list(gene_names_df[\"gene1\"].unique())\ngene_names[:5]\n\n\n['LOC113706996',\n 'LOC113695644',\n 'LOC113692361',\n 'LOC113706995',\n 'LOC113707349']\n\n\nThen, define specific functions to get the protein sequences from NCBI:\n\n\nCode\ndef fetch_protein_ids(gene_name):\n    \"\"\"Fetch protein IDs for a given gene name from NCBI.\"\"\"\n    handle = Entrez.esearch(db=\"protein\", term=gene_name)\n    record = Entrez.read(handle)\n    handle.close()\n    return record[\"IdList\"]\n\ndef fetch_protein_info(protein_id):\n    \"\"\"Fetch protein information for a given protein ID.\"\"\"\n    handle = Entrez.efetch(db=\"protein\", id=protein_id, rettype=\"gb\", retmode=\"text\")\n    record = SeqIO.read(handle, \"genbank\")\n    handle.close()\n    return record\n\n\n\nAlso, let’s save the aminoacids sequences to a fasta file:\n\n\nCode\n# List to store all protein records\nall_protein_records = []\n\nfor gene in gene_names:\n    protein_ids = fetch_protein_ids(gene)\n    proteins = [fetch_protein_info(pid) for pid in protein_ids]\n    all_protein_records.extend(proteins)\n\n# Write all protein sequences to a single FASTA file\nwith open(\"coffea_arabica_string_protein_sequences.fa\", \"w\") as output_handle:\n    SeqIO.write(all_protein_records, output_handle, \"fasta\")\n\nprint(\"All protein sequences have been saved to proteins.fasta\")\n\n\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\Bio\\Entrez\\__init__.py:723: UserWarning: \n            Email address is not specified.\n\n            To make use of NCBI's E-utilities, NCBI requires you to specify your\n            email address with each request.  As an example, if your email address\n            is A.N.Other@example.com, you can specify it as follows:\n               from Bio import Entrez\n               Entrez.email = 'A.N.Other@example.com'\n            In case of excessive usage of the E-utilities, NCBI will attempt to contact\n            a user at the email address provided before blocking access to the\n            E-utilities.\n  warnings.warn(\n\n\nAll protein sequences have been saved to proteins.fasta\n\n\nOnce we have the fasta file with all the proteins related to those genes, we need to create an interaction dataframe where we have all the possible pairwise interactions between these proteins. And , save those in a tsv file.\n\n\nCode\nimport csv\nfrom Bio import SeqIO\nfrom itertools import combinations\n\n# Read protein sequences from the FASTA file\nfasta_file = \"coffea_arabica_string_protein_sequences.fa\"\nprotein_ids = [record.id for record in SeqIO.parse(fasta_file, \"fasta\")]\n\n# Generate all pairwise combinations of protein IDs\npairwise_combinations = combinations(protein_ids, 2)\n\n# Save the pairwise combinations to a CSV file\ncsv_file = \"coffea_arabica_string_interactions.tsv\"\nwith open(csv_file, mode='w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow([\"Protein1\", \"Protein2\"])  # Write header\n    for protein1, protein2 in pairwise_combinations:\n        writer.writerow([protein1, protein2])\n\nprint(f\"Pairwise combinations saved to {csv_file}\")\n\n\nPairwise combinations saved to coffea_arabica_string_interactions.tsv\n\n\nAlso I manually zip the .tsv and the .fasta file."
  },
  {
    "objectID": "posts/proteinbert_coffea_arabica_thesis/aplication_to_coffea_arabica_thesis.html#embed-protein-sequences",
    "href": "posts/proteinbert_coffea_arabica_thesis/aplication_to_coffea_arabica_thesis.html#embed-protein-sequences",
    "title": "Evaluating ProteinBERT-GraphSAGE",
    "section": "Embed Protein Sequences",
    "text": "Embed Protein Sequences\nNow that we have the necesary data to run the model, we need to get the embedding from the aminoacids sequences using ProteinBERT.\n\n\nCode\nfrom proteinbert import load_pretrained_model\nfrom proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\nimport tensorflow as tf\n\n\nLoad the .tsv file:\n\n\nCode\nwith zipfile.ZipFile(\"coffea_arabica_string_interactions.zip\", 'r') as z:\n        \n    file_names = z.namelist()\n                    \n    tsv_files = [file for file in file_names if file.endswith('interactions.tsv')]\n\n    for tsv_file in tsv_files:\n        with z.open(tsv_file) as f:\n            df = pd.read_csv(f, sep=',')\n\n\nGet the unique protein IDs:\n\n\nCode\nunique_proteins = set(df[\"Protein1\"]).union(set(df[\"Protein2\"]))\n\n# Count the number of unique protein names\nnum_unique_proteins = len(unique_proteins)\nprint(f\"Number of unique proteins: {num_unique_proteins}\")\n\n\nNumber of unique proteins: 28\n\n\nAlso, read the protein sequences from the fasta file:\n\n\nCode\ndef _read_proteins_from_fasta(fasta_file):\n\n        protein_dict = {}\n        for record in SeqIO.parse(fasta_file, \"fasta\"):\n            protein_dict[record.id] = str(record.seq)\n        return protein_dict\n\n\n\n\nCode\nwith zipfile.ZipFile(\"coffea_arabica_string_interactions.zip\", 'r') as z:\n    \n    file_names = z.namelist()\n                    \n    tsv_files = [file for file in file_names if file.endswith('protein_sequences.fa')]\n\n    for tsv_file in tsv_files:\n        with z.open(tsv_file) as f:\n            f_text = io.TextIOWrapper(f)\n            protein_sequences_dict = _read_proteins_from_fasta(f_text)\n\n\n\n\nCode\nprotein_sequences_dict\n\n\n{'XP_027084939.1': 'MDVRLLGLDAPLVNALHHLIDAADDGDKIANAPTRTYVRDAKAMAATPADVKEYPNSYVFVVDMPGLKSGDIKVQVEDDNVLVVSGERKREEEKEGARYVRMERRVGKFMRKFVLPENANTDAISAVCQDGVLTVTVHKLPPPEPKKPKVVEVKIV',\n 'XP_027070567.1': 'MALIPKLFGDMLAPSGLSDETKGIVNARVDWKETPEAHVFKVDLPGLKKEEVKIEVEDGRVLAISGEGAAEKEDKNDKWHRVERSRGRFIRKFLLPENAKVEEVKANMEYGVLTVTIPKQEVKKPEVRAIEISG',\n 'XP_027066556.1': 'MALIPKLFGDMLAPSGLSDETKGMVNARVDWKETPEAHVFKVDLPGLKKEEVKVEVEDGRVLAISGERAAEKEDKNDKWHRVERSRGRFTRKFLLPENAKXEEVKANMEYGVLTVTIPKQEVKKPEVRAIEISG',\n 'XP_027084938.1': 'MDVRLLGLDAPLVNALHHLIDAADDGDKIANAPTRTYVRDAKAMAATPADVKEYPNSYVFVVDMPGLKSGDIKVQVEDDNVLVVSGERKREEEKEGARYVRMERRVSKFMRKFVLPENANTDAISAVCQDGVLTVTVHKLPPPEPKKPKVVEVKIA',\n 'XP_027085429.1': 'MDVRLLGLDAPLVNALHHLIDAADDGDKIANAPTRTYVRDAKAMAATPADVKEYPNSYVFIVDMPGLKSGDIKVQVEDDNVLVVSGERKRAEEKEGARYVRMERRVGKFMRKFVLPENANTDAISAVCQDGVLTVTVHKLPPPEPKKPKVIEVKIV',\n 'XP_027084168.1': 'MDVRLMGWDTPLFQTIQHMMDATDDADKTVNAPSRTYVRDTKAMASTPADVKEYPNSYAFIVDMPGLKSGDIKVQVEEDNVLIISGERKREEEKEGAKYVRMERRVGKFMRKFVLPENANTDAISAVCQDGVLTVTVQKLPPPEPKKAKTIQVQIA',\n 'XP_027089120.1': 'MSLIPSFFGNRRSSIFDPFPSDVWDPFRDISLPSSFSGETSSFVIARVDWKETPEAHVFKADLPGIKKEEVKVEVDDDRVLQIRGERNVEKEDKNDTWHRVERSSGQFMRRFRLPENAKMDQIKAAMENGVLTITIPKEEAKKTDVKAIQISG',\n 'XP_027098388.1': 'MSLIPSVFGGRRSNVFDPFSLDIWDPFEGFPFSNTSLANVPDTARDTSAFATARIDWKETPEAHVFKADLPGLKKEEVKVEVEEGQVLQISGERSREQEEKNDKWHRVERSSGRFLRRFRLPENAKVDQVKASMENGVLTVTVPKEEVKKADVKAIEISG',\n 'XP_027110885.1': 'MSLIPSIFGGRRSNVFDPFSLDIWDSFPFSDASLANVPNTARETSAFASARIDWKETPEAHVFKADLPGLKKEEVKVEVEDGRVLQISGERSREQEEKNDKWHRIERSSGKFLRRFRLPENAKLDQVKAGMENGVLTITVPKEQVKKPGVKAIEISG',\n 'XP_027096450.1': 'MSLIPSVFGGRRSNVFDPFSLDIWDPFEGFPFSNTSLANVPDTARDTSAFATARIDWKETPEAHVFKADLPGLKKEEVKVEVEEGRVLQISGERSREQEEKNDKWHRVERSSGRFLRRFRLPENAKVDQVKASMENGVLTVTVPKEEVKKSDVKAIEISG',\n 'XP_027113320.1': 'MVKATRFVFMSLLVLAAVAALLPEQAEALMPYSPRSFWDMMLPNEDPFRILEHSPLTVPKGVETLALARADWKETAKEHVISLDVPGIKKEEVKIEVEDNRVLRVSGERKTEEEVEGDTWHRAERTVGKFWRQFRLPGNADLDKVQAHLENGVLEIVVPKLAGEKKKQPKVISIAEEAGSNTGVDVKAQRDEM',\n 'XP_027109657.1': 'MSLIPSFFGNRRSSIFDPFPSDVWDPFRDISLPSSFAGETSSFVNARVDWKETPEAHVFKADLPGIKKEEVKVEVEDDRVLQIRGERNVEKEDKNDTWHRVERSSGQFMRRFRLPENAKMDQIKAAMENGVLTITIPKEEAKKTDVRAIQISG',\n 'XP_027084891.1': 'MDVRLMGWDTPLFQTIQHMMDAADDADKTVNAPSRTFVRDAKAMASTPADVKEYPNSYAFIVDMPGLKSGDIKVQVEEDNVLIISGERKREEEKEGAKYVRMERRVGKFMRKFALPENANTDAISAVCQDGVLTVTVQKLPPPEPKKAKTIQVQIA',\n 'XP_027110886.1': 'MALVPSIFGGRRSNIFDPFSLDIWDPFEGFPFSRTLANFPSGTDRETAVFTNARVDWRETPEAHIVQADLPGLKKEEVKVEVEDGRILKISGERSREQEEKTDTWHRVERSSGKFIRSFRMPENAKTEEIKASMENGVLTVTVPKVEEKKPEVKAIKISG',\n 'XP_027121387.1': 'MALARLALKNLQQRVAPASSSLPSFQCASERTVNSVQKRRWGSELLRRISSAAGKEDSAGQQVAVSEGGKKSNKLFPKKKQRSSLWKKEDDNYPPPLWEFFPSGLGNSLVQASENINRLLGNLSPSRLLGKFKEQDDLYKLRLPVPGLAKEDVKVTVDDGVLTIKGERKEEEEGSDEDDHWASFYGYYNTSVLLPDDAKVDEIRAEMKDGVLTVVIPRTDRPKKDVKEISVH',\n 'XP_027084272.1': 'MRWEIRSKSCIDHFLMRWEVRSKSCLPSLTTKCDKLLQVVSRRVHSFEPLGMDLRNLGMDIGGMGFGIDNPILSTIQDMLELSEEHDKGNQNNPSRAYVRDAKAMARTPADIKEYPDSYALVVDMPGIKANEIKVQVEDDNVLVVSGERKREKEEGVKYLKMERRGGKSMRKFVLPENANLDAISAVSRDGVLTVTVQKFPPPQAKKHKTIEVKAG',\n 'XP_027122722.1': 'MSTVVEAINHLFNFPETLDKFMLNSSSRAGEGAGSVANDSRGGVGSLPAVDILDSPKAYVFYVDVPGLSKSDIQVTLEDENTLVIRSNGKRKREDGEEEGCKYIRLERSAPQKLSRKFRLPDNANASAISANCENGVLTVAVEKLPPPPKSKTVQVAIS',\n 'XP_027125186.1': 'MSTVVEAINHLFNFPETLDKFLLNSSSRAGEGAGSVANDSRGGVGSLPAVDILDSPKAYVFYVDVPGLSKSDIQVTLEDENTLVIRSNGKRKREDGEEEGCKYIRLERSAPQKLSRKFRLPDNANASAISANCENGVLTVAVEKLPPPPKSKTVQVAIS',\n 'XP_027089887.1': 'MSVFPLQSMLLNTFSSESSCCSMDWKETPEAHVFKFDLPGLTKEDVKVQIHDNQVLHLSADRKDEDNQETGESDDRKRGGGGGGEYKWHCKERICGGSFQREFRLPEDALVDQIKASMSDGVLVVTVPKDHHLKKKKLKHGAVEISGVDGRNDAFSPKGFVRFVCCKA',\n 'XP_027074077.1': 'MALFGDPFRRFFWSPTIYRTSPGSSALLDWIESPDAHIFKINVPGFSKDEIKVQVEEGNVLVIKAEAKEEGGGQGKEKDVVWHVAERGGGITGKAAGFSREIELPEDVKADQIRASVENGVLTVVVPKDTTPKSSKVRNVNVTSKL',\n 'XP_027077852.1': 'MALFGDPFRRFFWSPTIYRTSPGSSALLDWIESPDAHIFKINVPGFSKDEIKVQVEEGNVLVIKAEAKEEGGGQGKEKDVVWHVAERGGGITGKAAGFSREIELPEDVKADQIRASVENGVLTVVVPKDTTPKSSKVRNVNVTSKL',\n 'XP_027108429.1': 'MITLVMFILWTSLLSDYKYQSLNPPFSSTSNRKQYQFLPVQLILAFELSLLGHILHTTKMSLIPSFFGGRKTNVFDPFSLDIWDPFDGFFVTSPSVANWPSSARETAAVATARIDWKETPEAHVFKADVPGLKKEELKVEVEEGRILQISGERSKEQEEKNDKWHRSERRRGKFLRRFRLPENAKVEEVKASLEDGVLTVTVPKVEEKKPEVKSIEISA',\n 'XP_027105380.1': 'MGVDYYKILQVDKSAKDEDLKKAYRKLAMKWHPDKNPNNKKEAEAKFKQISEAYEVLSDPEKRAIYDQYGEEGLKGQVPPPGAGGPGRATFFQTGDGPNVFRFNPRNANDIFDEFFGFSTPFGGMGGAGGMNGGGTRFPSSMFGDDIFSSFGEGRTMNSVPWKAPPIEQNLPCSLEELSKGTTKKMKISREIADASGKTLPVQEILTIDIKPGWKKGTKITFPEKGNEQPNVIPSDLVFIIDEKPHSVFKRDGNDLVVTQKISLAEALTGCTVHLTTLDGRKLTVPINAPIHPDYEEVVPREGMPIPKEPSKRGNLRIKFNIKFPTGLTAEQKSGIKKLLSP',\n 'XP_027063211.1': 'MITLVMFILWTSLLSDYKYQSLNPPFSSTSNRKRYQFLPVQLILAFELSLLGHILHTTKMSLIPSFFGGRKTNVFDPFSLDIWDPFDGFFVTSPSVANWPSSARETAAFATARIDWKETPEAHVFKADVPGLKKEELKVEVEEGRILQISGERSKEQEEKNDKWYRSERSSGKFLRRFRLPENAKVEEVKASLEDGVLTVTVPKVEEKKPEVKSIEISA',\n 'XP_027062161.1': 'MGLDYYKILGVDKKATDDDMKKAYRKLAMKWHPDKNPNNKKDAEAKFKQISEAYDVLSDPQKRAVYDQYGEEGLKAGVPPPDTAGGPGGTTFFSTGGGPTSFRFNPRSPDDIFSEIFGFSGFGGMGGGSGMRGSRFGGMFDDSMFSSFEGGGSGPGGSMHQQAIRKAPAIEQNLPCTLEELYKGTTKKMKISREVLDTNSGKIMPVEEILTINIKPGWKKGTKITFPDKGNELPGVAPADLVFIIDEKPHRVFTREGNDLIVTQKVSLTEALTGYTAHLTTLDGRNLTIPVTSVIHPTYEEVVRGEGMPLPKDPSKKGNLRIKFDIKFPARLTASQKAGIKELLGS',\n 'XP_027110883.1': 'MSMVPSFFGRRSSTPDEIWDPFQGWPFNSDFSPFSGQLRTTFPSSSSETASFAHASIDWKETPNAHVFKADVPGLRKEEVKVEVEDERILQISGERKREIEDKGHTWHKVERSSGKFMRRFRLPENAKVEQVKASMENGVLTVTVPKAEIRKPDVKSIEISG',\n 'XP_027065019.1': 'MGLDYYKILGVDKKATDDDMKKAYRKLAMKWHPDKNPNNKKDAEAKFKQISEAYDVLSDPQKRAVYDQYGEEGLKGGVPPPDTAGGPGSATFFSTGGGPTSFRFNPRSPDDIFSEIFGFSGFGGMGGGSGMRGSRFGGMFDDSMFSSFEGGGSGPGGSMHQQTIRKAPAIEQNLPCTLEELYKGTTKKMKISREVLDTNSGKIMPVEEILTINIKPGWKKGTKITFPDKGNELPGVAPADLVFIIDEKPHRVFTREGNDLIVTQKVSLTEALTGYTAHLTTLDGRNLTIPVTSVIHPTYEEVVRGEGMPLPKDPSKKGNLRIKFDIKFPARLTASQKAGIKELLGS',\n 'XP_027095883.1': 'MSLIPSVFGGRRSNVFDPFSLDIWDPFEGFPFSNTSLANVPDTARDTSAFATARIDWKETPEAHVFKADLPGLKKEEVKVEVEEGRVLQISGERSREQEEKNDKWHRVERSSGRFLRRFRLPENAKVDQVKASMENGVLTVTVPKEEVKKSDVKAIEISG'}\n\n\n\n\nCode\nunique_proteins = set(df['Protein1']).union(set(df['Protein2']))\n\n\nThis is to mbe sure that we have all the aminoacids sequences that are avaialble on the .tsv file:\n\n\nCode\nfiltered_protein_dict = {protein: seq for protein, seq in protein_sequences_dict.items() if protein in unique_proteins}\nfiltered_protein_dict\n\n\n{'XP_027084939.1': 'MDVRLLGLDAPLVNALHHLIDAADDGDKIANAPTRTYVRDAKAMAATPADVKEYPNSYVFVVDMPGLKSGDIKVQVEDDNVLVVSGERKREEEKEGARYVRMERRVGKFMRKFVLPENANTDAISAVCQDGVLTVTVHKLPPPEPKKPKVVEVKIV',\n 'XP_027070567.1': 'MALIPKLFGDMLAPSGLSDETKGIVNARVDWKETPEAHVFKVDLPGLKKEEVKIEVEDGRVLAISGEGAAEKEDKNDKWHRVERSRGRFIRKFLLPENAKVEEVKANMEYGVLTVTIPKQEVKKPEVRAIEISG',\n 'XP_027066556.1': 'MALIPKLFGDMLAPSGLSDETKGMVNARVDWKETPEAHVFKVDLPGLKKEEVKVEVEDGRVLAISGERAAEKEDKNDKWHRVERSRGRFTRKFLLPENAKXEEVKANMEYGVLTVTIPKQEVKKPEVRAIEISG',\n 'XP_027084938.1': 'MDVRLLGLDAPLVNALHHLIDAADDGDKIANAPTRTYVRDAKAMAATPADVKEYPNSYVFVVDMPGLKSGDIKVQVEDDNVLVVSGERKREEEKEGARYVRMERRVSKFMRKFVLPENANTDAISAVCQDGVLTVTVHKLPPPEPKKPKVVEVKIA',\n 'XP_027085429.1': 'MDVRLLGLDAPLVNALHHLIDAADDGDKIANAPTRTYVRDAKAMAATPADVKEYPNSYVFIVDMPGLKSGDIKVQVEDDNVLVVSGERKRAEEKEGARYVRMERRVGKFMRKFVLPENANTDAISAVCQDGVLTVTVHKLPPPEPKKPKVIEVKIV',\n 'XP_027084168.1': 'MDVRLMGWDTPLFQTIQHMMDATDDADKTVNAPSRTYVRDTKAMASTPADVKEYPNSYAFIVDMPGLKSGDIKVQVEEDNVLIISGERKREEEKEGAKYVRMERRVGKFMRKFVLPENANTDAISAVCQDGVLTVTVQKLPPPEPKKAKTIQVQIA',\n 'XP_027089120.1': 'MSLIPSFFGNRRSSIFDPFPSDVWDPFRDISLPSSFSGETSSFVIARVDWKETPEAHVFKADLPGIKKEEVKVEVDDDRVLQIRGERNVEKEDKNDTWHRVERSSGQFMRRFRLPENAKMDQIKAAMENGVLTITIPKEEAKKTDVKAIQISG',\n 'XP_027098388.1': 'MSLIPSVFGGRRSNVFDPFSLDIWDPFEGFPFSNTSLANVPDTARDTSAFATARIDWKETPEAHVFKADLPGLKKEEVKVEVEEGQVLQISGERSREQEEKNDKWHRVERSSGRFLRRFRLPENAKVDQVKASMENGVLTVTVPKEEVKKADVKAIEISG',\n 'XP_027110885.1': 'MSLIPSIFGGRRSNVFDPFSLDIWDSFPFSDASLANVPNTARETSAFASARIDWKETPEAHVFKADLPGLKKEEVKVEVEDGRVLQISGERSREQEEKNDKWHRIERSSGKFLRRFRLPENAKLDQVKAGMENGVLTITVPKEQVKKPGVKAIEISG',\n 'XP_027096450.1': 'MSLIPSVFGGRRSNVFDPFSLDIWDPFEGFPFSNTSLANVPDTARDTSAFATARIDWKETPEAHVFKADLPGLKKEEVKVEVEEGRVLQISGERSREQEEKNDKWHRVERSSGRFLRRFRLPENAKVDQVKASMENGVLTVTVPKEEVKKSDVKAIEISG',\n 'XP_027113320.1': 'MVKATRFVFMSLLVLAAVAALLPEQAEALMPYSPRSFWDMMLPNEDPFRILEHSPLTVPKGVETLALARADWKETAKEHVISLDVPGIKKEEVKIEVEDNRVLRVSGERKTEEEVEGDTWHRAERTVGKFWRQFRLPGNADLDKVQAHLENGVLEIVVPKLAGEKKKQPKVISIAEEAGSNTGVDVKAQRDEM',\n 'XP_027109657.1': 'MSLIPSFFGNRRSSIFDPFPSDVWDPFRDISLPSSFAGETSSFVNARVDWKETPEAHVFKADLPGIKKEEVKVEVEDDRVLQIRGERNVEKEDKNDTWHRVERSSGQFMRRFRLPENAKMDQIKAAMENGVLTITIPKEEAKKTDVRAIQISG',\n 'XP_027084891.1': 'MDVRLMGWDTPLFQTIQHMMDAADDADKTVNAPSRTFVRDAKAMASTPADVKEYPNSYAFIVDMPGLKSGDIKVQVEEDNVLIISGERKREEEKEGAKYVRMERRVGKFMRKFALPENANTDAISAVCQDGVLTVTVQKLPPPEPKKAKTIQVQIA',\n 'XP_027110886.1': 'MALVPSIFGGRRSNIFDPFSLDIWDPFEGFPFSRTLANFPSGTDRETAVFTNARVDWRETPEAHIVQADLPGLKKEEVKVEVEDGRILKISGERSREQEEKTDTWHRVERSSGKFIRSFRMPENAKTEEIKASMENGVLTVTVPKVEEKKPEVKAIKISG',\n 'XP_027121387.1': 'MALARLALKNLQQRVAPASSSLPSFQCASERTVNSVQKRRWGSELLRRISSAAGKEDSAGQQVAVSEGGKKSNKLFPKKKQRSSLWKKEDDNYPPPLWEFFPSGLGNSLVQASENINRLLGNLSPSRLLGKFKEQDDLYKLRLPVPGLAKEDVKVTVDDGVLTIKGERKEEEEGSDEDDHWASFYGYYNTSVLLPDDAKVDEIRAEMKDGVLTVVIPRTDRPKKDVKEISVH',\n 'XP_027084272.1': 'MRWEIRSKSCIDHFLMRWEVRSKSCLPSLTTKCDKLLQVVSRRVHSFEPLGMDLRNLGMDIGGMGFGIDNPILSTIQDMLELSEEHDKGNQNNPSRAYVRDAKAMARTPADIKEYPDSYALVVDMPGIKANEIKVQVEDDNVLVVSGERKREKEEGVKYLKMERRGGKSMRKFVLPENANLDAISAVSRDGVLTVTVQKFPPPQAKKHKTIEVKAG',\n 'XP_027122722.1': 'MSTVVEAINHLFNFPETLDKFMLNSSSRAGEGAGSVANDSRGGVGSLPAVDILDSPKAYVFYVDVPGLSKSDIQVTLEDENTLVIRSNGKRKREDGEEEGCKYIRLERSAPQKLSRKFRLPDNANASAISANCENGVLTVAVEKLPPPPKSKTVQVAIS',\n 'XP_027125186.1': 'MSTVVEAINHLFNFPETLDKFLLNSSSRAGEGAGSVANDSRGGVGSLPAVDILDSPKAYVFYVDVPGLSKSDIQVTLEDENTLVIRSNGKRKREDGEEEGCKYIRLERSAPQKLSRKFRLPDNANASAISANCENGVLTVAVEKLPPPPKSKTVQVAIS',\n 'XP_027089887.1': 'MSVFPLQSMLLNTFSSESSCCSMDWKETPEAHVFKFDLPGLTKEDVKVQIHDNQVLHLSADRKDEDNQETGESDDRKRGGGGGGEYKWHCKERICGGSFQREFRLPEDALVDQIKASMSDGVLVVTVPKDHHLKKKKLKHGAVEISGVDGRNDAFSPKGFVRFVCCKA',\n 'XP_027074077.1': 'MALFGDPFRRFFWSPTIYRTSPGSSALLDWIESPDAHIFKINVPGFSKDEIKVQVEEGNVLVIKAEAKEEGGGQGKEKDVVWHVAERGGGITGKAAGFSREIELPEDVKADQIRASVENGVLTVVVPKDTTPKSSKVRNVNVTSKL',\n 'XP_027077852.1': 'MALFGDPFRRFFWSPTIYRTSPGSSALLDWIESPDAHIFKINVPGFSKDEIKVQVEEGNVLVIKAEAKEEGGGQGKEKDVVWHVAERGGGITGKAAGFSREIELPEDVKADQIRASVENGVLTVVVPKDTTPKSSKVRNVNVTSKL',\n 'XP_027108429.1': 'MITLVMFILWTSLLSDYKYQSLNPPFSSTSNRKQYQFLPVQLILAFELSLLGHILHTTKMSLIPSFFGGRKTNVFDPFSLDIWDPFDGFFVTSPSVANWPSSARETAAVATARIDWKETPEAHVFKADVPGLKKEELKVEVEEGRILQISGERSKEQEEKNDKWHRSERRRGKFLRRFRLPENAKVEEVKASLEDGVLTVTVPKVEEKKPEVKSIEISA',\n 'XP_027105380.1': 'MGVDYYKILQVDKSAKDEDLKKAYRKLAMKWHPDKNPNNKKEAEAKFKQISEAYEVLSDPEKRAIYDQYGEEGLKGQVPPPGAGGPGRATFFQTGDGPNVFRFNPRNANDIFDEFFGFSTPFGGMGGAGGMNGGGTRFPSSMFGDDIFSSFGEGRTMNSVPWKAPPIEQNLPCSLEELSKGTTKKMKISREIADASGKTLPVQEILTIDIKPGWKKGTKITFPEKGNEQPNVIPSDLVFIIDEKPHSVFKRDGNDLVVTQKISLAEALTGCTVHLTTLDGRKLTVPINAPIHPDYEEVVPREGMPIPKEPSKRGNLRIKFNIKFPTGLTAEQKSGIKKLLSP',\n 'XP_027063211.1': 'MITLVMFILWTSLLSDYKYQSLNPPFSSTSNRKRYQFLPVQLILAFELSLLGHILHTTKMSLIPSFFGGRKTNVFDPFSLDIWDPFDGFFVTSPSVANWPSSARETAAFATARIDWKETPEAHVFKADVPGLKKEELKVEVEEGRILQISGERSKEQEEKNDKWYRSERSSGKFLRRFRLPENAKVEEVKASLEDGVLTVTVPKVEEKKPEVKSIEISA',\n 'XP_027062161.1': 'MGLDYYKILGVDKKATDDDMKKAYRKLAMKWHPDKNPNNKKDAEAKFKQISEAYDVLSDPQKRAVYDQYGEEGLKAGVPPPDTAGGPGGTTFFSTGGGPTSFRFNPRSPDDIFSEIFGFSGFGGMGGGSGMRGSRFGGMFDDSMFSSFEGGGSGPGGSMHQQAIRKAPAIEQNLPCTLEELYKGTTKKMKISREVLDTNSGKIMPVEEILTINIKPGWKKGTKITFPDKGNELPGVAPADLVFIIDEKPHRVFTREGNDLIVTQKVSLTEALTGYTAHLTTLDGRNLTIPVTSVIHPTYEEVVRGEGMPLPKDPSKKGNLRIKFDIKFPARLTASQKAGIKELLGS',\n 'XP_027110883.1': 'MSMVPSFFGRRSSTPDEIWDPFQGWPFNSDFSPFSGQLRTTFPSSSSETASFAHASIDWKETPNAHVFKADVPGLRKEEVKVEVEDERILQISGERKREIEDKGHTWHKVERSSGKFMRRFRLPENAKVEQVKASMENGVLTVTVPKAEIRKPDVKSIEISG',\n 'XP_027065019.1': 'MGLDYYKILGVDKKATDDDMKKAYRKLAMKWHPDKNPNNKKDAEAKFKQISEAYDVLSDPQKRAVYDQYGEEGLKGGVPPPDTAGGPGSATFFSTGGGPTSFRFNPRSPDDIFSEIFGFSGFGGMGGGSGMRGSRFGGMFDDSMFSSFEGGGSGPGGSMHQQTIRKAPAIEQNLPCTLEELYKGTTKKMKISREVLDTNSGKIMPVEEILTINIKPGWKKGTKITFPDKGNELPGVAPADLVFIIDEKPHRVFTREGNDLIVTQKVSLTEALTGYTAHLTTLDGRNLTIPVTSVIHPTYEEVVRGEGMPLPKDPSKKGNLRIKFDIKFPARLTASQKAGIKELLGS',\n 'XP_027095883.1': 'MSLIPSVFGGRRSNVFDPFSLDIWDPFEGFPFSNTSLANVPDTARDTSAFATARIDWKETPEAHVFKADLPGLKKEEVKVEVEEGRVLQISGERSREQEEKNDKWHRVERSSGRFLRRFRLPENAKVDQVKASMENGVLTVTVPKEEVKKSDVKAIEISG'}\n\n\nTo run ProteinBERT, we need to get the longest sequence:\n\n\nCode\nsequences = list(filtered_protein_dict.values())\nlongest_sequence_length = max(len(seq) for seq in sequences)\nlongest_sequence_length\n\n\n346\n\n\n\n\nCode\nseq_len = longest_sequence_length+2\nglobal_embeds = []\nlocal_embeds = []\nbatch_size = 2\n\n\nLet’s define a function that helps us get the embeddings:\n\n\nCode\ndef _get_embeddings(seq, seq_len=512, batch_size=1):\n\n    pretrained_model_generator, input_encoder = load_pretrained_model()\n    model = get_model_with_hidden_layers_as_outputs(pretrained_model_generator.create_model(seq_len=seq_len))\n    encoded_x = input_encoder.encode_X(seq, seq_len)\n    local_representations, global_representations = model.predict(encoded_x, batch_size=batch_size)\n\n    return local_representations, global_representations\n\n\nAnd use it for all the proteins:\n\n\nCode\nfor i in range(0, len(sequences), batch_size):\n\n    batch_seqs = sequences[i:i + batch_size]\n    local_representation, global_representation = _get_embeddings(batch_seqs, seq_len=seq_len, batch_size=batch_size)\n    global_embeds.extend(global_representation)\n    local_embeds.extend(local_representation)\n                \nglobal_embeds = np.array(global_embeds)\nlocal_embeds = np.array(local_embeds)\n\n\nWARNING:tensorflow:From c:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\keras-3.3.3-py3.10.egg\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\nWARNING:tensorflow:5 out of the last 5 calls to &lt;function TensorFlowTrainer.make_predict_function.&lt;locals&gt;.one_step_on_data_distributed at 0x0000029623428EE0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\nWARNING:tensorflow:6 out of the last 6 calls to &lt;function TensorFlowTrainer.make_predict_function.&lt;locals&gt;.one_step_on_data_distributed at 0x0000029623444EE0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n\n\n\n\nCode\nprint(global_embeds.shape)\nprint(global_embeds.shape)\n\n\n(28, 15599)\n(28, 15599)\n\n\nNow that we have the embedings, we need to create the edge_index to create a pytorch geometric Data object.\nFirst, we need to encode the protein ID’s:\n\n\nCode\nfrom sklearn import model_selection, metrics, preprocessing\n\nunique_proteins_set = set(df[\"Protein1\"]).union(set(df[\"Protein2\"]))\nall_proteins = list(unique_proteins_set)\nprint(f\"All unique proteins: {all_proteins}\")\n\nnum_unique_proteins = len(all_proteins)\nprint(f\"Number of unique proteins: {num_unique_proteins}\")\nprint(f\"Unique proteins: {all_proteins}\")\n\n# Fit the LabelEncoder on all unique proteins\nlbl_protein = preprocessing.LabelEncoder()\nlbl_protein.fit(all_proteins)\n\n# Verify the number of classes\nnum_classes = len(lbl_protein.classes_)\nprint(f\"Number of classes in LabelEncoder: {num_classes}\")\nprint(f\"Classes: {lbl_protein.classes_}\")\n\n# Check if there is any discrepancy\nif num_classes != num_unique_proteins:\n    missing_proteins = unique_proteins_set - set(lbl_protein.classes_)\n    print(f\"Missing proteins in LabelEncoder: {missing_proteins}\")\n\n\nAll unique proteins: ['XP_027110886.1', 'XP_027089887.1', 'XP_027089120.1', 'XP_027110885.1', 'XP_027110883.1', 'XP_027077852.1', 'XP_027098388.1', 'XP_027074077.1', 'XP_027084168.1', 'XP_027113320.1', 'XP_027065019.1', 'XP_027084891.1', 'XP_027095883.1', 'XP_027109657.1', 'XP_027096450.1', 'XP_027085429.1', 'XP_027084939.1', 'XP_027066556.1', 'XP_027084272.1', 'XP_027084938.1', 'XP_027070567.1', 'XP_027121387.1', 'XP_027108429.1', 'XP_027122722.1', 'XP_027125186.1', 'XP_027062161.1', 'XP_027105380.1', 'XP_027063211.1']\nNumber of unique proteins: 28\nUnique proteins: ['XP_027110886.1', 'XP_027089887.1', 'XP_027089120.1', 'XP_027110885.1', 'XP_027110883.1', 'XP_027077852.1', 'XP_027098388.1', 'XP_027074077.1', 'XP_027084168.1', 'XP_027113320.1', 'XP_027065019.1', 'XP_027084891.1', 'XP_027095883.1', 'XP_027109657.1', 'XP_027096450.1', 'XP_027085429.1', 'XP_027084939.1', 'XP_027066556.1', 'XP_027084272.1', 'XP_027084938.1', 'XP_027070567.1', 'XP_027121387.1', 'XP_027108429.1', 'XP_027122722.1', 'XP_027125186.1', 'XP_027062161.1', 'XP_027105380.1', 'XP_027063211.1']\nNumber of classes in LabelEncoder: 28\nClasses: ['XP_027062161.1' 'XP_027063211.1' 'XP_027065019.1' 'XP_027066556.1'\n 'XP_027070567.1' 'XP_027074077.1' 'XP_027077852.1' 'XP_027084168.1'\n 'XP_027084272.1' 'XP_027084891.1' 'XP_027084938.1' 'XP_027084939.1'\n 'XP_027085429.1' 'XP_027089120.1' 'XP_027089887.1' 'XP_027095883.1'\n 'XP_027096450.1' 'XP_027098388.1' 'XP_027105380.1' 'XP_027108429.1'\n 'XP_027109657.1' 'XP_027110883.1' 'XP_027110885.1' 'XP_027110886.1'\n 'XP_027113320.1' 'XP_027121387.1' 'XP_027122722.1' 'XP_027125186.1']\n\n\n\n\nCode\ndf[\"node1_string_id\"] = lbl_protein.transform(df.Protein1.values)\ndf[\"node2_string_id\"] = lbl_protein.transform(df.Protein2.values)\n\n# Verify the transformations\nprint(f\"Transformed Protein1: {df['node1_string_id'].unique()}\")\nprint(f\"Transformed Protein2: {df['node2_string_id'].unique()}\")\n\n\nTransformed Protein1: [11  4  3 10 12  7 13 17 22 16 24 20  9 23 25  8 26 27 14  5  6 19 18  1\n  0 21  2]\nTransformed Protein2: [ 4  3 10 12  7 13 17 22 16 24 20  9 23 25  8 26 27 14  5  6 19 18  1  0\n 21  2 15]\n\n\n\n\nCode\ndf\n\n\n\n\n\n\n\n\n\nProtein1\nProtein2\nnode1_string_id\nnode2_string_id\n\n\n\n\n0\nXP_027084939.1\nXP_027070567.1\n11\n4\n\n\n1\nXP_027084939.1\nXP_027066556.1\n11\n3\n\n\n2\nXP_027084939.1\nXP_027084938.1\n11\n10\n\n\n3\nXP_027084939.1\nXP_027085429.1\n11\n12\n\n\n4\nXP_027084939.1\nXP_027084168.1\n11\n7\n\n\n...\n...\n...\n...\n...\n\n\n373\nXP_027062161.1\nXP_027065019.1\n0\n2\n\n\n374\nXP_027062161.1\nXP_027095883.1\n0\n15\n\n\n375\nXP_027110883.1\nXP_027065019.1\n21\n2\n\n\n376\nXP_027110883.1\nXP_027095883.1\n21\n15\n\n\n377\nXP_027065019.1\nXP_027095883.1\n2\n15\n\n\n\n\n378 rows × 4 columns\n\n\n\nThen, with a helper function create the edge index:\n\n\nCode\nimport torch\n\ndef _load_edge_csv(df, src_index_col, dst_index_col):\n    src = df[src_index_col].values\n    dst = df[dst_index_col].values\n    edge_index = [src, dst]\n    return edge_index\n\n\n\n\nCode\nedge_index = _load_edge_csv(df=df, src_index_col=\"node1_string_id\", dst_index_col=\"node2_string_id\")\nedge_index = torch.LongTensor(edge_index)\n\n\nC:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_3324\\4265644366.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n  edge_index = torch.LongTensor(edge_index)\n\n\n\n\nCode\nedge_index\n\n\ntensor([[11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n         11, 11, 11, 11, 11, 11, 11, 11, 11,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,\n          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n          3,  3,  3,  3,  3,  3, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 12, 12, 12, 12, 12, 12,\n         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,  7,\n          7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n          7,  7,  7, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n         13, 13, 13, 13, 13, 13, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n         17, 17, 17, 17, 17, 17, 17, 17, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n         22, 22, 22, 22, 22, 22, 22, 22, 22, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n         16, 16, 16, 16, 16, 16, 16, 16, 16, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n         24, 24, 24, 24, 24, 24, 24, 24, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n         20, 20, 20, 20, 20, 20,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n          9,  9,  9, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 25,\n         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,  8,  8,  8,  8,  8,  8,\n          8,  8,  8,  8,  8,  8, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27,\n         27, 27, 27, 27, 27, 27, 27, 27, 27, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n          5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6, 19, 19, 19,\n         19, 19, 19, 18, 18, 18, 18, 18,  1,  1,  1,  1,  0,  0,  0, 21, 21,  2],\n        [ 4,  3, 10, 12,  7, 13, 17, 22, 16, 24, 20,  9, 23, 25,  8, 26, 27, 14,\n          5,  6, 19, 18,  1,  0, 21,  2, 15,  3, 10, 12,  7, 13, 17, 22, 16, 24,\n         20,  9, 23, 25,  8, 26, 27, 14,  5,  6, 19, 18,  1,  0, 21,  2, 15, 10,\n         12,  7, 13, 17, 22, 16, 24, 20,  9, 23, 25,  8, 26, 27, 14,  5,  6, 19,\n         18,  1,  0, 21,  2, 15, 12,  7, 13, 17, 22, 16, 24, 20,  9, 23, 25,  8,\n         26, 27, 14,  5,  6, 19, 18,  1,  0, 21,  2, 15,  7, 13, 17, 22, 16, 24,\n         20,  9, 23, 25,  8, 26, 27, 14,  5,  6, 19, 18,  1,  0, 21,  2, 15, 13,\n         17, 22, 16, 24, 20,  9, 23, 25,  8, 26, 27, 14,  5,  6, 19, 18,  1,  0,\n         21,  2, 15, 17, 22, 16, 24, 20,  9, 23, 25,  8, 26, 27, 14,  5,  6, 19,\n         18,  1,  0, 21,  2, 15, 22, 16, 24, 20,  9, 23, 25,  8, 26, 27, 14,  5,\n          6, 19, 18,  1,  0, 21,  2, 15, 16, 24, 20,  9, 23, 25,  8, 26, 27, 14,\n          5,  6, 19, 18,  1,  0, 21,  2, 15, 24, 20,  9, 23, 25,  8, 26, 27, 14,\n          5,  6, 19, 18,  1,  0, 21,  2, 15, 20,  9, 23, 25,  8, 26, 27, 14,  5,\n          6, 19, 18,  1,  0, 21,  2, 15,  9, 23, 25,  8, 26, 27, 14,  5,  6, 19,\n         18,  1,  0, 21,  2, 15, 23, 25,  8, 26, 27, 14,  5,  6, 19, 18,  1,  0,\n         21,  2, 15, 25,  8, 26, 27, 14,  5,  6, 19, 18,  1,  0, 21,  2, 15,  8,\n         26, 27, 14,  5,  6, 19, 18,  1,  0, 21,  2, 15, 26, 27, 14,  5,  6, 19,\n         18,  1,  0, 21,  2, 15, 27, 14,  5,  6, 19, 18,  1,  0, 21,  2, 15, 14,\n          5,  6, 19, 18,  1,  0, 21,  2, 15,  5,  6, 19, 18,  1,  0, 21,  2, 15,\n          6, 19, 18,  1,  0, 21,  2, 15, 19, 18,  1,  0, 21,  2, 15, 18,  1,  0,\n         21,  2, 15,  1,  0, 21,  2, 15,  0, 21,  2, 15, 21,  2, 15,  2, 15, 15]])\n\n\nI’m assigning a class to Coffea arabica\n\n\nCode\ny = torch.tensor([61], dtype=torch.long)\n\n\nWe have all the necesary to create the Data object:\n\n\nCode\nfrom torch_geometric.data import Dataset, download_url, extract_zip, Data\n\nglobal_embeds = torch.tensor(global_embeds, dtype=torch.float)\n\ndata = Data(x=global_embeds,edge_index=edge_index, y=y)\n\n\n\n\nCode\ndata\n\n\nData(x=[28, 15599], edge_index=[2, 378], y=[1])\n\n\n\n\nCode\nfrom torch_geometric.utils import to_networkx\n\nG = to_networkx(data=data)\n\nprint(G)\n\n\nDiGraph with 28 nodes and 378 edges\n\n\nWe can plot the network:\n\n\nCode\n%matplotlib inline\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# Visualization function for NX graph or PyTorch tensor\ndef visualize(h, color, epoch=None, loss=None, accuracy=None, node_size=300):\n    plt.figure(figsize=(7,7))\n    plt.xticks([])\n    plt.yticks([])\n\n    if torch.is_tensor(h):\n        h = h.detach().cpu().numpy()\n        plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n        if epoch is not None and loss is not None and accuracy['train'] is not None and accuracy['val'] is not None:\n            plt.xlabel((f'Epoch: {epoch}, Loss: {loss.item():.4f} \\n'\n                       f'Training Accuracy: {accuracy[\"train\"]*100:.2f}% \\n'\n                       f' Validation Accuracy: {accuracy[\"val\"]*100:.2f}%'),\n                       fontsize=16)\n    else:\n        nx.draw_networkx(h, pos=nx.spring_layout(h, seed=4572321), with_labels=False,\n                         node_color=color, cmap=\"Set2\", node_size=40, alpha=0.6)\n    plt.show()\n\n\n\n\nCode\nvisualize(G, color=\"cyan\")\n\n\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:437: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  node_collection = ax.scatter(\n\n\n\n\n\n\n\n\n\nEvery node in this network is connected to all the other nodes. This will change with the model predictions.\nLet’s see the 2-D dimentional reduction from the embeddings:\n\n\nCode\nfrom sklearn.manifold import TSNE\n\ntsne_components = TSNE(n_components=2, perplexity=5, init=\"pca\").fit_transform(data.x)\n\nplt.scatter(tsne_components[:,0], tsne_components[:,1],c=\"cyan\", cmap=\"tab20b\")\n\n\nC:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_3324\\233343671.py:5: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  plt.scatter(tsne_components[:,0], tsne_components[:,1],c=\"cyan\", cmap=\"tab20b\")"
  },
  {
    "objectID": "posts/proteinbert_coffea_arabica_thesis/aplication_to_coffea_arabica_thesis.html#using-model",
    "href": "posts/proteinbert_coffea_arabica_thesis/aplication_to_coffea_arabica_thesis.html#using-model",
    "title": "Evaluating ProteinBERT-GraphSAGE",
    "section": "Using Model",
    "text": "Using Model\n\n\nCode\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n\n\nCode\nfrom torch_geometric.nn import SAGEConv\n\nclass GNNStack(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, dropout, num_layers:int, emb=False):\n        super(GNNStack, self).__init__()\n\n        \n        self.dropout = dropout\n        self.num_layers = num_layers\n        self.emb = emb\n\n        self.convs = nn.ModuleList()\n\n        for layer in range(self.num_layers):\n            in_channels = input_dim if layer == 0 else hidden_dim\n            out_channels = hidden_dim \n\n            self.convs.append(SAGEConv(in_channels, out_channels, normalize=True))\n\n        self.post_mp = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.Dropout(self.dropout),\n            nn.Linear(hidden_dim, hidden_dim)\n        ) \n    \n\n    def forward(self, x, edge_index):\n        \n            \n        for i in range(self.num_layers):\n            x = self.convs[i](x, edge_index)\n            x = F.gelu(x)\n            x = F.dropout(x, p=self.dropout,training=self.training)\n        \n        x = self.post_mp(x)\n        \n\n        if self.emb == True:\n            return x\n            \n\n        return F.log_softmax(x, dim=1)\n\n    def loss(self, pred, label):\n        return F.nll_loss(pred, label)\n\n\n\n\nCode\nclass LinkPredictorHead(nn.Module):\n    def __init__(self, in_channels:int, hidden_channels:int, out_channels:int, n_layers:int,dropout_probabilty:float=0.3):\n        \"\"\"\n        Args:\n            in_channels (int):     Number of input features.\n            hidden_channels (int): Number of hidden features.\n            out_channels (int):    Number of output features.\n            n_layers (int):        Number of MLP layers.\n            dropout (float):       Dropout probability.\n            \"\"\"\n        super(LinkPredictorHead, self).__init__()\n        self.dropout_probabilty    = dropout_probabilty  # dropout probability\n        self.mlp_layers            = nn.ModuleList()     # ModuleList: is a list of modules\n        self.non_linearity         = F.relu              # non-linearity\n        \n        for i in range(n_layers - 1):                                 \n            if i == 0:\n                self.mlp_layers.append(nn.Linear(in_channels, hidden_channels))          # input layer (in_channels, hidden_channels)\n            else:\n                self.mlp_layers.append(nn.Linear(hidden_channels, hidden_channels))      # hidden layers (hidden_channels, hidden_channels)\n\n        self.mlp_layers.append(nn.Linear(hidden_channels, out_channels))                 # output layer (hidden_channels, out_channels)\n\n\n    def reset_parameters(self):\n        for mlp_layer in self.mlp_layers:\n            mlp_layer.reset_parameters()\n\n    def forward(self, x_i, x_j):\n\n        x = x_i * x_j                                                     # element-wise multiplication\n        for mlp_layer in self.mlp_layers[:-1]:                            # iterate over all layers except the last one\n            x = mlp_layer(x)                                              # apply linear transformation\n            x = self.non_linearity(x)                                     # Apply non linear activation function\n            x = F.dropout(x, p=self.dropout_probabilty,training=self.training)      # Apply dropout\n        x = self.mlp_layers[-1](x)                                        # apply linear transformation to the last layer\n        x = torch.sigmoid(x)                                              # apply sigmoid activation function to get the probability\n\n        return x\n\n\nLet’s load the model we trained before:\n\n\nCode\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ninput_dim = data.x.shape[1]\nhidden_dim = 1024\ndropout = 0.3\nnum_layers= 3\n\n\nmodel          = GNNStack(input_dim, hidden_dim, hidden_dim, dropout,num_layers, emb=True).to(device) # the graph neural network that takes all the node embeddings as inputs to message pass and agregate\nlink_predictor = LinkPredictorHead(hidden_dim, hidden_dim, 1, num_layers , dropout).to(device)\n\n\nbest_graphsage_model_path      = f\"GraphSage_epoch_{404}.pt\"\nbest_link_predictor_model_path =  f\"link_predictor_epoch_{404}.pt\"\n\nprint(f\"Loading best models:  {best_graphsage_model_path }  {best_link_predictor_model_path}\")\ncheckpoint = torch.load(best_graphsage_model_path, map_location=device)\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.eval()\n\ncheckpoint = torch.load(best_link_predictor_model_path, map_location=device)\nlink_predictor.load_state_dict(checkpoint['model_state_dict'])\nlink_predictor.eval()\n\n\nLoading best models:  GraphSage_epoch_404.pt  link_predictor_epoch_404.pt\n\n\nLinkPredictorHead(\n  (mlp_layers): ModuleList(\n    (0-1): 2 x Linear(in_features=1024, out_features=1024, bias=True)\n    (2): Linear(in_features=1024, out_features=1, bias=True)\n  )\n)\n\n\nNow, let’s update our ProteinBERT embeddings:\n\n\nCode\nx = torch.FloatTensor(data.x).to(device)\nedge_index = data.edge_index.to(device)\n\nembs = model(x, edge_index)\n\nembs.shape\n\n\ntorch.Size([28, 1024])\n\n\n\n\nCode\ntsne_components = TSNE(n_components=2, perplexity=27, init=\"pca\").fit_transform(embs.detach().cpu().numpy())\n\nplt.scatter(tsne_components[:,0], tsne_components[:,1],c=\"cyan\", cmap=\"tab20b\")\n\n\nC:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_3324\\1092476614.py:3: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  plt.scatter(tsne_components[:,0], tsne_components[:,1],c=\"cyan\", cmap=\"tab20b\")\n\n\n\n\n\n\n\n\n\nWe can see a similar behaviour to the graph we plotted before.\nNow, let’s pass those embedings to the LinkPredictorHead to get the probabilities of protein-protein interactions.\n\n\nCode\nimport itertools\n\ndef generate_pairs(num_embeddings):\n    pairs = itertools.combinations(range(num_embeddings), 2)\n    return list(pairs)\n\n\n\n\n\nCode\npairwise_combinations = generate_pairs(len(embs))\n\n\n\n\nCode\nresults = []\nwith torch.no_grad():  # Ensure no gradients are computed\n    for i, j in pairwise_combinations:\n        vec1 = embs[i].unsqueeze(0)  # Add batch dimension\n        vec2 = embs[j].unsqueeze(0)  # Add batch dimension\n        prediction = link_predictor(vec1, vec2).item()  # Convert to scalar\n        results.append((i, j, prediction))\n\n\n\n\nCode\nresults\n\n\n[(0, 1, 0.6516209244728088),\n (0, 2, 0.6353868246078491),\n (0, 3, 0.1549677550792694),\n (0, 4, 0.00240265647880733),\n (0, 5, 0.6596815586090088),\n (0, 6, 0.6366676688194275),\n (0, 7, 0.6536526679992676),\n (0, 8, 0.6611047387123108),\n (0, 9, 0.6263799667358398),\n (0, 10, 0.5428963303565979),\n (0, 11, 0.5935388207435608),\n (0, 12, 0.6135593056678772),\n (0, 13, 0.6762287616729736),\n (0, 14, 0.6489772796630859),\n (0, 15, 0.6287089586257935),\n (0, 16, 0.6755351424217224),\n (0, 17, 0.6885703802108765),\n (0, 18, 0.6545939445495605),\n (0, 19, 0.6656283736228943),\n (0, 20, 0.6443829536437988),\n (0, 21, 0.6490920186042786),\n (0, 22, 0.6958609223365784),\n (0, 23, 0.6536524295806885),\n (0, 24, 0.6821668744087219),\n (0, 25, 0.6490938067436218),\n (0, 26, 0.6867173910140991),\n (0, 27, 0.6356632113456726),\n (1, 2, 0.6407619118690491),\n (1, 3, 0.16379830241203308),\n (1, 4, 0.0026919585652649403),\n (1, 5, 0.663702130317688),\n (1, 6, 0.6410140991210938),\n (1, 7, 0.6575544476509094),\n (1, 8, 0.6650683283805847),\n (1, 9, 0.6302982568740845),\n (1, 10, 0.5495249032974243),\n (1, 11, 0.5960684418678284),\n (1, 12, 0.6183051466941833),\n (1, 13, 0.6807677149772644),\n (1, 14, 0.6529000401496887),\n (1, 15, 0.6348029375076294),\n (1, 16, 0.6794295310974121),\n (1, 17, 0.6925675272941589),\n (1, 18, 0.6591278314590454),\n (1, 19, 0.6698798537254333),\n (1, 20, 0.6476978063583374),\n (1, 21, 0.6544296145439148),\n (1, 22, 0.6998830437660217),\n (1, 23, 0.657951831817627),\n (1, 24, 0.6857574582099915),\n (1, 25, 0.6525057554244995),\n (1, 26, 0.6906378269195557),\n (1, 27, 0.6393598318099976),\n (2, 3, 0.1643204391002655),\n (2, 4, 0.002355146687477827),\n (2, 5, 0.6558791399002075),\n (2, 6, 0.6311058402061462),\n (2, 7, 0.6712092161178589),\n (2, 8, 0.6630185842514038),\n (2, 9, 0.6322583556175232),\n (2, 10, 0.5704501867294312),\n (2, 11, 0.5828412771224976),\n (2, 12, 0.6378066539764404),\n (2, 13, 0.69139564037323),\n (2, 14, 0.6474908590316772),\n (2, 15, 0.6154056787490845),\n (2, 16, 0.68714439868927),\n (2, 17, 0.7023219466209412),\n (2, 18, 0.6431967616081238),\n (2, 19, 0.6586276292800903),\n (2, 20, 0.650769054889679),\n (2, 21, 0.6362648010253906),\n (2, 22, 0.7066485285758972),\n (2, 23, 0.6588587164878845),\n (2, 24, 0.6905868053436279),\n (2, 25, 0.6514662504196167),\n (2, 26, 0.6880756616592407),\n (2, 27, 0.6354951858520508),\n (3, 4, 0.03235967084765434),\n (3, 5, 0.1512165665626526),\n (3, 6, 0.1380177140235901),\n (3, 7, 0.20171405375003815),\n (3, 8, 0.1526450365781784),\n (3, 9, 0.13056907057762146),\n (3, 10, 0.23209062218666077),\n (3, 11, 0.7857808470726013),\n (3, 12, 0.21389544010162354),\n (3, 13, 0.20203478634357452),\n (3, 14, 0.14245127141475677),\n (3, 15, 0.16068245470523834),\n (3, 16, 0.17039823532104492),\n (3, 17, 0.20283134281635284),\n (3, 18, 0.17598101496696472),\n (3, 19, 0.17448773980140686),\n (3, 20, 0.14938104152679443),\n (3, 21, 0.17380648851394653),\n (3, 22, 0.22450312972068787),\n (3, 23, 0.14858992397785187),\n (3, 24, 0.19588254392147064),\n (3, 25, 0.1469128578901291),\n (3, 26, 0.19678889214992523),\n (3, 27, 0.12700866162776947),\n (4, 5, 0.0031711102928966284),\n (4, 6, 0.002816929016262293),\n (4, 7, 0.028047362342476845),\n (4, 8, 0.004311413504183292),\n (4, 9, 0.006255981046706438),\n (4, 10, 0.04060244560241699),\n (4, 11, 0.7456787824630737),\n (4, 12, 0.033730071038007736),\n (4, 13, 0.021687116473913193),\n (4, 14, 0.003255143528804183),\n (4, 15, 0.002582560759037733),\n (4, 16, 0.01153197605162859),\n (4, 17, 0.01686677150428295),\n (4, 18, 0.0031696499790996313),\n (4, 19, 0.003379370318725705),\n (4, 20, 0.008798902854323387),\n (4, 21, 0.0027418360114097595),\n (4, 22, 0.01799710839986801),\n (4, 23, 0.005963128991425037),\n (4, 24, 0.013169199228286743),\n (4, 25, 0.004866440314799547),\n (4, 26, 0.005824151914566755),\n (4, 27, 0.0032935740891844034),\n (5, 6, 0.6407255530357361),\n (5, 7, 0.6145603656768799),\n (5, 8, 0.6539314389228821),\n (5, 9, 0.6078476905822754),\n (5, 10, 0.48655009269714355),\n (5, 11, 0.6330196261405945),\n (5, 12, 0.5605289936065674),\n (5, 13, 0.6491217613220215),\n (5, 14, 0.6484204530715942),\n (5, 15, 0.6462467908859253),\n (5, 16, 0.6530637741088867),\n (5, 17, 0.6639900803565979),\n (5, 18, 0.6656372547149658),\n (5, 19, 0.6717554330825806),\n (5, 20, 0.6260453462600708),\n (5, 21, 0.6658167839050293),\n (5, 22, 0.6743161678314209),\n (5, 23, 0.6420108675956726),\n (5, 24, 0.663898229598999),\n (5, 25, 0.6400290727615356),\n (5, 26, 0.683623731136322),\n (5, 27, 0.6318883895874023),\n (6, 7, 0.6121296882629395),\n (6, 8, 0.6378514766693115),\n (6, 9, 0.5936034917831421),\n (6, 10, 0.48594003915786743),\n (6, 11, 0.6049470901489258),\n (6, 12, 0.5616738796234131),\n (6, 13, 0.6440476775169373),\n (6, 14, 0.6289294958114624),\n (6, 15, 0.6212337017059326),\n (6, 16, 0.6450724005699158),\n (6, 17, 0.6578848361968994),\n (6, 18, 0.6423628926277161),\n (6, 19, 0.650640070438385),\n (6, 20, 0.6123230457305908),\n (6, 21, 0.6414790153503418),\n (6, 22, 0.668196439743042),\n (6, 23, 0.6280677318572998),\n (6, 24, 0.6558521389961243),\n (6, 25, 0.6238582730293274),\n (6, 26, 0.6675381660461426),\n (6, 27, 0.6140040159225464),\n (7, 8, 0.5666692852973938),\n (7, 9, 0.473154753446579),\n (7, 10, 0.31759050488471985),\n (7, 11, 0.786492645740509),\n (7, 12, 0.3461472690105438),\n (7, 13, 0.45529621839523315),\n (7, 14, 0.6007402539253235),\n (7, 15, 0.6579587459564209),\n (7, 16, 0.4867945909500122),\n (7, 17, 0.48854517936706543),\n (7, 18, 0.6632601618766785),\n (7, 19, 0.6519687175750732),\n (7, 20, 0.478398859500885),\n (7, 21, 0.6722728610038757),\n (7, 22, 0.5271363854408264),\n (7, 23, 0.5207403302192688),\n (7, 24, 0.521931529045105),\n (7, 25, 0.5416330099105835),\n (7, 26, 0.6081287264823914),\n (7, 27, 0.5660364627838135),\n (8, 9, 0.5807303786277771),\n (8, 10, 0.43117350339889526),\n (8, 11, 0.653941810131073),\n (8, 12, 0.5005493760108948),\n (8, 13, 0.6095291972160339),\n (8, 14, 0.6396584510803223),\n (8, 15, 0.6509921550750732),\n (8, 16, 0.6240960955619812),\n (8, 17, 0.6322875618934631),\n (8, 18, 0.6669977307319641),\n (8, 19, 0.6707509756088257),\n (8, 20, 0.5967980623245239),\n (8, 21, 0.6697534322738647),\n (8, 22, 0.6486610770225525),\n (8, 23, 0.6173009872436523),\n (8, 24, 0.6384821534156799),\n (8, 25, 0.6230064034461975),\n (8, 26, 0.6710716485977173),\n (8, 27, 0.6209467649459839),\n (9, 10, 0.33942732214927673),\n (9, 11, 0.6700907349586487),\n (9, 12, 0.40345248579978943),\n (9, 13, 0.5232086181640625),\n (9, 14, 0.5914512276649475),\n (9, 15, 0.6193699836730957),\n (9, 16, 0.5470945239067078),\n (9, 17, 0.5522660613059998),\n (9, 18, 0.6310119032859802),\n (9, 19, 0.6317589282989502),\n (9, 20, 0.5196877121925354),\n (9, 21, 0.6380939483642578),\n (9, 22, 0.5786010026931763),\n (9, 23, 0.5554651021957397),\n (9, 24, 0.5697511434555054),\n (9, 25, 0.5597211718559265),\n (9, 26, 0.6233639717102051),\n (9, 27, 0.5657612085342407),\n (10, 11, 0.8320461511611938),\n (10, 12, 0.2759856879711151),\n (10, 13, 0.36178725957870483),\n (10, 14, 0.4756852090358734),\n (10, 15, 0.5591267347335815),\n (10, 16, 0.3717026114463806),\n (10, 17, 0.3837338387966156),\n (10, 18, 0.5580776333808899),\n (10, 19, 0.5381458401679993),\n (10, 20, 0.35380661487579346),\n (10, 21, 0.5728854537010193),\n (10, 22, 0.41806942224502563),\n (10, 23, 0.38928279280662537),\n (10, 24, 0.40968748927116394),\n (10, 25, 0.4041808843612671),\n (10, 26, 0.4880358874797821),\n (10, 27, 0.43004876375198364),\n (11, 12, 0.8281411528587341),\n (11, 13, 0.7587007284164429),\n (11, 14, 0.6126635074615479),\n (11, 15, 0.5350322723388672),\n (11, 16, 0.7190828323364258),\n (11, 17, 0.7444915175437927),\n (11, 18, 0.5951054096221924),\n (11, 19, 0.6181790232658386),\n (11, 20, 0.6915994882583618),\n (11, 21, 0.5739037394523621),\n (11, 22, 0.6954312324523926),\n (11, 23, 0.6608714461326599),\n (11, 24, 0.6787600517272949),\n (11, 25, 0.6585936546325684),\n (11, 26, 0.6285814046859741),\n (11, 27, 0.6335501074790955),\n (12, 13, 0.3908439874649048),\n (12, 14, 0.5473573207855225),\n (12, 15, 0.6265749335289001),\n (12, 16, 0.4187116324901581),\n (12, 17, 0.42472636699676514),\n (12, 18, 0.6254512071609497),\n (12, 19, 0.6057702302932739),\n (12, 20, 0.410260409116745),\n (12, 21, 0.6382721662521362),\n (12, 22, 0.4646744430065155),\n (12, 23, 0.45221537351608276),\n (12, 24, 0.45593759417533875),\n (12, 25, 0.47443559765815735),\n (12, 26, 0.5471859574317932),\n (12, 27, 0.5039544701576233),\n (13, 14, 0.6351994872093201),\n (13, 15, 0.6790755987167358),\n (13, 16, 0.5415701866149902),\n (13, 17, 0.5441862344741821),\n (13, 18, 0.6867060661315918),\n (13, 19, 0.6789133548736572),\n (13, 20, 0.5312950015068054),\n (13, 21, 0.6924731135368347),\n (13, 22, 0.5747604370117188),\n (13, 23, 0.5711761116981506),\n (13, 24, 0.5694891810417175),\n (13, 25, 0.5893358588218689),\n (13, 26, 0.6470932960510254),\n (13, 27, 0.6072432398796082),\n (14, 15, 0.6351761817932129),\n (14, 16, 0.6383631825447083),\n (14, 17, 0.6506357789039612),\n (14, 18, 0.6555088758468628),\n (14, 19, 0.6611577272415161),\n (14, 20, 0.6099813580513),\n (14, 21, 0.6557841897010803),\n (14, 22, 0.6608516573905945),\n (14, 23, 0.6267029047012329),\n (14, 24, 0.6494652628898621),\n (14, 25, 0.6262791156768799),\n (14, 26, 0.6703994870185852),\n (14, 27, 0.6172877550125122),\n (15, 16, 0.6741568446159363),\n (15, 17, 0.6897742748260498),\n (15, 18, 0.6372163891792297),\n (15, 19, 0.6502119302749634),\n (15, 20, 0.6392190456390381),\n (15, 21, 0.6295965313911438),\n (15, 22, 0.6940183043479919),\n (15, 23, 0.6454131007194519),\n (15, 24, 0.6772948503494263),\n (15, 25, 0.6392379403114319),\n (15, 26, 0.6756613254547119),\n (15, 27, 0.623073399066925),\n (16, 17, 0.5736261010169983),\n (16, 18, 0.683904230594635),\n (16, 19, 0.6805753111839294),\n (16, 20, 0.5568569898605347),\n (16, 21, 0.6898322105407715),\n (16, 22, 0.6020229458808899),\n (16, 23, 0.593259871006012),\n (16, 24, 0.5982497334480286),\n (16, 25, 0.6057554483413696),\n (16, 26, 0.6600492596626282),\n (16, 27, 0.6153603196144104),\n (17, 18, 0.6978296041488647),\n (17, 19, 0.6904391646385193),\n (17, 20, 0.5623536705970764),\n (17, 21, 0.7035311460494995),\n (17, 22, 0.6020848751068115),\n (17, 23, 0.59806227684021),\n (17, 24, 0.6001761555671692),\n (17, 25, 0.6134010553359985),\n (17, 26, 0.6648403406143188),\n (17, 27, 0.625240683555603),\n (18, 19, 0.6715191602706909),\n (18, 20, 0.6481854915618896),\n (18, 21, 0.6572598814964294),\n (18, 22, 0.70438152551651),\n (18, 23, 0.6600649356842041),\n (18, 24, 0.688887894153595),\n (18, 25, 0.6536574363708496),\n (18, 26, 0.6930991411209106),\n (18, 27, 0.6409668922424316),\n (19, 20, 0.6499772667884827),\n (19, 21, 0.6694555282592773),\n (19, 22, 0.6986953616142273),\n (19, 23, 0.6628071665763855),\n (19, 24, 0.6879525184631348),\n (19, 25, 0.6575807332992554),\n (19, 26, 0.6970205307006836),\n (19, 27, 0.6467885375022888),\n (20, 21, 0.657131016254425),\n (20, 22, 0.5877546072006226),\n (20, 23, 0.571294903755188),\n (20, 24, 0.5778743624687195),\n (20, 25, 0.5762938261032104),\n (20, 26, 0.6398497223854065),\n (20, 27, 0.5857248902320862),\n (21, 22, 0.7083775997161865),\n (21, 23, 0.6642312407493591),\n (21, 24, 0.6941034197807312),\n (21, 25, 0.658011794090271),\n (21, 26, 0.6938483715057373),\n (21, 27, 0.6433342695236206),\n (22, 23, 0.6195434927940369),\n (22, 24, 0.6229152679443359),\n (22, 25, 0.6323350667953491),\n (22, 26, 0.6771524548530579),\n (22, 27, 0.6395193338394165),\n (23, 24, 0.6132277846336365),\n (23, 25, 0.600766658782959),\n (23, 26, 0.6547662019729614),\n (23, 27, 0.603947103023529),\n (24, 25, 0.6209597587585449),\n (24, 26, 0.6712677478790283),\n (24, 27, 0.6275331974029541),\n (25, 26, 0.6600415706634521),\n (25, 27, 0.6034719944000244),\n (26, 27, 0.6551728844642639)]\n\n\nLet’s put those probabilities to a sorted dataframe:\n\n\nCode\nresults_df = pd.DataFrame(results, columns=[\"Protein1\", \"Protein2\", \"Prediction\"])\n\n# Sort the DataFrame by prediction score in descending order\nresults_df = results_df.sort_values(by=\"Prediction\", ascending=False)\n\nresults_df\n\n\n\n\n\n\n\n\n\nProtein1\nProtein2\nPrediction\n\n\n\n\n225\n10\n11\n0.832046\n\n\n242\n11\n12\n0.828141\n\n\n171\n7\n11\n0.786493\n\n\n85\n3\n11\n0.785781\n\n\n243\n11\n13\n0.758701\n\n\n...\n...\n...\n...\n\n\n118\n4\n21\n0.002742\n\n\n29\n1\n4\n0.002692\n\n\n112\n4\n15\n0.002583\n\n\n3\n0\n4\n0.002403\n\n\n54\n2\n4\n0.002355\n\n\n\n\n378 rows × 3 columns\n\n\n\nHere, we can filter out probabilities less than 50%:\n\n\nCode\nmask = results_df[\"Prediction\"] &gt; 0.5\nfiltered_results_df = results_df[mask]\n\nfiltered_results_df\n\n\n\n\n\n\n\n\n\nProtein1\nProtein2\nPrediction\n\n\n\n\n225\n10\n11\n0.832046\n\n\n242\n11\n12\n0.828141\n\n\n171\n7\n11\n0.786493\n\n\n85\n3\n11\n0.785781\n\n\n243\n11\n13\n0.758701\n\n\n...\n...\n...\n...\n\n\n184\n7\n24\n0.521932\n\n\n183\n7\n23\n0.520740\n\n\n217\n9\n20\n0.519688\n\n\n272\n12\n27\n0.503954\n\n\n191\n8\n12\n0.500549\n\n\n\n\n295 rows × 3 columns\n\n\n\nAnd, get back the protein ID’s:\n\n\nCode\nfiltered_results_df[\"Protein1\"] = lbl_protein.inverse_transform(filtered_results_df[\"Protein1\"])\nfiltered_results_df[\"Protein2\"] = lbl_protein.inverse_transform(filtered_results_df[\"Protein2\"])\nfiltered_results_df\n\n\nC:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_3324\\338268944.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  filtered_results_df[\"Protein1\"] = lbl_protein.inverse_transform(filtered_results_df[\"Protein1\"])\nC:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_3324\\338268944.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  filtered_results_df[\"Protein2\"] = lbl_protein.inverse_transform(filtered_results_df[\"Protein2\"])\n\n\n\n\n\n\n\n\n\nProtein1\nProtein2\nPrediction\n\n\n\n\n225\nXP_027084938.1\nXP_027084939.1\n0.832046\n\n\n242\nXP_027084939.1\nXP_027085429.1\n0.828141\n\n\n171\nXP_027084168.1\nXP_027084939.1\n0.786493\n\n\n85\nXP_027066556.1\nXP_027084939.1\n0.785781\n\n\n243\nXP_027084939.1\nXP_027089120.1\n0.758701\n\n\n...\n...\n...\n...\n\n\n184\nXP_027084168.1\nXP_027113320.1\n0.521932\n\n\n183\nXP_027084168.1\nXP_027110886.1\n0.520740\n\n\n217\nXP_027084891.1\nXP_027109657.1\n0.519688\n\n\n272\nXP_027085429.1\nXP_027125186.1\n0.503954\n\n\n191\nXP_027084272.1\nXP_027085429.1\n0.500549\n\n\n\n\n295 rows × 3 columns\n\n\n\nTo check, let’s left-join the first dsf to the filtered to see that the protein ID’s are correct:\n\n\nCode\nfiltered_results_df = pd.merge(\n    filtered_results_df,\n    df,\n    how='left',\n    left_on=['Protein1', 'Protein2'],\n    right_on=['Protein1', 'Protein2']\n)\n\nfiltered_results_df = filtered_results_df.drop(columns=['node1_string_id', 'node2_string_id'])\nfiltered_results_df = filtered_results_df.sort_values(by=\"Prediction\", ascending=False)\n\n# Display the filtered results DataFrame\nprint(filtered_results_df)\n\n\n           Protein1        Protein2  Prediction\n0    XP_027084938.1  XP_027084939.1    0.832046\n1    XP_027084939.1  XP_027085429.1    0.828141\n2    XP_027084168.1  XP_027084939.1    0.786493\n3    XP_027066556.1  XP_027084939.1    0.785781\n4    XP_027084939.1  XP_027089120.1    0.758701\n..              ...             ...         ...\n290  XP_027084168.1  XP_027113320.1    0.521932\n291  XP_027084168.1  XP_027110886.1    0.520740\n292  XP_027084891.1  XP_027109657.1    0.519688\n293  XP_027085429.1  XP_027125186.1    0.503954\n294  XP_027084272.1  XP_027085429.1    0.500549\n\n[295 rows x 3 columns]\n\n\nAnd, we can plot the graph with the edges coloured by the predicted probaility of interaction:\n\n\nCode\nimport networkx as nx\n\nG = nx.Graph()\n\n# Add edges to the graph\nfor index, row in filtered_results_df.iterrows():\n    G.add_edge(row['Protein1'], row['Protein2'], weight=round(row['Prediction'],3))\n\n# Print some info about the graph\nprint(G)\n\n\nGraph with 28 nodes and 295 edges\n\n\n\n\nCode\nimport pandas as pd\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nimport matplotlib.cm as cm\nimport matplotlib as mpl\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\n\n# Define the plot size and create a subplot\nfig, ax = plt.subplots(figsize=(14, 14))\n\n# Get edge weights and normalize them\nweights = nx.get_edge_attributes(G, 'weight').values()\n\n# Define the layout for the nodes\npos = nx.spring_layout(G, seed=120, weight='weight')  # for consistent layout\n\n# Draw the nodes\nnx.draw_networkx_nodes(G, pos, node_size=700, ax=ax)\n\n\nnorm = mcolors.Normalize(vmin=min(weights), vmax=max(weights))\ncmap = cm.jet\n\n# Draw the edges with colors based on the weights\nedges = G.edges(data=True)\nedge_colors = [cmap(norm(weight['weight'])) for _, _, weight in edges]\nedge_alphas = [norm(weight['weight']) for _, _, weight in edges]\n\nnx.draw_networkx_edges(G, pos, edge_color=edge_colors, width=1.0, alpha=edge_alphas, ax=ax)\n\n# Draw the labels\nnx.draw_networkx_labels(G, pos, font_size=9, font_family=\"sans-serif\", ax=ax)\n\n# Add edge weights as labels (optional)\nedge_labels = nx.get_edge_attributes(G, 'weight')\nnx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=5, ax=ax)\n\n# Create a colorbar as a legend\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\nsm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\nsm.set_array([])\ncbar = plt.colorbar(sm, cax=cax)\ncbar.set_label('Prediction Probability')\n\n# Show the plot\nplt.title(\"Protein-Protein Interaction Network\")\nplt.axis('off')  # Turn off the axis\nplt.savefig(\"protein_interaction_network.svg\", format='svg')\nplt.show()\n\n\n\n\n\n\n\n\n\nWe can see that have a “medium” probaility of interaction based on their protein sequences. Doing a small search, most of the proteins in the messy part of the network are small heatshock protein sequences. It would be interesting to investigate the strong relations and if this have a biological meeaning like: these proteins are in the same compartment?"
  },
  {
    "objectID": "posts/proteinbert_graphsage/BERT2Graphsage.html",
    "href": "posts/proteinbert_graphsage/BERT2Graphsage.html",
    "title": "Predict Protein-Protein Interactions with GraphSAGE",
    "section": "",
    "text": "Code\nimport random\nfrom tqdm.notebook import tqdm, trange\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, metrics, preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import ConfusionMatrixDisplay\nimport copy\n\nimport torch\nfrom torch import nn, optim, Tensor\nimport torch.nn.functional as F\n\nfrom torch_sparse import SparseTensor, matmul, set_diag\nfrom torch_geometric.utils import negative_sampling\nfrom torch_geometric.data import Dataset, download_url, extract_zip, Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn.conv.gcn_conv import gcn_norm\nfrom torch_geometric.nn.conv import MessagePassing\nfrom torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType, OptTensor)\nimport torch_geometric.nn as pyg_nn\nimport torch_geometric.utils as pyg_utils\nfrom torch_geometric.utils import remove_self_loops, add_self_loops, softmax\nimport torch_scatter\n\nfrom Bio import SeqIO\n\nimport zipfile\nimport os\nimport os.path as osp\nimport io\n\nfrom proteinbert import load_pretrained_model\nfrom proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\nimport tensorflow as tf\nThis is the second of a Protein Embedding with ProteinBERT and STRING. On this part, we are gonna build a graph neural network (GNN) to update the embeddings of PorteinBERT with the information about the STRING network.\nWe will keep using the Unfolded protein binding (GO:0051082) ontology which belongs to the heat shock response. As before, the reason is because this was a gene set that appears significant on my thesis (Functional analysis of transcriptomes of Coffea arabica L. related to thermal stress) and because I don’t have much power on my laptop."
  },
  {
    "objectID": "posts/proteinbert_graphsage/BERT2Graphsage.html#creating-and-loading-the-unfolded-protein-binding-dataset",
    "href": "posts/proteinbert_graphsage/BERT2Graphsage.html#creating-and-loading-the-unfolded-protein-binding-dataset",
    "title": "Predict Protein-Protein Interactions with GraphSAGE",
    "section": "Creating and Loading the Unfolded Protein Binding Dataset",
    "text": "Creating and Loading the Unfolded Protein Binding Dataset\nBefore creating the neural network, we need data. So, for this I downloaded 60 plant species as zip files from STRING database. The reason I chooosed only plants, is because the heat shock proteins on plants are compartmentalized. This means, that there are specific heat shock proteins for the chloroplat, nucleus, mitocondria, plastids and cytoplasm. Using only plants in this case will result in a better training for this small part of the metabolism.\nOther important thing to mention is that due to the size of the plants networks and the capacities of my laptop, I’m only using the Unfolded protein binding for these 60 species. If you have enough computing resources, you can try using the complete network from all these 60 species to train a robust model.\nGreat! Once downloaded the data, we need to create a dataset that pytorch geometric can use. For this, we need to use the Dataset object from pytorch geometric.\nSee the code below:\n\n\nCode\n\nclass UnfoldedProteinBinding(Dataset):\n    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n        self.batch_size = 2 # adapt it according to your ram and gpu memmory\n        super(UnfoldedProteinBinding, self).__init__(root, transform, pre_transform, pre_filter)\n        \n\n    @property\n    def raw_file_names(self):\n        return self._get_zip_files()\n    \n    def _get_zip_files(self):\n\n        files = os.listdir(self.raw_dir)\n\n        zip_files = [f for f in files if f.endswith(\".zip\")]\n        return zip_files\n\n    @property\n    def processed_file_names(self):\n        \n        num_zip_files = len(self.raw_file_names)\n\n        return [f\"data_{i}.pt\" for i in range(num_zip_files)]\n\n    def download(self):\n        # Download to `self.raw_dir`.\n        pass\n\n    def process(self):\n\n        # gpu device only on linux system\n        gpus = tf.config.experimental.list_physical_devices('GPU')\n        if len(gpus) &gt; 0:\n            try:\n                for gpu in gpus:\n                    tf.config.experimental.set_memory_growth(gpu, True)\n            except RuntimeError as e:\n                print(e)\n        else:\n            print(f\"Not gpus available\")\n            if os.name == \"nt\":\n                print(\"Not gpus detected because you are using Windows system, Device: CPU\")\n\n        # check that we already processed the files\n        if len(os.listdir(self.processed_dir)) == len(self.raw_file_names)+2:\n            pass\n\n        else:\n                \n            for species in self.raw_paths:\n\n                print(species)\n\n                # reading interactions from tsv file\n                with zipfile.ZipFile(species, 'r') as z:\n        \n                    file_names = z.namelist()\n                    \n                    tsv_files = [file for file in file_names if file.endswith('interactions.tsv')]\n\n                    for tsv_file in tsv_files:\n                        with z.open(tsv_file) as f:\n                            df = pd.read_csv(f, sep='\\t')\n\n                # reading fasta file\n                with zipfile.ZipFile(species, 'r') as z:\n    \n                    file_names = z.namelist()\n                    \n                    tsv_files = [file for file in file_names if file.endswith('protein_sequences.fa')]\n\n                    for tsv_file in tsv_files:\n                        with z.open(tsv_file) as f:\n                            f_text = io.TextIOWrapper(f)\n                            protein_sequences_dict = self._read_proteins_from_fasta(f_text)\n                \n                # get unique proteins\n                unique_proteins = set(df['node1_string_id']).union(set(df['node2_string_id']))\n\n                # filter unique proteins on a dict\n                filtered_protein_dict = {protein: seq for protein, seq in protein_sequences_dict.items() if protein in unique_proteins}\n\n                # getting the larger sequence for the proteinbert embedding\n                sequences = list(filtered_protein_dict.values())\n                # protein_names = list(filtered_protein_dict.keys())\n                longest_sequence_length = max(len(seq) for seq in sequences)\n\n                # use protein bert to get embeddings\n                batch_size = self.batch_size  # Adjust based on your GPU memory\n                seq_len = longest_sequence_length+2\n                global_embeds = []\n                local_embeds = []\n\n                for i in range(0, len(sequences), batch_size):\n\n                    batch_seqs = sequences[i:i + batch_size]\n                    local_representation, global_representation = self._get_embeddings(batch_seqs, seq_len=seq_len, batch_size=batch_size)\n                    global_embeds.extend(global_representation)\n                    local_embeds.extend(local_representation)\n                \n                global_embeds = np.array(global_embeds)\n                local_embeds = np.array(local_embeds)\n\n                # encode the protein names\n\n                lbl_protein = preprocessing.LabelEncoder()\n\n                df.node1_string_id = lbl_protein.fit_transform(df.node1_string_id.values)\n                df.node2_string_id = lbl_protein.fit_transform(df.node2_string_id.values)\n\n                # generate edge index\n\n                edge_index = self._load_edge_csv(df=df, src_index_col=\"node1_string_id\", dst_index_col=\"node2_string_id\", link_index_col=\"combined_score\")\n                edge_index = torch.LongTensor(edge_index)\n\n                # get class for the graph\n\n                y = self._find_species_classes(self.root+\"/raw/species.xlsx\",species).values\n                index = y.copy()[0]\n                y = torch.Tensor(y).to(torch.long)\n                \n                # create pytorch geometric data\n\n                data = Data(x=global_embeds,edge_index=edge_index, y=y)\n                \n                # save as .pt file according to the index (class)\n                torch.save(data, osp.join(self.processed_dir,f\"data_{index}.pt\"))\n\n           \n    \n    def _read_proteins_from_fasta(self, fasta_file):\n\n        protein_dict = {}\n        for record in SeqIO.parse(fasta_file, \"fasta\"):\n            protein_dict[record.id] = str(record.seq)\n        return protein_dict\n    \n    def _get_embeddings(self, seq, seq_len=512, batch_size=1):\n\n        pretrained_model_generator, input_encoder = load_pretrained_model()\n        model = get_model_with_hidden_layers_as_outputs(pretrained_model_generator.create_model(seq_len=seq_len))\n        encoded_x = input_encoder.encode_X(seq, seq_len)\n        local_representations, global_representations = model.predict(encoded_x, batch_size=batch_size)\n\n        return local_representations, global_representations\n    \n    def _load_edge_csv(self, df, src_index_col, dst_index_col, link_index_col):\n    \n        edge_index= None\n        src = [protein1 for protein1 in df[src_index_col]]\n        dst = [protein2 for protein2 in df[dst_index_col]]\n\n        edge_attr = torch.from_numpy(df[link_index_col].values).view(-1,1)\n\n        edge_index = [[], []]\n        for i in range(edge_attr.shape[0]):\n            if edge_attr[i]:\n                edge_index[0].append(src[i])\n                edge_index[1].append(dst[i])\n        return edge_index\n    \n    def _find_species_classes(self, file_path, species_path):\n    # Load the Excel file into a pandas DataFrame        \n        df = pd.read_excel(file_path)\n\n        # Ensure the columns 'species' and 'class' exist\n        if 'species' not in df.columns or 'class' not in df.columns:\n            raise ValueError(\"The input file must contain 'species' and 'class' columns.\")\n\n        # Identify rows where \"scientific name\" is present in the \"species\" column (case insensitive)\n        extract_pattern = [i.split(\"\\\\\") for i in species_path.split(\"_\")[0:2]]\n        extract_pattern = [i[-1] for i in extract_pattern]\n        extract_pattern = \" \".join(extract_pattern)\n        print(f\"Extracted pattern: {extract_pattern}\")\n\n        mask = df['species'].str.contains(extract_pattern, case=False, na=False)\n\n        # Return the corresponding \"class\" values\n        result = df.loc[mask, 'class']\n        return result\n\n\n    def len(self):\n        return len(self.processed_file_names)\n\n    def get(self, idx):\n        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n        return data\n\n\nBasically what this code does, is using the .tsv and .fasta files to create a Data object that stores 3 things:\n\nThe embedding of ProteinBERT as node features.\nThe edge_index which is the connections of the network.\nA number representing the plant species.\n\nWe can verifiy that the data was created and loaded:\n\n\nCode\ndataset = UnfoldedProteinBinding(root=\"data/\")\n\n\n\n\nCode\ndataset[0]\n\n\nData(x=[158, 15599], edge_index=[2, 8578], y=[1])"
  },
  {
    "objectID": "posts/proteinbert_graphsage/BERT2Graphsage.html#spliting-the-data",
    "href": "posts/proteinbert_graphsage/BERT2Graphsage.html#spliting-the-data",
    "title": "Predict Protein-Protein Interactions with GraphSAGE",
    "section": "Spliting the Data",
    "text": "Spliting the Data\nOnce we have the data loaded, we need to split it to trainning and test datasets. For this, we can use random_split and load these two datasets to a DataLoader from pytorch geometric.\nI set batch to one because I dont have much computer resources and because if I increase the number of batches, I need to add a for loop on the GNN class due to the different number of nodes for each species. You are free to modify this for a larger scale training.\n\n\nCode\nfrom torch_geometric.loader import DataLoader\n\ntrain_dataset, test_dataset = torch.utils.data.random_split(dataset, [50, 10])\n\n\nbatch_size = 1  # Adjust based on your memory capacity\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
  },
  {
    "objectID": "posts/proteinbert_graphsage/BERT2Graphsage.html#define-device",
    "href": "posts/proteinbert_graphsage/BERT2Graphsage.html#define-device",
    "title": "Predict Protein-Protein Interactions with GraphSAGE",
    "section": "Define Device",
    "text": "Define Device\nIs important to define the device of work.\n\n\nCode\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint('Device: {}'.format(device))\n\n\nDevice: cuda"
  },
  {
    "objectID": "posts/proteinbert_graphsage/BERT2Graphsage.html#graph-neural-network",
    "href": "posts/proteinbert_graphsage/BERT2Graphsage.html#graph-neural-network",
    "title": "Predict Protein-Protein Interactions with GraphSAGE",
    "section": "Graph Neural Network",
    "text": "Graph Neural Network\nOkay! We are ready to create our graph neural network. We are gonna use GraphSAGE for this task because it’s easy to implement and faster to train.\n\nGNNStack\nThe GNNStack class, takes as input the ProteinBERT embeddings and the edge index and returns the updated node embeddings. Notice that we are using a built-in GraphSAGE (SAGEConv) from pytorch geometric.\n\n\nCode\nfrom torch_geometric.nn import SAGEConv\n\nclass GNNStack(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, dropout, num_layers:int, emb=False):\n        super(GNNStack, self).__init__()\n\n        \n        self.dropout = dropout\n        self.num_layers = num_layers\n        self.emb = emb\n\n        self.convs = nn.ModuleList()\n\n        for layer in range(self.num_layers):\n            in_channels = input_dim if layer == 0 else hidden_dim\n            out_channels = hidden_dim \n\n            self.convs.append(SAGEConv(in_channels, out_channels, normalize=True))\n\n        self.post_mp = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.Dropout(self.dropout),\n            nn.Linear(hidden_dim, hidden_dim)\n        ) \n    \n\n    def forward(self, x, edge_index):\n        \n            \n        for i in range(self.num_layers):\n            x = self.convs[i](x, edge_index)\n            x = F.gelu(x)\n            x = F.dropout(x, p=self.dropout,training=self.training)\n        \n        x = self.post_mp(x)\n        \n\n        if self.emb == True:\n            return x\n            \n\n        return F.log_softmax(x, dim=1)\n\n    def loss(self, pred, label):\n        return F.nll_loss(pred, label)\n\n\nA function to save the model:\n\n\nCode\ndef save_torch_model(model,epoch,PATH:str,optimizer):\n    print(f\"Saving Model in Path {PATH}\")\n    torch.save({'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer':optimizer,      \n                }, PATH)\n\n\nLet’s check the model structure:\n\n\nCode\ninput_dim = dataset[0].x.shape[1]\nhidden_dim = 1024\ndropout = 0.3\nnum_layers= 3\n\nmodel = GNNStack(input_dim, hidden_dim, hidden_dim, dropout, num_layers, True)\nmodel\n\n\nGNNStack(\n  (convs): ModuleList(\n    (0): SAGEConv(15599, 1024, aggr=mean)\n    (1-2): 2 x SAGEConv(1024, 1024, aggr=mean)\n  )\n  (post_mp): Sequential(\n    (0): Linear(in_features=1024, out_features=1024, bias=True)\n    (1): Dropout(p=0.3, inplace=False)\n    (2): Linear(in_features=1024, out_features=1024, bias=True)\n  )\n)\n\n\n\n\nLinkPredictionHead\nOnce we have the updated protein embeddings, we need to create a prediction head that will calculate the probability that two proteins interact.\nThe LinkPredictorHead takes as input two vectors that corresponds to the edge indeces from a specific network and return a estimated probability that these nodes interact.\nNotice that to the last layer, a multi layer perceptron is applied.\n\n\nCode\nclass LinkPredictorHead(nn.Module):\n    def __init__(self, in_channels:int, hidden_channels:int, out_channels:int, n_layers:int,dropout_probabilty:float=0.3):\n        \n        super(LinkPredictorHead, self).__init__()\n        self.dropout_probabilty    = dropout_probabilty  # dropout probability\n        self.mlp_layers            = nn.ModuleList()     # ModuleList: is a list of modules\n        self.non_linearity         = F.relu              # non-linearity\n        \n        for i in range(n_layers - 1):                                 \n            if i == 0:\n                self.mlp_layers.append(nn.Linear(in_channels, hidden_channels))          # input layer (in_channels, hidden_channels)\n            else:\n                self.mlp_layers.append(nn.Linear(hidden_channels, hidden_channels))      # hidden layers (hidden_channels, hidden_channels)\n\n        self.mlp_layers.append(nn.Linear(hidden_channels, out_channels))                 # output layer (hidden_channels, out_channels)\n\n\n    def reset_parameters(self):\n        for mlp_layer in self.mlp_layers:\n            mlp_layer.reset_parameters()\n\n    def forward(self, x_i, x_j):\n\n        x = x_i * x_j                                                     # element-wise multiplication\n        for mlp_layer in self.mlp_layers[:-1]:                            # iterate over all layers except the last one\n            x = mlp_layer(x)                                              # apply linear transformation\n            x = self.non_linearity(x)                                     # Apply non linear activation function\n            x = F.dropout(x, p=self.dropout_probabilty,training=self.training)      # Apply dropout\n        x = self.mlp_layers[-1](x)                                        # apply linear transformation to the last layer\n        x = torch.sigmoid(x)                                              # apply sigmoid activation function to get the probability\n        return x\n\n\nLet’s check the model estructure:\n\n\nCode\nlink_model_pred = LinkPredictorHead(hidden_dim, hidden_dim,1,3)\nlink_model_pred\n\n\nLinkPredictorHead(\n  (mlp_layers): ModuleList(\n    (0-1): 2 x Linear(in_features=1024, out_features=1024, bias=True)\n    (2): Linear(in_features=1024, out_features=1, bias=True)\n  )\n)\n\n\nNow, let’s check if our GNNStack and LinkPredictorHead works on a single graph:\n\n\nCode\nfor batch in train_loader:\n\n    print(batch)\n\n    x = torch.FloatTensor(batch.x[0])\n    \n    emb = model(x, batch.edge_index)\n\n    x = link_model_pred(emb[batch.edge_index[0]], emb[batch.edge_index[1]])\n\n    print(x)\n\n    break\n\n\n\nDataBatch(x=[1], edge_index=[2, 6832], y=[1], batch=[136], ptr=[2])\ntensor([[0.4934],\n        [0.4940],\n        [0.4909],\n        ...,\n        [0.4943],\n        [0.4953],\n        [0.4922]], grad_fn=&lt;SigmoidBackward0&gt;)"
  },
  {
    "objectID": "posts/proteinbert_graphsage/BERT2Graphsage.html#training-function",
    "href": "posts/proteinbert_graphsage/BERT2Graphsage.html#training-function",
    "title": "Predict Protein-Protein Interactions with GraphSAGE",
    "section": "Training Function",
    "text": "Training Function\nLet’s define a training function that for each batch, will get the updated embedding using GrapgSAGE and get the estimated probaiblities using the link predictor head. Now, we need to sample negatives edges so the model can learn which edges are good an which aren’t. Finally, the negative log-likelihood is calculated with the positive and negative edges.\n\n\nCode\ndef train(model, link_predictor, dataloader, optimizer, device:str):\n    \n    if model != None:\n        model.train()\n\n    link_predictor.train()\n\n    total_loss = 0\n\n    for batch in tqdm(dataloader):  \n        \n        x, edge_index = batch.x[0], batch.edge_index\n\n        x = torch.FloatTensor(x).to(device)\n        edge_index = edge_index.to(device)\n        \n        optimizer.zero_grad()  \n        \n        if model !=  None:\n            node_emb = model(x, edge_index)  # Embed Bert Embeddigns with graphsage (N, d)   \n        else:\n            node_emb = x                     # Else (None) use Bert Embedddings\n        # Predict the class probabilities on the batch of positive edges using link_predictor\n        #print(node_emb[edge_index[0]].shape)\n        pos_pred = link_predictor(node_emb[edge_index[0]], node_emb[edge_index[1]])   # (B, )\n\n        # Sample negative edges (same number as number of positive edges) and predict class probabilities \n        # (2,N) = (2,P) = (2,|E|)\n        neg_edge = negative_sampling(edge_index = edge_index,             # Possitve PPI's\n                                 num_nodes        = x.shape[0],           # Total number of nodes in graph\n                                 num_neg_samples  = edge_index.shape[1],  # Same Number of edges as in positive example\n                                 force_undirected = True)                 # Our graph is undirected\n        \n        \n        neg_pred = link_predictor(node_emb[neg_edge[0]], node_emb[neg_edge[1]])         # (Ne,)\n\n        # Compute the corresponding negative log likelihood loss on the positive and negative edges\n        loss = -torch.log(pos_pred + 1e-15).mean() - torch.log(1 - neg_pred + 1e-15).mean()\n\n        # Backpropagate and update parameters\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader)"
  },
  {
    "objectID": "posts/proteinbert_graphsage/BERT2Graphsage.html#testing-function",
    "href": "posts/proteinbert_graphsage/BERT2Graphsage.html#testing-function",
    "title": "Predict Protein-Protein Interactions with GraphSAGE",
    "section": "Testing Function",
    "text": "Testing Function\nFor the testing function, as Perez et al. mention:\n“if we were to use all the PPI to embed the graph it would be practically cheating (since our embedding would have this information). Therefore (for the evaluation loop) we will randomly drop a percentage of PPIs by doing two steps: Randomly permuted the edge_index and Dropping a percentage of PPI for embedding and leaving another percentage for inference”\nThen, we use the GNNStack and the LinkPredictorHead to get the estimated probability on the permuted edge_index. Also, we need to get negative edges and predict the probability of their interactions. The idea is to get high accuracy for the positive and negatives edges so we are sure that the model is performing better each epoch of training.\nAn extra chunk of code is inside the function that will show the AUC/ROC plot and Confusion matrix plot.\n\n\nCode\ndef evaluate(model, predictor,dataloader,device:str,threshold=0.5,ppi_:int=0.9,verbose:bool=False,best_accuracy=0,show_extra_metrics:bool=False):\n    \n    if model != None:\n        model.eval()\n\n    possitive_acc  = 0 \n    negative_acc   = 0\n    batches        = 0\n\n    if show_extra_metrics:\n        yhat_total     = []\n        y_total        = []\n        \n    for batch in dataloader:                              # Get X and Index from Dataste\n        \n        x, edge_index = batch.x[0], batch.edge_index\n\n        x = torch.FloatTensor(x).to(device)\n        edge_index = edge_index.to(device)\n\n        number_of_edges =  edge_index.size(1)                 # Retrive number of edges \n        permutations    =  torch.randperm(number_of_edges)     # Create Permutations for edge index\n        edge_index      = edge_index[:,permutations]           # Run permutation\n        limit           = int(ppi_*number_of_edges)            # get limit  (based on ppis to embed)\n        ppi_index_embed = edge_index[:,0:limit]                # PPI to embed with GraphSage \n        ppi_index_infer = edge_index[:,limit:]                 # PPI to make inference\n        \n        # x                    = x.squeeze(dim=1)\n        # x ,ppi_index_embed   = x.to(device) , ppi_index_embed.to(device) \n        if model !=  None:\n            node_emb = model(x,ppi_index_embed)             # Get all node embeddings\n        else:\n            node_emb = x.cpu()                                                 # Else (None) use Bert Embedddings\n            \n        if verbose:\n            print(f\" {limit} Positive Protein Interactions were used to Embed a graph with {number_of_edges} ppi's\")\n        \n        del ppi_index_embed \n        \n        with torch.no_grad():\n            ### Positive PPI ###\n            positive_pairs_embeddings = node_emb[ppi_index_infer[0]], node_emb[ppi_index_infer[1]]\n            predictions               = predictor(positive_pairs_embeddings[0], positive_pairs_embeddings[1]) \n            y                         = torch.ones_like(input=predictions)\n\n            predictions,y             = predictions.cpu(),y.cpu()\n            possitive_acc            += accuracy_score(predictions &gt; threshold  ,y)\n\n            if show_extra_metrics:\n                yhat_total.extend(predictions.tolist())\n                y_total.extend(y.tolist())\n                \n            else:\n                del y, predictions , positive_pairs_embeddings,ppi_index_infer\n\n            ### Negative PPI ##\n            \n            neg_edge = negative_sampling(edge_index = edge_index,        # Possitve PPI's\n                                         num_nodes        = x.shape[0],           # Total number of nodes in graph\n                                         num_neg_samples  = edge_index.shape[1],  # Same Number of edges as in positive example\n                                         force_undirected = True)                 # Our graph is undirected\n\n            negative_pairs_embeddings = node_emb[neg_edge[0]], node_emb[neg_edge[1]]\n            predictions               = predictor(negative_pairs_embeddings[0], negative_pairs_embeddings[1])   \n            y                         = torch.zeros_like(input=predictions)\n            predictions,y             = predictions.cpu(),y.cpu()\n            negative_acc             += accuracy_score(predictions &gt; threshold,y)\n            if show_extra_metrics:\n                yhat_total.extend(predictions.tolist())\n                y_total.extend(y.tolist())\n                \n            else:\n                del y,  predictions  ,negative_pairs_embeddings \n            batches +=1\n\n    negative_acc  = negative_acc/batches\n    possitive_acc = possitive_acc/batches\n    total_acc     = 0.5*possitive_acc  + 0.5*negative_acc\n    if show_extra_metrics == False:\n        print(f\"Sensitivity (poss_acc):{possitive_acc:.4f} Specificity (negative_acc):{negative_acc:.4f} accuracy:{total_acc:.4f}\")\n    \n    elif show_extra_metrics == True:\n        \n        fig, ax = plt.subplots(1, 2,figsize=(10,2))\n        fpr, tpr, thresholds = metrics.roc_curve( y_total, yhat_total)\n        \n        sens      =  tpr\n        spec      =  1 - fpr\n        j         = sens + spec -1\n        opt_index = np.where(j == np.max(j))[0][0]\n        op_point  = thresholds[opt_index]\n        \n        print(f\"Youdens  index: {op_point:.4f} Sensitivity: {round(sens[opt_index],4)} Specificity: {round(spec[opt_index],4)}\")\n       \n        ax[0].set_title(\"ROC Curve\")\n        ax[1].set_title(\"Confussion Matrix\")\n        if model == None:\n            ax[0].plot(fpr,tpr,label=\"MLP\") \n        else:\n            ax[0].plot(fpr,tpr,label=\"GraphSage+MLP\") \n        ax[0].plot([0, 1], [0, 1], 'k--')\n        ax[0].set_ylabel('True Positive Rate')\n        ax[0].set_xlabel('False Positive Rate')\n        ax[0].legend()\n       \n    \n        cfm = metrics.confusion_matrix(y_total, np.array(yhat_total)&gt; op_point)\n        \n        cmn = cfm.astype('float') / cfm.sum(axis=1)[:, np.newaxis] # Normalise\n        disp = ConfusionMatrixDisplay(cmn)\n        disp.plot(ax=ax[1])\n        \n        plt.show()\n     \n    return total_acc"
  },
  {
    "objectID": "posts/proteinbert_graphsage/BERT2Graphsage.html#training-the-model",
    "href": "posts/proteinbert_graphsage/BERT2Graphsage.html#training-the-model",
    "title": "Predict Protein-Protein Interactions with GraphSAGE",
    "section": "Training the Model",
    "text": "Training the Model\nIt’s time to train the model. First, let’s define some parameters:\n\n\nCode\nepochs        = 500  \nlearning_rate = 1e-4\ninput_dim = dataset[0].x.shape[1]\nhidden_dim = 1024\ndropout = 0.3\nnum_layers= 3\n\n\nInitialize the models:\n\n\nCode\nmodel          = GNNStack(input_dim, hidden_dim, hidden_dim, dropout,num_layers, emb=True).to(device) # the graph neural network that takes all the node embeddings as inputs to message pass and agregate\nlink_predictor = LinkPredictorHead(hidden_dim, hidden_dim, 1, num_layers , dropout).to(device) # the MLP that takes embeddings of a pair of nodes and predicts the existence of an edge between them\noptimizer      = torch.optim.Adam(list(model.parameters()) + list(link_predictor.parameters() ), lr=learning_rate)\n\nprint(model)\nprint(link_predictor)\nprint(f\"Models Loaded to {device}\")\n\n\nGNNStack(\n  (convs): ModuleList(\n    (0): SAGEConv(15599, 1024, aggr=mean)\n    (1-2): 2 x SAGEConv(1024, 1024, aggr=mean)\n  )\n  (post_mp): Sequential(\n    (0): Linear(in_features=1024, out_features=1024, bias=True)\n    (1): Dropout(p=0.3, inplace=False)\n    (2): Linear(in_features=1024, out_features=1024, bias=True)\n  )\n)\nLinkPredictorHead(\n  (mlp_layers): ModuleList(\n    (0-1): 2 x Linear(in_features=1024, out_features=1024, bias=True)\n    (2): Linear(in_features=1024, out_features=1, bias=True)\n  )\n)\nModels Loaded to cuda\n\n\nCheck the training function:\n\n\nCode\nimport gc\n\ntorch.cuda.empty_cache()\ngc.collect()\nloss = train(model, link_predictor, train_loader, optimizer, device)\n\ntorch.cuda.empty_cache()\ngc.collect()\n\n\n\n\n\n170\n\n\nPlease, before running the training loop, take into account that on my NVIDIA GeForce RTX 1650, it took 8 hours.\n\n\nCode\ntrain_loss                      = []\ntrain_accuracy                  = []\nshow_metrics_every              = 20\nbest_accuracy                   = 0 \nbest_graphsage_model_path       = \"\"\nbest_link_predictor_model_path  = \"\"\n\nfor epoch in range(1,epochs):\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    ### TRAIN ####\n    loss = train(model, link_predictor,train_loader, optimizer,device) # Get Loss\n    train_loss.append(loss)\n    print(f\"Epoch {epoch}: loss: {round(loss, 5)}\")\n    \n    ### EVALUATE ###\n    if (epoch % 20 == 0) or (epoch ==1):\n        accuracy = evaluate(model, link_predictor ,test_loader,device=device,best_accuracy=best_accuracy,show_extra_metrics=True)\n        \n    else:\n        accuracy = evaluate(model, link_predictor ,test_loader,device=device,best_accuracy=best_accuracy)\n    \n    train_accuracy.append(accuracy)\n    ### SAVE ###\n    if best_accuracy &lt; accuracy:\n        if os.path.exists(best_graphsage_model_path):\n            \n            os.remove(best_graphsage_model_path)\n            \n        if os.path.exists(best_link_predictor_model_path):\n            os.remove(best_link_predictor_model_path)\n        print(f\"Replacing models: {best_graphsage_model_path }  {best_link_predictor_model_path}\")\n            \n        best_accuracy  = accuracy\n        best_graphsage_model_path      = f\"GraphSage_epoch_{epoch}.pt\"\n        best_link_predictor_model_path =  f\"link_predictor_epoch_{epoch}.pt\"\n        print(f\"with: Best models at {best_graphsage_model_path }  {best_link_predictor_model_path}\")\n        save_torch_model(model,         epoch=epoch,PATH=best_graphsage_model_path ,     optimizer=optimizer)\n        save_torch_model(link_predictor,epoch=epoch,PATH=best_link_predictor_model_path, optimizer=optimizer)\n\n        \n#### Load Best Models ####\n\nprint(f\"Loading best models:  {best_graphsage_model_path }  {best_link_predictor_model_path}\")\ncheckpoint = torch.load(best_graphsage_model_path)\nmodel.load_state_dict(checkpoint['model_state_dict'])\n\ncheckpoint = torch.load(best_link_predictor_model_path)\nlink_predictor.load_state_dict(checkpoint['model_state_dict'])\n\ndel checkpoint\n\n\n\n\n\nEpoch 1: loss: 1.38448\nYoudens  index: 0.5037 Sensitivity: 0.3319 Specificity: 0.6824\n\n\n\n\n\n\n\n\n\nReplacing models:   \nwith: Best models at GraphSage_epoch_1.pt  link_predictor_epoch_1.pt\nSaving Model in Path GraphSage_epoch_1.pt\nSaving Model in Path link_predictor_epoch_1.pt\n\n\n\n\n\nEpoch 2: loss: 1.38614\nSensitivity (poss_acc):0.8252 Specificity (negative_acc):0.2117 accuracy:0.5184\nReplacing models: GraphSage_epoch_1.pt  link_predictor_epoch_1.pt\nwith: Best models at GraphSage_epoch_2.pt  link_predictor_epoch_2.pt\nSaving Model in Path GraphSage_epoch_2.pt\nSaving Model in Path link_predictor_epoch_2.pt\n\n\n\n\n\nEpoch 3: loss: 1.38463\nSensitivity (poss_acc):0.9350 Specificity (negative_acc):0.2309 accuracy:0.5829\nReplacing models: GraphSage_epoch_2.pt  link_predictor_epoch_2.pt\nwith: Best models at GraphSage_epoch_3.pt  link_predictor_epoch_3.pt\nSaving Model in Path GraphSage_epoch_3.pt\nSaving Model in Path link_predictor_epoch_3.pt\n\n\n\n\n\nEpoch 4: loss: 1.3332\nSensitivity (poss_acc):0.8810 Specificity (negative_acc):0.3632 accuracy:0.6221\nReplacing models: GraphSage_epoch_3.pt  link_predictor_epoch_3.pt\nwith: Best models at GraphSage_epoch_4.pt  link_predictor_epoch_4.pt\nSaving Model in Path GraphSage_epoch_4.pt\nSaving Model in Path link_predictor_epoch_4.pt\n\n\n\n\n\nEpoch 5: loss: 1.23284\nSensitivity (poss_acc):0.9000 Specificity (negative_acc):0.3776 accuracy:0.6388\nReplacing models: GraphSage_epoch_4.pt  link_predictor_epoch_4.pt\nwith: Best models at GraphSage_epoch_5.pt  link_predictor_epoch_5.pt\nSaving Model in Path GraphSage_epoch_5.pt\nSaving Model in Path link_predictor_epoch_5.pt\n\n\n\n\n\nEpoch 6: loss: 1.24907\nSensitivity (poss_acc):0.5224 Specificity (negative_acc):0.5986 accuracy:0.5605\n\n\n\n\n\nEpoch 7: loss: 1.28041\nSensitivity (poss_acc):0.8782 Specificity (negative_acc):0.3660 accuracy:0.6221\n\n\n\n\n\nEpoch 8: loss: 1.20592\nSensitivity (poss_acc):0.9635 Specificity (negative_acc):0.3077 accuracy:0.6356\n\n\n\n\n\nEpoch 9: loss: 1.12853\nSensitivity (poss_acc):0.9092 Specificity (negative_acc):0.4707 accuracy:0.6900\nReplacing models: GraphSage_epoch_5.pt  link_predictor_epoch_5.pt\nwith: Best models at GraphSage_epoch_9.pt  link_predictor_epoch_9.pt\nSaving Model in Path GraphSage_epoch_9.pt\nSaving Model in Path link_predictor_epoch_9.pt\n\n\n\n\n\nEpoch 10: loss: 1.13204\nSensitivity (poss_acc):0.9162 Specificity (negative_acc):0.4552 accuracy:0.6857\n\n\n\n\n\nEpoch 11: loss: 1.08384\nSensitivity (poss_acc):0.6898 Specificity (negative_acc):0.6484 accuracy:0.6691\n\n\n\n\n\nEpoch 12: loss: 1.06029\nSensitivity (poss_acc):0.7078 Specificity (negative_acc):0.6942 accuracy:0.7010\nReplacing models: GraphSage_epoch_9.pt  link_predictor_epoch_9.pt\nwith: Best models at GraphSage_epoch_12.pt  link_predictor_epoch_12.pt\nSaving Model in Path GraphSage_epoch_12.pt\nSaving Model in Path link_predictor_epoch_12.pt\n\n\n\n\n\nEpoch 13: loss: 1.06227\nSensitivity (poss_acc):0.7683 Specificity (negative_acc):0.6015 accuracy:0.6849\n\n\n\n\n\nEpoch 14: loss: 1.04963\nSensitivity (poss_acc):0.8731 Specificity (negative_acc):0.5512 accuracy:0.7122\nReplacing models: GraphSage_epoch_12.pt  link_predictor_epoch_12.pt\nwith: Best models at GraphSage_epoch_14.pt  link_predictor_epoch_14.pt\nSaving Model in Path GraphSage_epoch_14.pt\nSaving Model in Path link_predictor_epoch_14.pt\n\n\n\n\n\nEpoch 15: loss: 1.01064\nSensitivity (poss_acc):0.8945 Specificity (negative_acc):0.4840 accuracy:0.6893\n\n\n\n\n\nEpoch 16: loss: 1.02564\nSensitivity (poss_acc):0.7047 Specificity (negative_acc):0.7023 accuracy:0.7035\n\n\n\n\n\nEpoch 17: loss: 0.98034\nSensitivity (poss_acc):0.8704 Specificity (negative_acc):0.5577 accuracy:0.7140\nReplacing models: GraphSage_epoch_14.pt  link_predictor_epoch_14.pt\nwith: Best models at GraphSage_epoch_17.pt  link_predictor_epoch_17.pt\nSaving Model in Path GraphSage_epoch_17.pt\nSaving Model in Path link_predictor_epoch_17.pt\n\n\n\n\n\nEpoch 18: loss: 0.98538\nSensitivity (poss_acc):0.7756 Specificity (negative_acc):0.6488 accuracy:0.7122\n\n\n\n\n\nEpoch 19: loss: 0.97591\nSensitivity (poss_acc):0.7789 Specificity (negative_acc):0.6861 accuracy:0.7325\nReplacing models: GraphSage_epoch_17.pt  link_predictor_epoch_17.pt\nwith: Best models at GraphSage_epoch_19.pt  link_predictor_epoch_19.pt\nSaving Model in Path GraphSage_epoch_19.pt\nSaving Model in Path link_predictor_epoch_19.pt\n\n\n\n\n\nEpoch 20: loss: 0.99183\nYoudens  index: 0.6296 Sensitivity: 0.7128 Specificity: 0.7018\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 21: loss: 0.94824\nSensitivity (poss_acc):0.8119 Specificity (negative_acc):0.6123 accuracy:0.7121\n\n\n\n\n\nEpoch 22: loss: 0.95164\nSensitivity (poss_acc):0.8740 Specificity (negative_acc):0.5648 accuracy:0.7194\n\n\n\n\n\nEpoch 23: loss: 0.92309\nSensitivity (poss_acc):0.8093 Specificity (negative_acc):0.6073 accuracy:0.7083\n\n\n\n\n\nEpoch 24: loss: 0.90591\nSensitivity (poss_acc):0.8679 Specificity (negative_acc):0.5768 accuracy:0.7223\n\n\n\n\n\nEpoch 25: loss: 0.89268\nSensitivity (poss_acc):0.8058 Specificity (negative_acc):0.6467 accuracy:0.7263\n\n\n\n\n\nEpoch 26: loss: 0.90408\nSensitivity (poss_acc):0.8594 Specificity (negative_acc):0.5980 accuracy:0.7287\n\n\n\n\n\nEpoch 27: loss: 0.88659\nSensitivity (poss_acc):0.7914 Specificity (negative_acc):0.6508 accuracy:0.7211\n\n\n\n\n\nEpoch 28: loss: 0.86054\nSensitivity (poss_acc):0.8014 Specificity (negative_acc):0.6656 accuracy:0.7335\nReplacing models: GraphSage_epoch_19.pt  link_predictor_epoch_19.pt\nwith: Best models at GraphSage_epoch_28.pt  link_predictor_epoch_28.pt\nSaving Model in Path GraphSage_epoch_28.pt\nSaving Model in Path link_predictor_epoch_28.pt\n\n\n\n\n\nEpoch 29: loss: 0.8593\nSensitivity (poss_acc):0.8800 Specificity (negative_acc):0.6003 accuracy:0.7401\nReplacing models: GraphSage_epoch_28.pt  link_predictor_epoch_28.pt\nwith: Best models at GraphSage_epoch_29.pt  link_predictor_epoch_29.pt\nSaving Model in Path GraphSage_epoch_29.pt\nSaving Model in Path link_predictor_epoch_29.pt\n\n\n\n\n\nEpoch 30: loss: 0.84031\nSensitivity (poss_acc):0.7682 Specificity (negative_acc):0.6855 accuracy:0.7269\n\n\n\n\n\nEpoch 31: loss: 0.82922\nSensitivity (poss_acc):0.8506 Specificity (negative_acc):0.5955 accuracy:0.7230\n\n\n\n\n\nEpoch 32: loss: 0.89779\nSensitivity (poss_acc):0.9056 Specificity (negative_acc):0.5731 accuracy:0.7393\n\n\n\n\n\nEpoch 33: loss: 0.81816\nSensitivity (poss_acc):0.9166 Specificity (negative_acc):0.5448 accuracy:0.7307\n\n\n\n\n\nEpoch 34: loss: 0.83937\nSensitivity (poss_acc):0.8341 Specificity (negative_acc):0.6407 accuracy:0.7374\n\n\n\n\n\nEpoch 35: loss: 0.80066\nSensitivity (poss_acc):0.8574 Specificity (negative_acc):0.6354 accuracy:0.7464\nReplacing models: GraphSage_epoch_29.pt  link_predictor_epoch_29.pt\nwith: Best models at GraphSage_epoch_35.pt  link_predictor_epoch_35.pt\nSaving Model in Path GraphSage_epoch_35.pt\nSaving Model in Path link_predictor_epoch_35.pt\n\n\n\n\n\nEpoch 36: loss: 0.82452\nSensitivity (poss_acc):0.8161 Specificity (negative_acc):0.6823 accuracy:0.7492\nReplacing models: GraphSage_epoch_35.pt  link_predictor_epoch_35.pt\nwith: Best models at GraphSage_epoch_36.pt  link_predictor_epoch_36.pt\nSaving Model in Path GraphSage_epoch_36.pt\nSaving Model in Path link_predictor_epoch_36.pt\n\n\n\n\n\nEpoch 37: loss: 0.795\nSensitivity (poss_acc):0.8560 Specificity (negative_acc):0.6546 accuracy:0.7553\nReplacing models: GraphSage_epoch_36.pt  link_predictor_epoch_36.pt\nwith: Best models at GraphSage_epoch_37.pt  link_predictor_epoch_37.pt\nSaving Model in Path GraphSage_epoch_37.pt\nSaving Model in Path link_predictor_epoch_37.pt\n\n\n\n\n\nEpoch 38: loss: 0.775\nSensitivity (poss_acc):0.7666 Specificity (negative_acc):0.7051 accuracy:0.7358\n\n\n\n\n\nEpoch 39: loss: 0.77688\nSensitivity (poss_acc):0.8864 Specificity (negative_acc):0.5919 accuracy:0.7391\n\n\n\n\n\nEpoch 40: loss: 0.77014\nYoudens  index: 0.5298 Sensitivity: 0.825 Specificity: 0.6481\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 41: loss: 0.77564\nSensitivity (poss_acc):0.8507 Specificity (negative_acc):0.6416 accuracy:0.7462\n\n\n\n\n\nEpoch 42: loss: 0.76536\nSensitivity (poss_acc):0.8773 Specificity (negative_acc):0.6335 accuracy:0.7554\nReplacing models: GraphSage_epoch_37.pt  link_predictor_epoch_37.pt\nwith: Best models at GraphSage_epoch_42.pt  link_predictor_epoch_42.pt\nSaving Model in Path GraphSage_epoch_42.pt\nSaving Model in Path link_predictor_epoch_42.pt\n\n\n\n\n\nEpoch 43: loss: 0.75756\nSensitivity (poss_acc):0.8017 Specificity (negative_acc):0.6687 accuracy:0.7352\n\n\n\n\n\nEpoch 44: loss: 0.77873\nSensitivity (poss_acc):0.8070 Specificity (negative_acc):0.7004 accuracy:0.7537\n\n\n\n\n\nEpoch 45: loss: 0.75666\nSensitivity (poss_acc):0.8784 Specificity (negative_acc):0.6495 accuracy:0.7639\nReplacing models: GraphSage_epoch_42.pt  link_predictor_epoch_42.pt\nwith: Best models at GraphSage_epoch_45.pt  link_predictor_epoch_45.pt\nSaving Model in Path GraphSage_epoch_45.pt\nSaving Model in Path link_predictor_epoch_45.pt\n\n\n\n\n\nEpoch 46: loss: 0.73604\nSensitivity (poss_acc):0.8434 Specificity (negative_acc):0.6621 accuracy:0.7527\n\n\n\n\n\nEpoch 47: loss: 0.71601\nSensitivity (poss_acc):0.8178 Specificity (negative_acc):0.6714 accuracy:0.7446\n\n\n\n\n\nEpoch 48: loss: 0.73447\nSensitivity (poss_acc):0.8929 Specificity (negative_acc):0.6169 accuracy:0.7549\n\n\n\n\n\nEpoch 49: loss: 0.70766\nSensitivity (poss_acc):0.8879 Specificity (negative_acc):0.6044 accuracy:0.7461\n\n\n\n\n\nEpoch 50: loss: 0.721\nSensitivity (poss_acc):0.7702 Specificity (negative_acc):0.7172 accuracy:0.7437\n\n\n\n\n\nEpoch 51: loss: 0.70365\nSensitivity (poss_acc):0.8941 Specificity (negative_acc):0.5911 accuracy:0.7426\n\n\n\n\n\nEpoch 52: loss: 0.71855\nSensitivity (poss_acc):0.8371 Specificity (negative_acc):0.6921 accuracy:0.7646\nReplacing models: GraphSage_epoch_45.pt  link_predictor_epoch_45.pt\nwith: Best models at GraphSage_epoch_52.pt  link_predictor_epoch_52.pt\nSaving Model in Path GraphSage_epoch_52.pt\nSaving Model in Path link_predictor_epoch_52.pt\n\n\n\n\n\nEpoch 53: loss: 0.70317\nSensitivity (poss_acc):0.8851 Specificity (negative_acc):0.6400 accuracy:0.7626\n\n\n\n\n\nEpoch 54: loss: 0.68315\nSensitivity (poss_acc):0.8620 Specificity (negative_acc):0.6639 accuracy:0.7629\n\n\n\n\n\nEpoch 55: loss: 0.68344\nSensitivity (poss_acc):0.9168 Specificity (negative_acc):0.6041 accuracy:0.7605\n\n\n\n\n\nEpoch 56: loss: 0.72247\nSensitivity (poss_acc):0.8332 Specificity (negative_acc):0.6505 accuracy:0.7419\n\n\n\n\n\nEpoch 57: loss: 0.68305\nSensitivity (poss_acc):0.7903 Specificity (negative_acc):0.6858 accuracy:0.7380\n\n\n\n\n\nEpoch 58: loss: 0.72189\nSensitivity (poss_acc):0.8622 Specificity (negative_acc):0.6615 accuracy:0.7618\n\n\n\n\n\nEpoch 59: loss: 0.71029\nSensitivity (poss_acc):0.8834 Specificity (negative_acc):0.6440 accuracy:0.7637\n\n\n\n\n\nEpoch 60: loss: 0.68376\nYoudens  index: 0.6426 Sensitivity: 0.7956 Specificity: 0.7022\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 61: loss: 0.66578\nSensitivity (poss_acc):0.8348 Specificity (negative_acc):0.7032 accuracy:0.7690\nReplacing models: GraphSage_epoch_52.pt  link_predictor_epoch_52.pt\nwith: Best models at GraphSage_epoch_61.pt  link_predictor_epoch_61.pt\nSaving Model in Path GraphSage_epoch_61.pt\nSaving Model in Path link_predictor_epoch_61.pt\n\n\n\n\n\nEpoch 62: loss: 0.6673\nSensitivity (poss_acc):0.8208 Specificity (negative_acc):0.7111 accuracy:0.7659\n\n\n\n\n\nEpoch 63: loss: 0.68062\nSensitivity (poss_acc):0.8707 Specificity (negative_acc):0.6446 accuracy:0.7576\n\n\n\n\n\nEpoch 64: loss: 0.6795\nSensitivity (poss_acc):0.8385 Specificity (negative_acc):0.6963 accuracy:0.7674\n\n\n\n\n\nEpoch 65: loss: 0.66361\nSensitivity (poss_acc):0.8480 Specificity (negative_acc):0.6889 accuracy:0.7684\n\n\n\n\n\nEpoch 66: loss: 0.62076\nSensitivity (poss_acc):0.8800 Specificity (negative_acc):0.6549 accuracy:0.7674\n\n\n\n\n\nEpoch 67: loss: 0.65321\nSensitivity (poss_acc):0.8725 Specificity (negative_acc):0.6989 accuracy:0.7857\nReplacing models: GraphSage_epoch_61.pt  link_predictor_epoch_61.pt\nwith: Best models at GraphSage_epoch_67.pt  link_predictor_epoch_67.pt\nSaving Model in Path GraphSage_epoch_67.pt\nSaving Model in Path link_predictor_epoch_67.pt\n\n\n\n\n\nEpoch 68: loss: 0.65814\nSensitivity (poss_acc):0.8510 Specificity (negative_acc):0.6696 accuracy:0.7603\n\n\n\n\n\nEpoch 69: loss: 0.61733\nSensitivity (poss_acc):0.8883 Specificity (negative_acc):0.6437 accuracy:0.7660\n\n\n\n\n\nEpoch 70: loss: 0.62729\nSensitivity (poss_acc):0.8375 Specificity (negative_acc):0.6697 accuracy:0.7536\n\n\n\n\n\nEpoch 71: loss: 0.63786\nSensitivity (poss_acc):0.8540 Specificity (negative_acc):0.6948 accuracy:0.7744\n\n\n\n\n\nEpoch 72: loss: 0.61542\nSensitivity (poss_acc):0.8660 Specificity (negative_acc):0.6844 accuracy:0.7752\n\n\n\n\n\nEpoch 73: loss: 0.63899\nSensitivity (poss_acc):0.9172 Specificity (negative_acc):0.6451 accuracy:0.7812\n\n\n\n\n\nEpoch 74: loss: 0.62225\nSensitivity (poss_acc):0.9224 Specificity (negative_acc):0.6045 accuracy:0.7634\n\n\n\n\n\nEpoch 75: loss: 0.61122\nSensitivity (poss_acc):0.8573 Specificity (negative_acc):0.6775 accuracy:0.7674\n\n\n\n\n\nEpoch 76: loss: 0.63183\nSensitivity (poss_acc):0.8417 Specificity (negative_acc):0.6718 accuracy:0.7568\n\n\n\n\n\nEpoch 77: loss: 0.60156\nSensitivity (poss_acc):0.8331 Specificity (negative_acc):0.7251 accuracy:0.7791\n\n\n\n\n\nEpoch 78: loss: 0.60803\nSensitivity (poss_acc):0.8507 Specificity (negative_acc):0.6427 accuracy:0.7467\n\n\n\n\n\nEpoch 79: loss: 0.62981\nSensitivity (poss_acc):0.8813 Specificity (negative_acc):0.6210 accuracy:0.7512\n\n\n\n\n\nEpoch 80: loss: 0.62121\nYoudens  index: 0.5663 Sensitivity: 0.8471 Specificity: 0.6592\n\n\n\n\n\n\n\n\n\nReplacing models: GraphSage_epoch_67.pt  link_predictor_epoch_67.pt\nwith: Best models at GraphSage_epoch_80.pt  link_predictor_epoch_80.pt\nSaving Model in Path GraphSage_epoch_80.pt\nSaving Model in Path link_predictor_epoch_80.pt\n\n\n\n\n\nEpoch 81: loss: 0.60267\nSensitivity (poss_acc):0.9296 Specificity (negative_acc):0.6217 accuracy:0.7756\n\n\n\n\n\nEpoch 82: loss: 0.59262\nSensitivity (poss_acc):0.9133 Specificity (negative_acc):0.6490 accuracy:0.7811\n\n\n\n\n\nEpoch 83: loss: 0.57688\nSensitivity (poss_acc):0.8874 Specificity (negative_acc):0.6519 accuracy:0.7697\n\n\n\n\n\nEpoch 84: loss: 0.61293\nSensitivity (poss_acc):0.9245 Specificity (negative_acc):0.6087 accuracy:0.7666\n\n\n\n\n\nEpoch 85: loss: 0.60371\nSensitivity (poss_acc):0.8326 Specificity (negative_acc):0.7372 accuracy:0.7849\n\n\n\n\n\nEpoch 86: loss: 0.58238\nSensitivity (poss_acc):0.8584 Specificity (negative_acc):0.7173 accuracy:0.7879\n\n\n\n\n\nEpoch 87: loss: 0.57882\nSensitivity (poss_acc):0.8350 Specificity (negative_acc):0.7388 accuracy:0.7869\n\n\n\n\n\nEpoch 88: loss: 0.58094\nSensitivity (poss_acc):0.9041 Specificity (negative_acc):0.6514 accuracy:0.7778\n\n\n\n\n\nEpoch 89: loss: 0.57736\nSensitivity (poss_acc):0.9035 Specificity (negative_acc):0.6471 accuracy:0.7753\n\n\n\n\n\nEpoch 90: loss: 0.59027\nSensitivity (poss_acc):0.8923 Specificity (negative_acc):0.6594 accuracy:0.7759\n\n\n\n\n\nEpoch 91: loss: 0.56539\nSensitivity (poss_acc):0.8236 Specificity (negative_acc):0.7368 accuracy:0.7802\n\n\n\n\n\nEpoch 92: loss: 0.5552\nSensitivity (poss_acc):0.8738 Specificity (negative_acc):0.6527 accuracy:0.7633\n\n\n\n\n\nEpoch 93: loss: 0.57432\nSensitivity (poss_acc):0.9030 Specificity (negative_acc):0.6750 accuracy:0.7890\n\n\n\n\n\nEpoch 94: loss: 0.56306\nSensitivity (poss_acc):0.9061 Specificity (negative_acc):0.6587 accuracy:0.7824\n\n\n\n\n\nEpoch 95: loss: 0.55674\nSensitivity (poss_acc):0.9025 Specificity (negative_acc):0.6688 accuracy:0.7857\n\n\n\n\n\nEpoch 96: loss: 0.55312\nSensitivity (poss_acc):0.8650 Specificity (negative_acc):0.7189 accuracy:0.7920\n\n\n\n\n\nEpoch 97: loss: 0.54806\nSensitivity (poss_acc):0.9043 Specificity (negative_acc):0.6350 accuracy:0.7697\n\n\n\n\n\nEpoch 98: loss: 0.54841\nSensitivity (poss_acc):0.8942 Specificity (negative_acc):0.6665 accuracy:0.7803\n\n\n\n\n\nEpoch 99: loss: 0.55615\nSensitivity (poss_acc):0.9013 Specificity (negative_acc):0.6701 accuracy:0.7857\n\n\n\n\n\nEpoch 100: loss: 0.54454\nYoudens  index: 0.4448 Sensitivity: 0.8937 Specificity: 0.6138\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 101: loss: 0.54446\nSensitivity (poss_acc):0.8894 Specificity (negative_acc):0.6551 accuracy:0.7723\n\n\n\n\n\nEpoch 102: loss: 0.5723\nSensitivity (poss_acc):0.8506 Specificity (negative_acc):0.6718 accuracy:0.7612\n\n\n\n\n\nEpoch 103: loss: 0.56733\nSensitivity (poss_acc):0.8526 Specificity (negative_acc):0.6583 accuracy:0.7554\n\n\n\n\n\nEpoch 104: loss: 0.58279\nSensitivity (poss_acc):0.8929 Specificity (negative_acc):0.6595 accuracy:0.7762\n\n\n\n\n\nEpoch 105: loss: 0.55634\nSensitivity (poss_acc):0.8726 Specificity (negative_acc):0.7020 accuracy:0.7873\n\n\n\n\n\nEpoch 106: loss: 0.52631\nSensitivity (poss_acc):0.8754 Specificity (negative_acc):0.6962 accuracy:0.7858\n\n\n\n\n\nEpoch 107: loss: 0.53896\nSensitivity (poss_acc):0.9066 Specificity (negative_acc):0.6293 accuracy:0.7680\n\n\n\n\n\nEpoch 108: loss: 0.54728\nSensitivity (poss_acc):0.8757 Specificity (negative_acc):0.6988 accuracy:0.7872\n\n\n\n\n\nEpoch 109: loss: 0.54289\nSensitivity (poss_acc):0.8233 Specificity (negative_acc):0.7388 accuracy:0.7811\n\n\n\n\n\nEpoch 110: loss: 0.57868\nSensitivity (poss_acc):0.8988 Specificity (negative_acc):0.6629 accuracy:0.7808\n\n\n\n\n\nEpoch 111: loss: 0.54878\nSensitivity (poss_acc):0.8878 Specificity (negative_acc):0.6634 accuracy:0.7756\n\n\n\n\n\nEpoch 112: loss: 0.52526\nSensitivity (poss_acc):0.8668 Specificity (negative_acc):0.6882 accuracy:0.7775\n\n\n\n\n\nEpoch 113: loss: 0.50896\nSensitivity (poss_acc):0.8924 Specificity (negative_acc):0.6953 accuracy:0.7939\nReplacing models: GraphSage_epoch_80.pt  link_predictor_epoch_80.pt\nwith: Best models at GraphSage_epoch_113.pt  link_predictor_epoch_113.pt\nSaving Model in Path GraphSage_epoch_113.pt\nSaving Model in Path link_predictor_epoch_113.pt\n\n\n\n\n\nEpoch 114: loss: 0.50759\nSensitivity (poss_acc):0.8995 Specificity (negative_acc):0.6727 accuracy:0.7861\n\n\n\n\n\nEpoch 115: loss: 0.50268\nSensitivity (poss_acc):0.8969 Specificity (negative_acc):0.6606 accuracy:0.7788\n\n\n\n\n\nEpoch 116: loss: 0.50792\nSensitivity (poss_acc):0.9244 Specificity (negative_acc):0.6078 accuracy:0.7661\n\n\n\n\n\nEpoch 117: loss: 0.52405\nSensitivity (poss_acc):0.9112 Specificity (negative_acc):0.6921 accuracy:0.8017\nReplacing models: GraphSage_epoch_113.pt  link_predictor_epoch_113.pt\nwith: Best models at GraphSage_epoch_117.pt  link_predictor_epoch_117.pt\nSaving Model in Path GraphSage_epoch_117.pt\nSaving Model in Path link_predictor_epoch_117.pt\n\n\n\n\n\nEpoch 118: loss: 0.51385\nSensitivity (poss_acc):0.9144 Specificity (negative_acc):0.6564 accuracy:0.7854\n\n\n\n\n\nEpoch 119: loss: 0.50277\nSensitivity (poss_acc):0.7894 Specificity (negative_acc):0.7720 accuracy:0.7807\n\n\n\n\n\nEpoch 120: loss: 0.55554\nYoudens  index: 0.8903 Sensitivity: 0.7731 Specificity: 0.7513\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 121: loss: 0.52758\nSensitivity (poss_acc):0.8491 Specificity (negative_acc):0.7034 accuracy:0.7762\n\n\n\n\n\nEpoch 122: loss: 0.51773\nSensitivity (poss_acc):0.8961 Specificity (negative_acc):0.6889 accuracy:0.7925\n\n\n\n\n\nEpoch 123: loss: 0.5199\nSensitivity (poss_acc):0.9011 Specificity (negative_acc):0.6201 accuracy:0.7606\n\n\n\n\n\nEpoch 124: loss: 0.49275\nSensitivity (poss_acc):0.9145 Specificity (negative_acc):0.6465 accuracy:0.7805\n\n\n\n\n\nEpoch 125: loss: 0.48386\nSensitivity (poss_acc):0.9110 Specificity (negative_acc):0.6463 accuracy:0.7786\n\n\n\n\n\nEpoch 126: loss: 0.48924\nSensitivity (poss_acc):0.8364 Specificity (negative_acc):0.7269 accuracy:0.7817\n\n\n\n\n\nEpoch 127: loss: 0.51036\nSensitivity (poss_acc):0.8763 Specificity (negative_acc):0.7330 accuracy:0.8047\nReplacing models: GraphSage_epoch_117.pt  link_predictor_epoch_117.pt\nwith: Best models at GraphSage_epoch_127.pt  link_predictor_epoch_127.pt\nSaving Model in Path GraphSage_epoch_127.pt\nSaving Model in Path link_predictor_epoch_127.pt\n\n\n\n\n\nEpoch 128: loss: 0.49851\nSensitivity (poss_acc):0.8669 Specificity (negative_acc):0.7206 accuracy:0.7937\n\n\n\n\n\nEpoch 129: loss: 0.50085\nSensitivity (poss_acc):0.9474 Specificity (negative_acc):0.6183 accuracy:0.7829\n\n\n\n\n\nEpoch 130: loss: 0.54889\nSensitivity (poss_acc):0.6257 Specificity (negative_acc):0.8309 accuracy:0.7283\n\n\n\n\n\nEpoch 131: loss: 0.55055\nSensitivity (poss_acc):0.8653 Specificity (negative_acc):0.6874 accuracy:0.7763\n\n\n\n\n\nEpoch 132: loss: 0.51206\nSensitivity (poss_acc):0.9042 Specificity (negative_acc):0.6420 accuracy:0.7731\n\n\n\n\n\nEpoch 133: loss: 0.51192\nSensitivity (poss_acc):0.8775 Specificity (negative_acc):0.6130 accuracy:0.7452\n\n\n\n\n\nEpoch 134: loss: 0.50242\nSensitivity (poss_acc):0.8995 Specificity (negative_acc):0.6712 accuracy:0.7854\n\n\n\n\n\nEpoch 135: loss: 0.48485\nSensitivity (poss_acc):0.9119 Specificity (negative_acc):0.6743 accuracy:0.7931\n\n\n\n\n\nEpoch 136: loss: 0.48699\nSensitivity (poss_acc):0.8436 Specificity (negative_acc):0.7155 accuracy:0.7796\n\n\n\n\n\nEpoch 137: loss: 0.49194\nSensitivity (poss_acc):0.8512 Specificity (negative_acc):0.6830 accuracy:0.7671\n\n\n\n\n\nEpoch 138: loss: 0.50101\nSensitivity (poss_acc):0.9332 Specificity (negative_acc):0.6543 accuracy:0.7938\n\n\n\n\n\nEpoch 139: loss: 0.47573\nSensitivity (poss_acc):0.8989 Specificity (negative_acc):0.6814 accuracy:0.7901\n\n\n\n\n\nEpoch 140: loss: 0.49843\nYoudens  index: 0.8106 Sensitivity: 0.7878 Specificity: 0.7682\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 141: loss: 0.49341\nSensitivity (poss_acc):0.9493 Specificity (negative_acc):0.6303 accuracy:0.7898\n\n\n\n\n\nEpoch 142: loss: 0.49255\nSensitivity (poss_acc):0.9033 Specificity (negative_acc):0.6476 accuracy:0.7754\n\n\n\n\n\nEpoch 143: loss: 0.50336\nSensitivity (poss_acc):0.9380 Specificity (negative_acc):0.5859 accuracy:0.7620\n\n\n\n\n\nEpoch 144: loss: 0.50648\nSensitivity (poss_acc):0.8858 Specificity (negative_acc):0.7136 accuracy:0.7997\n\n\n\n\n\nEpoch 145: loss: 0.47623\nSensitivity (poss_acc):0.9039 Specificity (negative_acc):0.6729 accuracy:0.7884\n\n\n\n\n\nEpoch 146: loss: 0.4612\nSensitivity (poss_acc):0.8685 Specificity (negative_acc):0.7316 accuracy:0.8000\n\n\n\n\n\nEpoch 147: loss: 0.4581\nSensitivity (poss_acc):0.9303 Specificity (negative_acc):0.6462 accuracy:0.7883\n\n\n\n\n\nEpoch 148: loss: 0.48994\nSensitivity (poss_acc):0.8567 Specificity (negative_acc):0.7341 accuracy:0.7954\n\n\n\n\n\nEpoch 149: loss: 0.48878\nSensitivity (poss_acc):0.9125 Specificity (negative_acc):0.6570 accuracy:0.7847\n\n\n\n\n\nEpoch 150: loss: 0.53287\nSensitivity (poss_acc):0.8979 Specificity (negative_acc):0.6948 accuracy:0.7963\n\n\n\n\n\nEpoch 151: loss: 0.49147\nSensitivity (poss_acc):0.9002 Specificity (negative_acc):0.6850 accuracy:0.7926\n\n\n\n\n\nEpoch 152: loss: 0.46707\nSensitivity (poss_acc):0.9427 Specificity (negative_acc):0.6313 accuracy:0.7870\n\n\n\n\n\nEpoch 153: loss: 0.48187\nSensitivity (poss_acc):0.9323 Specificity (negative_acc):0.6508 accuracy:0.7916\n\n\n\n\n\nEpoch 154: loss: 0.47412\nSensitivity (poss_acc):0.9231 Specificity (negative_acc):0.6634 accuracy:0.7933\n\n\n\n\n\nEpoch 155: loss: 0.46019\nSensitivity (poss_acc):0.9138 Specificity (negative_acc):0.6684 accuracy:0.7911\n\n\n\n\n\nEpoch 156: loss: 0.45743\nSensitivity (poss_acc):0.8920 Specificity (negative_acc):0.6928 accuracy:0.7924\n\n\n\n\n\nEpoch 157: loss: 0.46888\nSensitivity (poss_acc):0.9020 Specificity (negative_acc):0.7071 accuracy:0.8045\n\n\n\n\n\nEpoch 158: loss: 0.45439\nSensitivity (poss_acc):0.9209 Specificity (negative_acc):0.6748 accuracy:0.7979\n\n\n\n\n\nEpoch 159: loss: 0.45289\nSensitivity (poss_acc):0.8891 Specificity (negative_acc):0.6905 accuracy:0.7898\n\n\n\n\n\nEpoch 160: loss: 0.44807\nYoudens  index: 0.8163 Sensitivity: 0.8043 Specificity: 0.7319\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 161: loss: 0.49089\nSensitivity (poss_acc):0.9219 Specificity (negative_acc):0.6560 accuracy:0.7890\n\n\n\n\n\nEpoch 162: loss: 0.47265\nSensitivity (poss_acc):0.9236 Specificity (negative_acc):0.6515 accuracy:0.7875\n\n\n\n\n\nEpoch 163: loss: 0.44\nSensitivity (poss_acc):0.9045 Specificity (negative_acc):0.6998 accuracy:0.8021\n\n\n\n\n\nEpoch 164: loss: 0.44266\nSensitivity (poss_acc):0.8685 Specificity (negative_acc):0.7099 accuracy:0.7892\n\n\n\n\n\nEpoch 165: loss: 0.45557\nSensitivity (poss_acc):0.9253 Specificity (negative_acc):0.6358 accuracy:0.7805\n\n\n\n\n\nEpoch 166: loss: 0.44287\nSensitivity (poss_acc):0.8703 Specificity (negative_acc):0.7072 accuracy:0.7888\n\n\n\n\n\nEpoch 167: loss: 0.48216\nSensitivity (poss_acc):0.9269 Specificity (negative_acc):0.6661 accuracy:0.7965\n\n\n\n\n\nEpoch 168: loss: 0.47142\nSensitivity (poss_acc):0.9055 Specificity (negative_acc):0.7056 accuracy:0.8055\nReplacing models: GraphSage_epoch_127.pt  link_predictor_epoch_127.pt\nwith: Best models at GraphSage_epoch_168.pt  link_predictor_epoch_168.pt\nSaving Model in Path GraphSage_epoch_168.pt\nSaving Model in Path link_predictor_epoch_168.pt\n\n\n\n\n\nEpoch 169: loss: 0.43165\nSensitivity (poss_acc):0.9116 Specificity (negative_acc):0.6951 accuracy:0.8033\n\n\n\n\n\nEpoch 170: loss: 0.47262\nSensitivity (poss_acc):0.8697 Specificity (negative_acc):0.6667 accuracy:0.7682\n\n\n\n\n\nEpoch 171: loss: 0.61125\nSensitivity (poss_acc):0.9161 Specificity (negative_acc):0.6978 accuracy:0.8070\nReplacing models: GraphSage_epoch_168.pt  link_predictor_epoch_168.pt\nwith: Best models at GraphSage_epoch_171.pt  link_predictor_epoch_171.pt\nSaving Model in Path GraphSage_epoch_171.pt\nSaving Model in Path link_predictor_epoch_171.pt\n\n\n\n\n\nEpoch 172: loss: 0.46705\nSensitivity (poss_acc):0.9193 Specificity (negative_acc):0.6860 accuracy:0.8027\n\n\n\n\n\nEpoch 173: loss: 0.44765\nSensitivity (poss_acc):0.9180 Specificity (negative_acc):0.6723 accuracy:0.7951\n\n\n\n\n\nEpoch 174: loss: 0.43044\nSensitivity (poss_acc):0.9091 Specificity (negative_acc):0.6971 accuracy:0.8031\n\n\n\n\n\nEpoch 175: loss: 0.45681\nSensitivity (poss_acc):0.9198 Specificity (negative_acc):0.6693 accuracy:0.7945\n\n\n\n\n\nEpoch 176: loss: 0.466\nSensitivity (poss_acc):0.8678 Specificity (negative_acc):0.6825 accuracy:0.7752\n\n\n\n\n\nEpoch 177: loss: 0.54062\nSensitivity (poss_acc):0.9125 Specificity (negative_acc):0.6593 accuracy:0.7859\n\n\n\n\n\nEpoch 178: loss: 0.48161\nSensitivity (poss_acc):0.9141 Specificity (negative_acc):0.6930 accuracy:0.8036\n\n\n\n\n\nEpoch 179: loss: 0.45612\nSensitivity (poss_acc):0.9156 Specificity (negative_acc):0.6663 accuracy:0.7910\n\n\n\n\n\nEpoch 180: loss: 0.43715\nYoudens  index: 0.8723 Sensitivity: 0.8152 Specificity: 0.728\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 181: loss: 0.42755\nSensitivity (poss_acc):0.9248 Specificity (negative_acc):0.6706 accuracy:0.7977\n\n\n\n\n\nEpoch 182: loss: 0.41749\nSensitivity (poss_acc):0.9439 Specificity (negative_acc):0.6517 accuracy:0.7978\n\n\n\n\n\nEpoch 183: loss: 0.42708\nSensitivity (poss_acc):0.8720 Specificity (negative_acc):0.7587 accuracy:0.8154\nReplacing models: GraphSage_epoch_171.pt  link_predictor_epoch_171.pt\nwith: Best models at GraphSage_epoch_183.pt  link_predictor_epoch_183.pt\nSaving Model in Path GraphSage_epoch_183.pt\nSaving Model in Path link_predictor_epoch_183.pt\n\n\n\n\n\nEpoch 184: loss: 0.41298\nSensitivity (poss_acc):0.9118 Specificity (negative_acc):0.7048 accuracy:0.8083\n\n\n\n\n\nEpoch 185: loss: 0.41202\nSensitivity (poss_acc):0.9100 Specificity (negative_acc):0.6900 accuracy:0.8000\n\n\n\n\n\nEpoch 186: loss: 0.40708\nSensitivity (poss_acc):0.9198 Specificity (negative_acc):0.6820 accuracy:0.8009\n\n\n\n\n\nEpoch 187: loss: 0.40626\nSensitivity (poss_acc):0.8890 Specificity (negative_acc):0.7266 accuracy:0.8078\n\n\n\n\n\nEpoch 188: loss: 0.40534\nSensitivity (poss_acc):0.9348 Specificity (negative_acc):0.6586 accuracy:0.7967\n\n\n\n\n\nEpoch 189: loss: 0.4076\nSensitivity (poss_acc):0.9150 Specificity (negative_acc):0.7113 accuracy:0.8132\n\n\n\n\n\nEpoch 190: loss: 0.45307\nSensitivity (poss_acc):0.9209 Specificity (negative_acc):0.6623 accuracy:0.7916\n\n\n\n\n\nEpoch 191: loss: 0.44397\nSensitivity (poss_acc):0.9187 Specificity (negative_acc):0.6886 accuracy:0.8036\n\n\n\n\n\nEpoch 192: loss: 0.42787\nSensitivity (poss_acc):0.9268 Specificity (negative_acc):0.6716 accuracy:0.7992\n\n\n\n\n\nEpoch 193: loss: 0.42432\nSensitivity (poss_acc):0.9124 Specificity (negative_acc):0.7081 accuracy:0.8102\n\n\n\n\n\nEpoch 194: loss: 0.41286\nSensitivity (poss_acc):0.9431 Specificity (negative_acc):0.6466 accuracy:0.7949\n\n\n\n\n\nEpoch 195: loss: 0.3983\nSensitivity (poss_acc):0.8974 Specificity (negative_acc):0.7192 accuracy:0.8083\n\n\n\n\n\nEpoch 196: loss: 0.4047\nSensitivity (poss_acc):0.9017 Specificity (negative_acc):0.7000 accuracy:0.8008\n\n\n\n\n\nEpoch 197: loss: 0.41938\nSensitivity (poss_acc):0.9122 Specificity (negative_acc):0.7020 accuracy:0.8071\n\n\n\n\n\nEpoch 198: loss: 0.41011\nSensitivity (poss_acc):0.8877 Specificity (negative_acc):0.6849 accuracy:0.7863\n\n\n\n\n\nEpoch 199: loss: 0.40851\nSensitivity (poss_acc):0.9508 Specificity (negative_acc):0.6040 accuracy:0.7774\n\n\n\n\n\nEpoch 200: loss: 0.40208\nYoudens  index: 0.8050 Sensitivity: 0.8685 Specificity: 0.6462\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 201: loss: 0.4103\nSensitivity (poss_acc):0.9197 Specificity (negative_acc):0.6839 accuracy:0.8018\n\n\n\n\n\nEpoch 202: loss: 0.40747\nSensitivity (poss_acc):0.8880 Specificity (negative_acc):0.7392 accuracy:0.8136\n\n\n\n\n\nEpoch 203: loss: 0.41031\nSensitivity (poss_acc):0.9370 Specificity (negative_acc):0.6643 accuracy:0.8007\n\n\n\n\n\nEpoch 204: loss: 0.43305\nSensitivity (poss_acc):0.8786 Specificity (negative_acc):0.7546 accuracy:0.8166\nReplacing models: GraphSage_epoch_183.pt  link_predictor_epoch_183.pt\nwith: Best models at GraphSage_epoch_204.pt  link_predictor_epoch_204.pt\nSaving Model in Path GraphSage_epoch_204.pt\nSaving Model in Path link_predictor_epoch_204.pt\n\n\n\n\n\nEpoch 205: loss: 0.42921\nSensitivity (poss_acc):0.9255 Specificity (negative_acc):0.6437 accuracy:0.7846\n\n\n\n\n\nEpoch 206: loss: 0.40325\nSensitivity (poss_acc):0.8794 Specificity (negative_acc):0.7583 accuracy:0.8188\nReplacing models: GraphSage_epoch_204.pt  link_predictor_epoch_204.pt\nwith: Best models at GraphSage_epoch_206.pt  link_predictor_epoch_206.pt\nSaving Model in Path GraphSage_epoch_206.pt\nSaving Model in Path link_predictor_epoch_206.pt\n\n\n\n\n\nEpoch 207: loss: 0.42156\nSensitivity (poss_acc):0.9212 Specificity (negative_acc):0.6752 accuracy:0.7982\n\n\n\n\n\nEpoch 208: loss: 0.41784\nSensitivity (poss_acc):0.9274 Specificity (negative_acc):0.6669 accuracy:0.7972\n\n\n\n\n\nEpoch 209: loss: 0.40038\nSensitivity (poss_acc):0.9144 Specificity (negative_acc):0.7032 accuracy:0.8088\n\n\n\n\n\nEpoch 210: loss: 0.37098\nSensitivity (poss_acc):0.9144 Specificity (negative_acc):0.6935 accuracy:0.8040\n\n\n\n\n\nEpoch 211: loss: 0.36849\nSensitivity (poss_acc):0.9085 Specificity (negative_acc):0.6990 accuracy:0.8037\n\n\n\n\n\nEpoch 212: loss: 0.38473\nSensitivity (poss_acc):0.9147 Specificity (negative_acc):0.7057 accuracy:0.8102\n\n\n\n\n\nEpoch 213: loss: 0.37492\nSensitivity (poss_acc):0.9260 Specificity (negative_acc):0.6797 accuracy:0.8029\n\n\n\n\n\nEpoch 214: loss: 0.3749\nSensitivity (poss_acc):0.9214 Specificity (negative_acc):0.6857 accuracy:0.8036\n\n\n\n\n\nEpoch 215: loss: 0.39814\nSensitivity (poss_acc):0.9321 Specificity (negative_acc):0.6463 accuracy:0.7892\n\n\n\n\n\nEpoch 216: loss: 0.459\nSensitivity (poss_acc):0.9046 Specificity (negative_acc):0.6838 accuracy:0.7942\n\n\n\n\n\nEpoch 217: loss: 0.45932\nSensitivity (poss_acc):0.9157 Specificity (negative_acc):0.7072 accuracy:0.8115\n\n\n\n\n\nEpoch 218: loss: 0.41404\nSensitivity (poss_acc):0.9352 Specificity (negative_acc):0.6760 accuracy:0.8056\n\n\n\n\n\nEpoch 219: loss: 0.39108\nSensitivity (poss_acc):0.8974 Specificity (negative_acc):0.7331 accuracy:0.8152\n\n\n\n\n\nEpoch 220: loss: 0.37651\nYoudens  index: 0.7470 Sensitivity: 0.8334 Specificity: 0.6935\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 221: loss: 0.37296\nSensitivity (poss_acc):0.9149 Specificity (negative_acc):0.6996 accuracy:0.8072\n\n\n\n\n\nEpoch 222: loss: 0.36198\nSensitivity (poss_acc):0.8977 Specificity (negative_acc):0.7271 accuracy:0.8124\n\n\n\n\n\nEpoch 223: loss: 0.36658\nSensitivity (poss_acc):0.9045 Specificity (negative_acc):0.7249 accuracy:0.8147\n\n\n\n\n\nEpoch 224: loss: 0.40081\nSensitivity (poss_acc):0.9213 Specificity (negative_acc):0.6180 accuracy:0.7697\n\n\n\n\n\nEpoch 225: loss: 0.40396\nSensitivity (poss_acc):0.8988 Specificity (negative_acc):0.7054 accuracy:0.8021\n\n\n\n\n\nEpoch 226: loss: 0.37393\nSensitivity (poss_acc):0.9002 Specificity (negative_acc):0.7243 accuracy:0.8123\n\n\n\n\n\nEpoch 227: loss: 0.36643\nSensitivity (poss_acc):0.9167 Specificity (negative_acc):0.7135 accuracy:0.8151\n\n\n\n\n\nEpoch 228: loss: 0.35272\nSensitivity (poss_acc):0.9018 Specificity (negative_acc):0.6904 accuracy:0.7961\n\n\n\n\n\nEpoch 229: loss: 0.36281\nSensitivity (poss_acc):0.9305 Specificity (negative_acc):0.6779 accuracy:0.8042\n\n\n\n\n\nEpoch 230: loss: 0.38086\nSensitivity (poss_acc):0.9119 Specificity (negative_acc):0.7000 accuracy:0.8060\n\n\n\n\n\nEpoch 231: loss: 0.37236\nSensitivity (poss_acc):0.9165 Specificity (negative_acc):0.7024 accuracy:0.8095\n\n\n\n\n\nEpoch 232: loss: 0.3733\nSensitivity (poss_acc):0.9305 Specificity (negative_acc):0.6702 accuracy:0.8004\n\n\n\n\n\nEpoch 233: loss: 0.37444\nSensitivity (poss_acc):0.8984 Specificity (negative_acc):0.6952 accuracy:0.7968\n\n\n\n\n\nEpoch 234: loss: 0.35352\nSensitivity (poss_acc):0.9126 Specificity (negative_acc):0.6985 accuracy:0.8056\n\n\n\n\n\nEpoch 235: loss: 0.35052\nSensitivity (poss_acc):0.9115 Specificity (negative_acc):0.7056 accuracy:0.8085\n\n\n\n\n\nEpoch 236: loss: 0.35984\nSensitivity (poss_acc):0.9219 Specificity (negative_acc):0.7035 accuracy:0.8127\n\n\n\n\n\nEpoch 237: loss: 0.39235\nSensitivity (poss_acc):0.9239 Specificity (negative_acc):0.6965 accuracy:0.8102\n\n\n\n\n\nEpoch 238: loss: 0.38771\nSensitivity (poss_acc):0.8825 Specificity (negative_acc):0.7139 accuracy:0.7982\n\n\n\n\n\nEpoch 239: loss: 0.36623\nSensitivity (poss_acc):0.9317 Specificity (negative_acc):0.6673 accuracy:0.7995\n\n\n\n\n\nEpoch 240: loss: 0.35054\nYoudens  index: 0.7685 Sensitivity: 0.8625 Specificity: 0.6838\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 241: loss: 0.34954\nSensitivity (poss_acc):0.8987 Specificity (negative_acc):0.7206 accuracy:0.8096\n\n\n\n\n\nEpoch 242: loss: 0.33929\nSensitivity (poss_acc):0.9120 Specificity (negative_acc):0.7079 accuracy:0.8100\n\n\n\n\n\nEpoch 243: loss: 0.34533\nSensitivity (poss_acc):0.9267 Specificity (negative_acc):0.7034 accuracy:0.8151\n\n\n\n\n\nEpoch 244: loss: 0.41143\nSensitivity (poss_acc):0.8742 Specificity (negative_acc):0.7312 accuracy:0.8027\n\n\n\n\n\nEpoch 245: loss: 0.40834\nSensitivity (poss_acc):0.9291 Specificity (negative_acc):0.6405 accuracy:0.7848\n\n\n\n\n\nEpoch 246: loss: 0.39436\nSensitivity (poss_acc):0.9190 Specificity (negative_acc):0.6853 accuracy:0.8022\n\n\n\n\n\nEpoch 247: loss: 0.3475\nSensitivity (poss_acc):0.9343 Specificity (negative_acc):0.6675 accuracy:0.8009\n\n\n\n\n\nEpoch 248: loss: 0.35281\nSensitivity (poss_acc):0.9211 Specificity (negative_acc):0.6328 accuracy:0.7769\n\n\n\n\n\nEpoch 249: loss: 0.34568\nSensitivity (poss_acc):0.9172 Specificity (negative_acc):0.7051 accuracy:0.8112\n\n\n\n\n\nEpoch 250: loss: 0.33825\nSensitivity (poss_acc):0.9178 Specificity (negative_acc):0.6890 accuracy:0.8034\n\n\n\n\n\nEpoch 251: loss: 0.33479\nSensitivity (poss_acc):0.9357 Specificity (negative_acc):0.6899 accuracy:0.8128\n\n\n\n\n\nEpoch 252: loss: 0.32778\nSensitivity (poss_acc):0.9049 Specificity (negative_acc):0.7105 accuracy:0.8077\n\n\n\n\n\nEpoch 253: loss: 0.32766\nSensitivity (poss_acc):0.9207 Specificity (negative_acc):0.6917 accuracy:0.8062\n\n\n\n\n\nEpoch 254: loss: 0.32788\nSensitivity (poss_acc):0.9353 Specificity (negative_acc):0.6604 accuracy:0.7979\n\n\n\n\n\nEpoch 255: loss: 0.35386\nSensitivity (poss_acc):0.9138 Specificity (negative_acc):0.7067 accuracy:0.8103\n\n\n\n\n\nEpoch 256: loss: 0.33551\nSensitivity (poss_acc):0.9296 Specificity (negative_acc):0.6746 accuracy:0.8021\n\n\n\n\n\nEpoch 257: loss: 0.34903\nSensitivity (poss_acc):0.9326 Specificity (negative_acc):0.6740 accuracy:0.8033\n\n\n\n\n\nEpoch 258: loss: 0.34495\nSensitivity (poss_acc):0.9302 Specificity (negative_acc):0.6925 accuracy:0.8113\n\n\n\n\n\nEpoch 259: loss: 0.33097\nSensitivity (poss_acc):0.9193 Specificity (negative_acc):0.6901 accuracy:0.8047\n\n\n\n\n\nEpoch 260: loss: 0.32369\nYoudens  index: 0.8636 Sensitivity: 0.8352 Specificity: 0.7301\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 261: loss: 0.34254\nSensitivity (poss_acc):0.9362 Specificity (negative_acc):0.6633 accuracy:0.7998\n\n\n\n\n\nEpoch 262: loss: 0.33674\nSensitivity (poss_acc):0.8981 Specificity (negative_acc):0.7273 accuracy:0.8127\n\n\n\n\n\nEpoch 263: loss: 0.38279\nSensitivity (poss_acc):0.5439 Specificity (negative_acc):0.8548 accuracy:0.6994\n\n\n\n\n\nEpoch 264: loss: 0.48767\nSensitivity (poss_acc):0.8254 Specificity (negative_acc):0.7355 accuracy:0.7805\n\n\n\n\n\nEpoch 265: loss: 0.36447\nSensitivity (poss_acc):0.8628 Specificity (negative_acc):0.7420 accuracy:0.8024\n\n\n\n\n\nEpoch 266: loss: 0.34492\nSensitivity (poss_acc):0.9068 Specificity (negative_acc):0.7151 accuracy:0.8109\n\n\n\n\n\nEpoch 267: loss: 0.32435\nSensitivity (poss_acc):0.9105 Specificity (negative_acc):0.7026 accuracy:0.8065\n\n\n\n\n\nEpoch 268: loss: 0.32409\nSensitivity (poss_acc):0.9014 Specificity (negative_acc):0.7120 accuracy:0.8067\n\n\n\n\n\nEpoch 269: loss: 0.32108\nSensitivity (poss_acc):0.9313 Specificity (negative_acc):0.6747 accuracy:0.8030\n\n\n\n\n\nEpoch 270: loss: 0.3237\nSensitivity (poss_acc):0.9210 Specificity (negative_acc):0.7061 accuracy:0.8135\n\n\n\n\n\nEpoch 271: loss: 0.32685\nSensitivity (poss_acc):0.9401 Specificity (negative_acc):0.6747 accuracy:0.8074\n\n\n\n\n\nEpoch 272: loss: 0.32929\nSensitivity (poss_acc):0.9032 Specificity (negative_acc):0.7093 accuracy:0.8062\n\n\n\n\n\nEpoch 273: loss: 0.31754\nSensitivity (poss_acc):0.8953 Specificity (negative_acc):0.7217 accuracy:0.8085\n\n\n\n\n\nEpoch 274: loss: 0.31051\nSensitivity (poss_acc):0.9149 Specificity (negative_acc):0.7113 accuracy:0.8131\n\n\n\n\n\nEpoch 275: loss: 0.30441\nSensitivity (poss_acc):0.8978 Specificity (negative_acc):0.7097 accuracy:0.8038\n\n\n\n\n\nEpoch 276: loss: 0.31611\nSensitivity (poss_acc):0.9033 Specificity (negative_acc):0.7165 accuracy:0.8099\n\n\n\n\n\nEpoch 277: loss: 0.339\nSensitivity (poss_acc):0.9191 Specificity (negative_acc):0.6874 accuracy:0.8032\n\n\n\n\n\nEpoch 278: loss: 0.30854\nSensitivity (poss_acc):0.8892 Specificity (negative_acc):0.7273 accuracy:0.8083\n\n\n\n\n\nEpoch 279: loss: 0.30588\nSensitivity (poss_acc):0.9110 Specificity (negative_acc):0.7136 accuracy:0.8123\n\n\n\n\n\nEpoch 280: loss: 0.3044\nYoudens  index: 0.8684 Sensitivity: 0.8255 Specificity: 0.7423\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 281: loss: 0.31266\nSensitivity (poss_acc):0.9100 Specificity (negative_acc):0.7139 accuracy:0.8119\n\n\n\n\n\nEpoch 282: loss: 0.34434\nSensitivity (poss_acc):0.9148 Specificity (negative_acc):0.6951 accuracy:0.8050\n\n\n\n\n\nEpoch 283: loss: 0.356\nSensitivity (poss_acc):0.9467 Specificity (negative_acc):0.6041 accuracy:0.7754\n\n\n\n\n\nEpoch 284: loss: 0.37104\nSensitivity (poss_acc):0.9132 Specificity (negative_acc):0.7085 accuracy:0.8109\n\n\n\n\n\nEpoch 285: loss: 0.41003\nSensitivity (poss_acc):0.9130 Specificity (negative_acc):0.6852 accuracy:0.7991\n\n\n\n\n\nEpoch 286: loss: 0.31963\nSensitivity (poss_acc):0.9146 Specificity (negative_acc):0.7064 accuracy:0.8105\n\n\n\n\n\nEpoch 287: loss: 0.29864\nSensitivity (poss_acc):0.9220 Specificity (negative_acc):0.6982 accuracy:0.8101\n\n\n\n\n\nEpoch 288: loss: 0.29035\nSensitivity (poss_acc):0.9211 Specificity (negative_acc):0.7120 accuracy:0.8166\n\n\n\n\n\nEpoch 289: loss: 0.28872\nSensitivity (poss_acc):0.9180 Specificity (negative_acc):0.7109 accuracy:0.8144\n\n\n\n\n\nEpoch 290: loss: 0.2885\nSensitivity (poss_acc):0.9079 Specificity (negative_acc):0.7042 accuracy:0.8061\n\n\n\n\n\nEpoch 291: loss: 0.28131\nSensitivity (poss_acc):0.9179 Specificity (negative_acc):0.7221 accuracy:0.8200\nReplacing models: GraphSage_epoch_206.pt  link_predictor_epoch_206.pt\nwith: Best models at GraphSage_epoch_291.pt  link_predictor_epoch_291.pt\nSaving Model in Path GraphSage_epoch_291.pt\nSaving Model in Path link_predictor_epoch_291.pt\n\n\n\n\n\nEpoch 292: loss: 0.28524\nSensitivity (poss_acc):0.9307 Specificity (negative_acc):0.6792 accuracy:0.8050\n\n\n\n\n\nEpoch 293: loss: 0.27918\nSensitivity (poss_acc):0.9019 Specificity (negative_acc):0.7214 accuracy:0.8116\n\n\n\n\n\nEpoch 294: loss: 0.28873\nSensitivity (poss_acc):0.9255 Specificity (negative_acc):0.6810 accuracy:0.8033\n\n\n\n\n\nEpoch 295: loss: 0.29937\nSensitivity (poss_acc):0.9420 Specificity (negative_acc):0.6690 accuracy:0.8055\n\n\n\n\n\nEpoch 296: loss: 0.31016\nSensitivity (poss_acc):0.9117 Specificity (negative_acc):0.6966 accuracy:0.8042\n\n\n\n\n\nEpoch 297: loss: 0.31863\nSensitivity (poss_acc):0.8969 Specificity (negative_acc):0.7367 accuracy:0.8168\n\n\n\n\n\nEpoch 298: loss: 0.30645\nSensitivity (poss_acc):0.9004 Specificity (negative_acc):0.7192 accuracy:0.8098\n\n\n\n\n\nEpoch 299: loss: 0.32054\nSensitivity (poss_acc):0.9291 Specificity (negative_acc):0.6969 accuracy:0.8130\n\n\n\n\n\nEpoch 300: loss: 0.32326\nYoudens  index: 0.8774 Sensitivity: 0.8498 Specificity: 0.737\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 301: loss: 0.29137\nSensitivity (poss_acc):0.9161 Specificity (negative_acc):0.7305 accuracy:0.8233\nReplacing models: GraphSage_epoch_291.pt  link_predictor_epoch_291.pt\nwith: Best models at GraphSage_epoch_301.pt  link_predictor_epoch_301.pt\nSaving Model in Path GraphSage_epoch_301.pt\nSaving Model in Path link_predictor_epoch_301.pt\n\n\n\n\n\nEpoch 302: loss: 0.30295\nSensitivity (poss_acc):0.9140 Specificity (negative_acc):0.7151 accuracy:0.8146\n\n\n\n\n\nEpoch 303: loss: 0.29503\nSensitivity (poss_acc):0.9399 Specificity (negative_acc):0.7023 accuracy:0.8211\n\n\n\n\n\nEpoch 304: loss: 0.27937\nSensitivity (poss_acc):0.9195 Specificity (negative_acc):0.7122 accuracy:0.8159\n\n\n\n\n\nEpoch 305: loss: 0.29081\nSensitivity (poss_acc):0.9257 Specificity (negative_acc):0.6959 accuracy:0.8108\n\n\n\n\n\nEpoch 306: loss: 0.31621\nSensitivity (poss_acc):0.9212 Specificity (negative_acc):0.7136 accuracy:0.8174\n\n\n\n\n\nEpoch 307: loss: 0.27997\nSensitivity (poss_acc):0.9203 Specificity (negative_acc):0.7062 accuracy:0.8133\n\n\n\n\n\nEpoch 308: loss: 0.3185\nSensitivity (poss_acc):0.8559 Specificity (negative_acc):0.7480 accuracy:0.8020\n\n\n\n\n\nEpoch 309: loss: 0.3216\nSensitivity (poss_acc):0.9458 Specificity (negative_acc):0.6806 accuracy:0.8132\n\n\n\n\n\nEpoch 310: loss: 0.32574\nSensitivity (poss_acc):0.9323 Specificity (negative_acc):0.7062 accuracy:0.8193\n\n\n\n\n\nEpoch 311: loss: 0.2875\nSensitivity (poss_acc):0.9044 Specificity (negative_acc):0.7480 accuracy:0.8262\nReplacing models: GraphSage_epoch_301.pt  link_predictor_epoch_301.pt\nwith: Best models at GraphSage_epoch_311.pt  link_predictor_epoch_311.pt\nSaving Model in Path GraphSage_epoch_311.pt\nSaving Model in Path link_predictor_epoch_311.pt\n\n\n\n\n\nEpoch 312: loss: 0.26868\nSensitivity (poss_acc):0.9264 Specificity (negative_acc):0.7044 accuracy:0.8154\n\n\n\n\n\nEpoch 313: loss: 0.26539\nSensitivity (poss_acc):0.9263 Specificity (negative_acc):0.7039 accuracy:0.8151\n\n\n\n\n\nEpoch 314: loss: 0.27278\nSensitivity (poss_acc):0.9304 Specificity (negative_acc):0.7035 accuracy:0.8170\n\n\n\n\n\nEpoch 315: loss: 0.27866\nSensitivity (poss_acc):0.9092 Specificity (negative_acc):0.7336 accuracy:0.8214\n\n\n\n\n\nEpoch 316: loss: 0.27996\nSensitivity (poss_acc):0.9247 Specificity (negative_acc):0.7157 accuracy:0.8202\n\n\n\n\n\nEpoch 317: loss: 0.2774\nSensitivity (poss_acc):0.9422 Specificity (negative_acc):0.6833 accuracy:0.8127\n\n\n\n\n\nEpoch 318: loss: 0.29832\nSensitivity (poss_acc):0.9286 Specificity (negative_acc):0.6972 accuracy:0.8129\n\n\n\n\n\nEpoch 319: loss: 0.31629\nSensitivity (poss_acc):0.9385 Specificity (negative_acc):0.6817 accuracy:0.8101\n\n\n\n\n\nEpoch 320: loss: 0.29874\nYoudens  index: 0.6011 Sensitivity: 0.8919 Specificity: 0.6917\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 321: loss: 0.27478\nSensitivity (poss_acc):0.9296 Specificity (negative_acc):0.7037 accuracy:0.8166\n\n\n\n\n\nEpoch 322: loss: 0.26487\nSensitivity (poss_acc):0.9121 Specificity (negative_acc):0.7153 accuracy:0.8137\n\n\n\n\n\nEpoch 323: loss: 0.2636\nSensitivity (poss_acc):0.9221 Specificity (negative_acc):0.7217 accuracy:0.8219\n\n\n\n\n\nEpoch 324: loss: 0.26743\nSensitivity (poss_acc):0.9144 Specificity (negative_acc):0.7314 accuracy:0.8229\n\n\n\n\n\nEpoch 325: loss: 0.26381\nSensitivity (poss_acc):0.9418 Specificity (negative_acc):0.6830 accuracy:0.8124\n\n\n\n\n\nEpoch 326: loss: 0.26971\nSensitivity (poss_acc):0.9278 Specificity (negative_acc):0.7047 accuracy:0.8162\n\n\n\n\n\nEpoch 327: loss: 0.29703\nSensitivity (poss_acc):0.8546 Specificity (negative_acc):0.7918 accuracy:0.8232\n\n\n\n\n\nEpoch 328: loss: 0.31146\nSensitivity (poss_acc):0.8838 Specificity (negative_acc):0.7442 accuracy:0.8140\n\n\n\n\n\nEpoch 329: loss: 0.27847\nSensitivity (poss_acc):0.9403 Specificity (negative_acc):0.6829 accuracy:0.8116\n\n\n\n\n\nEpoch 330: loss: 0.26299\nSensitivity (poss_acc):0.9354 Specificity (negative_acc):0.7072 accuracy:0.8213\n\n\n\n\n\nEpoch 331: loss: 0.26303\nSensitivity (poss_acc):0.9154 Specificity (negative_acc):0.7331 accuracy:0.8243\n\n\n\n\n\nEpoch 332: loss: 0.25426\nSensitivity (poss_acc):0.9239 Specificity (negative_acc):0.7059 accuracy:0.8149\n\n\n\n\n\nEpoch 333: loss: 0.25015\nSensitivity (poss_acc):0.9082 Specificity (negative_acc):0.7338 accuracy:0.8210\n\n\n\n\n\nEpoch 334: loss: 0.26118\nSensitivity (poss_acc):0.9227 Specificity (negative_acc):0.7164 accuracy:0.8196\n\n\n\n\n\nEpoch 335: loss: 0.25302\nSensitivity (poss_acc):0.9286 Specificity (negative_acc):0.7148 accuracy:0.8217\n\n\n\n\n\nEpoch 336: loss: 0.25933\nSensitivity (poss_acc):0.9413 Specificity (negative_acc):0.6888 accuracy:0.8150\n\n\n\n\n\nEpoch 337: loss: 0.28035\nSensitivity (poss_acc):0.9063 Specificity (negative_acc):0.7286 accuracy:0.8174\n\n\n\n\n\nEpoch 338: loss: 0.25494\nSensitivity (poss_acc):0.9229 Specificity (negative_acc):0.7104 accuracy:0.8167\n\n\n\n\n\nEpoch 339: loss: 0.24699\nSensitivity (poss_acc):0.9201 Specificity (negative_acc):0.7101 accuracy:0.8151\n\n\n\n\n\nEpoch 340: loss: 0.24394\nYoudens  index: 0.8950 Sensitivity: 0.8676 Specificity: 0.7121\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 341: loss: 0.24413\nSensitivity (poss_acc):0.8992 Specificity (negative_acc):0.7515 accuracy:0.8254\n\n\n\n\n\nEpoch 342: loss: 0.24053\nSensitivity (poss_acc):0.9398 Specificity (negative_acc):0.6915 accuracy:0.8157\n\n\n\n\n\nEpoch 343: loss: 0.29209\nSensitivity (poss_acc):0.9573 Specificity (negative_acc):0.6284 accuracy:0.7929\n\n\n\n\n\nEpoch 344: loss: 0.48287\nSensitivity (poss_acc):0.8723 Specificity (negative_acc):0.7623 accuracy:0.8173\n\n\n\n\n\nEpoch 345: loss: 0.35241\nSensitivity (poss_acc):0.9142 Specificity (negative_acc):0.7485 accuracy:0.8313\nReplacing models: GraphSage_epoch_311.pt  link_predictor_epoch_311.pt\nwith: Best models at GraphSage_epoch_345.pt  link_predictor_epoch_345.pt\nSaving Model in Path GraphSage_epoch_345.pt\nSaving Model in Path link_predictor_epoch_345.pt\n\n\n\n\n\nEpoch 346: loss: 0.27701\nSensitivity (poss_acc):0.9462 Specificity (negative_acc):0.6819 accuracy:0.8140\n\n\n\n\n\nEpoch 347: loss: 0.25205\nSensitivity (poss_acc):0.9063 Specificity (negative_acc):0.7409 accuracy:0.8236\n\n\n\n\n\nEpoch 348: loss: 0.24887\nSensitivity (poss_acc):0.9463 Specificity (negative_acc):0.6827 accuracy:0.8145\n\n\n\n\n\nEpoch 349: loss: 0.24235\nSensitivity (poss_acc):0.9327 Specificity (negative_acc):0.7253 accuracy:0.8290\n\n\n\n\n\nEpoch 350: loss: 0.24123\nSensitivity (poss_acc):0.9439 Specificity (negative_acc):0.6913 accuracy:0.8176\n\n\n\n\n\nEpoch 351: loss: 0.24302\nSensitivity (poss_acc):0.9240 Specificity (negative_acc):0.6951 accuracy:0.8095\n\n\n\n\n\nEpoch 352: loss: 0.24553\nSensitivity (poss_acc):0.9193 Specificity (negative_acc):0.7285 accuracy:0.8239\n\n\n\n\n\nEpoch 353: loss: 0.23427\nSensitivity (poss_acc):0.9197 Specificity (negative_acc):0.7387 accuracy:0.8292\n\n\n\n\n\nEpoch 354: loss: 0.2294\nSensitivity (poss_acc):0.9341 Specificity (negative_acc):0.6866 accuracy:0.8104\n\n\n\n\n\nEpoch 355: loss: 0.23221\nSensitivity (poss_acc):0.9356 Specificity (negative_acc):0.7092 accuracy:0.8224\n\n\n\n\n\nEpoch 356: loss: 0.22796\nSensitivity (poss_acc):0.9188 Specificity (negative_acc):0.7202 accuracy:0.8195\n\n\n\n\n\nEpoch 357: loss: 0.23815\nSensitivity (poss_acc):0.9420 Specificity (negative_acc):0.6986 accuracy:0.8203\n\n\n\n\n\nEpoch 358: loss: 0.24684\nSensitivity (poss_acc):0.9355 Specificity (negative_acc):0.6995 accuracy:0.8175\n\n\n\n\n\nEpoch 359: loss: 0.25699\nSensitivity (poss_acc):0.9266 Specificity (negative_acc):0.7014 accuracy:0.8140\n\n\n\n\n\nEpoch 360: loss: 0.26083\nYoudens  index: 0.9143 Sensitivity: 0.8573 Specificity: 0.7576\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 361: loss: 0.25936\nSensitivity (poss_acc):0.9076 Specificity (negative_acc):0.7554 accuracy:0.8315\nReplacing models: GraphSage_epoch_345.pt  link_predictor_epoch_345.pt\nwith: Best models at GraphSage_epoch_361.pt  link_predictor_epoch_361.pt\nSaving Model in Path GraphSage_epoch_361.pt\nSaving Model in Path link_predictor_epoch_361.pt\n\n\n\n\n\nEpoch 362: loss: 0.24979\nSensitivity (poss_acc):0.9259 Specificity (negative_acc):0.7303 accuracy:0.8281\n\n\n\n\n\nEpoch 363: loss: 0.23555\nSensitivity (poss_acc):0.9424 Specificity (negative_acc):0.6934 accuracy:0.8179\n\n\n\n\n\nEpoch 364: loss: 0.24072\nSensitivity (poss_acc):0.9233 Specificity (negative_acc):0.7338 accuracy:0.8285\n\n\n\n\n\nEpoch 365: loss: 0.24204\nSensitivity (poss_acc):0.9306 Specificity (negative_acc):0.7124 accuracy:0.8215\n\n\n\n\n\nEpoch 366: loss: 0.23186\nSensitivity (poss_acc):0.9369 Specificity (negative_acc):0.6904 accuracy:0.8136\n\n\n\n\n\nEpoch 367: loss: 0.22834\nSensitivity (poss_acc):0.9331 Specificity (negative_acc):0.6955 accuracy:0.8143\n\n\n\n\n\nEpoch 368: loss: 0.22755\nSensitivity (poss_acc):0.9359 Specificity (negative_acc):0.6992 accuracy:0.8175\n\n\n\n\n\nEpoch 369: loss: 0.22694\nSensitivity (poss_acc):0.9377 Specificity (negative_acc):0.6754 accuracy:0.8066\n\n\n\n\n\nEpoch 370: loss: 0.26628\nSensitivity (poss_acc):0.9138 Specificity (negative_acc):0.7267 accuracy:0.8202\n\n\n\n\n\nEpoch 371: loss: 0.23757\nSensitivity (poss_acc):0.9161 Specificity (negative_acc):0.7257 accuracy:0.8209\n\n\n\n\n\nEpoch 372: loss: 0.23516\nSensitivity (poss_acc):0.9381 Specificity (negative_acc):0.7021 accuracy:0.8201\n\n\n\n\n\nEpoch 373: loss: 0.23502\nSensitivity (poss_acc):0.9255 Specificity (negative_acc):0.7370 accuracy:0.8312\n\n\n\n\n\nEpoch 374: loss: 0.23408\nSensitivity (poss_acc):0.9201 Specificity (negative_acc):0.7220 accuracy:0.8210\n\n\n\n\n\nEpoch 375: loss: 0.24173\nSensitivity (poss_acc):0.9111 Specificity (negative_acc):0.7324 accuracy:0.8218\n\n\n\n\n\nEpoch 376: loss: 0.24685\nSensitivity (poss_acc):0.9111 Specificity (negative_acc):0.7398 accuracy:0.8254\n\n\n\n\n\nEpoch 377: loss: 0.24181\nSensitivity (poss_acc):0.9347 Specificity (negative_acc):0.7024 accuracy:0.8186\n\n\n\n\n\nEpoch 378: loss: 0.25231\nSensitivity (poss_acc):0.9276 Specificity (negative_acc):0.6988 accuracy:0.8132\n\n\n\n\n\nEpoch 379: loss: 0.24032\nSensitivity (poss_acc):0.9296 Specificity (negative_acc):0.6854 accuracy:0.8075\n\n\n\n\n\nEpoch 380: loss: 0.2515\nYoudens  index: 0.9390 Sensitivity: 0.8487 Specificity: 0.7432\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 381: loss: 0.27215\nSensitivity (poss_acc):0.9264 Specificity (negative_acc):0.7043 accuracy:0.8154\n\n\n\n\n\nEpoch 382: loss: 0.27327\nSensitivity (poss_acc):0.8217 Specificity (negative_acc):0.8156 accuracy:0.8186\n\n\n\n\n\nEpoch 383: loss: 0.24583\nSensitivity (poss_acc):0.9425 Specificity (negative_acc):0.6963 accuracy:0.8194\n\n\n\n\n\nEpoch 384: loss: 0.22456\nSensitivity (poss_acc):0.9361 Specificity (negative_acc):0.7006 accuracy:0.8183\n\n\n\n\n\nEpoch 385: loss: 0.22032\nSensitivity (poss_acc):0.9157 Specificity (negative_acc):0.7279 accuracy:0.8218\n\n\n\n\n\nEpoch 386: loss: 0.2244\nSensitivity (poss_acc):0.9160 Specificity (negative_acc):0.7137 accuracy:0.8148\n\n\n\n\n\nEpoch 387: loss: 0.21072\nSensitivity (poss_acc):0.9096 Specificity (negative_acc):0.7449 accuracy:0.8273\n\n\n\n\n\nEpoch 388: loss: 0.2204\nSensitivity (poss_acc):0.9345 Specificity (negative_acc):0.7072 accuracy:0.8208\n\n\n\n\n\nEpoch 389: loss: 0.21742\nSensitivity (poss_acc):0.9376 Specificity (negative_acc):0.7054 accuracy:0.8215\n\n\n\n\n\nEpoch 390: loss: 0.2208\nSensitivity (poss_acc):0.9231 Specificity (negative_acc):0.7287 accuracy:0.8259\n\n\n\n\n\nEpoch 391: loss: 0.21633\nSensitivity (poss_acc):0.9181 Specificity (negative_acc):0.7176 accuracy:0.8179\n\n\n\n\n\nEpoch 392: loss: 0.2131\nSensitivity (poss_acc):0.9095 Specificity (negative_acc):0.7374 accuracy:0.8234\n\n\n\n\n\nEpoch 393: loss: 0.20912\nSensitivity (poss_acc):0.9370 Specificity (negative_acc):0.7129 accuracy:0.8249\n\n\n\n\n\nEpoch 394: loss: 0.20719\nSensitivity (poss_acc):0.9170 Specificity (negative_acc):0.7373 accuracy:0.8271\n\n\n\n\n\nEpoch 395: loss: 0.22036\nSensitivity (poss_acc):0.9067 Specificity (negative_acc):0.7465 accuracy:0.8266\n\n\n\n\n\nEpoch 396: loss: 0.24959\nSensitivity (poss_acc):0.9254 Specificity (negative_acc):0.7150 accuracy:0.8202\n\n\n\n\n\nEpoch 397: loss: 0.23008\nSensitivity (poss_acc):0.9188 Specificity (negative_acc):0.7329 accuracy:0.8259\n\n\n\n\n\nEpoch 398: loss: 0.21689\nSensitivity (poss_acc):0.9142 Specificity (negative_acc):0.7152 accuracy:0.8147\n\n\n\n\n\nEpoch 399: loss: 0.22647\nSensitivity (poss_acc):0.9370 Specificity (negative_acc):0.7086 accuracy:0.8228\n\n\n\n\n\nEpoch 400: loss: 0.22033\nYoudens  index: 0.8356 Sensitivity: 0.8722 Specificity: 0.738\n\n\n\n\n\n\n\n\n\nReplacing models: GraphSage_epoch_361.pt  link_predictor_epoch_361.pt\nwith: Best models at GraphSage_epoch_400.pt  link_predictor_epoch_400.pt\nSaving Model in Path GraphSage_epoch_400.pt\nSaving Model in Path link_predictor_epoch_400.pt\n\n\n\n\n\nEpoch 401: loss: 0.22417\nSensitivity (poss_acc):0.9385 Specificity (negative_acc):0.6754 accuracy:0.8070\n\n\n\n\n\nEpoch 402: loss: 0.22036\nSensitivity (poss_acc):0.9273 Specificity (negative_acc):0.7116 accuracy:0.8195\n\n\n\n\n\nEpoch 403: loss: 0.22335\nSensitivity (poss_acc):0.9309 Specificity (negative_acc):0.7180 accuracy:0.8244\n\n\n\n\n\nEpoch 404: loss: 0.21484\nSensitivity (poss_acc):0.8955 Specificity (negative_acc):0.7831 accuracy:0.8393\nReplacing models: GraphSage_epoch_400.pt  link_predictor_epoch_400.pt\nwith: Best models at GraphSage_epoch_404.pt  link_predictor_epoch_404.pt\nSaving Model in Path GraphSage_epoch_404.pt\nSaving Model in Path link_predictor_epoch_404.pt\n\n\n\n\n\nEpoch 405: loss: 0.22207\nSensitivity (poss_acc):0.9363 Specificity (negative_acc):0.6996 accuracy:0.8179\n\n\n\n\n\nEpoch 406: loss: 0.24823\nSensitivity (poss_acc):0.9283 Specificity (negative_acc):0.7215 accuracy:0.8249\n\n\n\n\n\nEpoch 407: loss: 0.22388\nSensitivity (poss_acc):0.9247 Specificity (negative_acc):0.7464 accuracy:0.8355\n\n\n\n\n\nEpoch 408: loss: 0.21491\nSensitivity (poss_acc):0.9214 Specificity (negative_acc):0.7454 accuracy:0.8334\n\n\n\n\n\nEpoch 409: loss: 0.20652\nSensitivity (poss_acc):0.9119 Specificity (negative_acc):0.7507 accuracy:0.8313\n\n\n\n\n\nEpoch 410: loss: 0.20941\nSensitivity (poss_acc):0.8952 Specificity (negative_acc):0.7374 accuracy:0.8163\n\n\n\n\n\nEpoch 411: loss: 0.22706\nSensitivity (poss_acc):0.9301 Specificity (negative_acc):0.7208 accuracy:0.8255\n\n\n\n\n\nEpoch 412: loss: 0.21377\nSensitivity (poss_acc):0.9152 Specificity (negative_acc):0.7346 accuracy:0.8249\n\n\n\n\n\nEpoch 413: loss: 0.23774\nSensitivity (poss_acc):0.8829 Specificity (negative_acc):0.7607 accuracy:0.8218\n\n\n\n\n\nEpoch 414: loss: 0.21501\nSensitivity (poss_acc):0.9251 Specificity (negative_acc):0.7199 accuracy:0.8225\n\n\n\n\n\nEpoch 415: loss: 0.21192\nSensitivity (poss_acc):0.9258 Specificity (negative_acc):0.7120 accuracy:0.8189\n\n\n\n\n\nEpoch 416: loss: 0.2122\nSensitivity (poss_acc):0.9350 Specificity (negative_acc):0.7126 accuracy:0.8238\n\n\n\n\n\nEpoch 417: loss: 0.20387\nSensitivity (poss_acc):0.9221 Specificity (negative_acc):0.7249 accuracy:0.8235\n\n\n\n\n\nEpoch 418: loss: 0.19571\nSensitivity (poss_acc):0.9287 Specificity (negative_acc):0.7219 accuracy:0.8253\n\n\n\n\n\nEpoch 419: loss: 0.19462\nSensitivity (poss_acc):0.9441 Specificity (negative_acc):0.6975 accuracy:0.8208\n\n\n\n\n\nEpoch 420: loss: 0.1974\nYoudens  index: 0.9035 Sensitivity: 0.8457 Specificity: 0.7657\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 421: loss: 0.24172\nSensitivity (poss_acc):0.9244 Specificity (negative_acc):0.7144 accuracy:0.8194\n\n\n\n\n\nEpoch 422: loss: 0.20444\nSensitivity (poss_acc):0.9205 Specificity (negative_acc):0.7327 accuracy:0.8266\n\n\n\n\n\nEpoch 423: loss: 0.20627\nSensitivity (poss_acc):0.9069 Specificity (negative_acc):0.7523 accuracy:0.8296\n\n\n\n\n\nEpoch 424: loss: 0.21716\nSensitivity (poss_acc):0.9253 Specificity (negative_acc):0.7196 accuracy:0.8224\n\n\n\n\n\nEpoch 425: loss: 0.28508\nSensitivity (poss_acc):0.8785 Specificity (negative_acc):0.7684 accuracy:0.8234\n\n\n\n\n\nEpoch 426: loss: 0.39432\nSensitivity (poss_acc):0.9058 Specificity (negative_acc):0.7272 accuracy:0.8165\n\n\n\n\n\nEpoch 427: loss: 0.29863\nSensitivity (poss_acc):0.9264 Specificity (negative_acc):0.7209 accuracy:0.8237\n\n\n\n\n\nEpoch 428: loss: 0.23338\nSensitivity (poss_acc):0.9358 Specificity (negative_acc):0.6780 accuracy:0.8069\n\n\n\n\n\nEpoch 429: loss: 0.21444\nSensitivity (poss_acc):0.9156 Specificity (negative_acc):0.7380 accuracy:0.8268\n\n\n\n\n\nEpoch 430: loss: 0.19334\nSensitivity (poss_acc):0.9283 Specificity (negative_acc):0.7225 accuracy:0.8254\n\n\n\n\n\nEpoch 431: loss: 0.19064\nSensitivity (poss_acc):0.9279 Specificity (negative_acc):0.7242 accuracy:0.8261\n\n\n\n\n\nEpoch 432: loss: 0.19181\nSensitivity (poss_acc):0.9396 Specificity (negative_acc):0.7197 accuracy:0.8297\n\n\n\n\n\nEpoch 433: loss: 0.18775\nSensitivity (poss_acc):0.9438 Specificity (negative_acc):0.6887 accuracy:0.8163\n\n\n\n\n\nEpoch 434: loss: 0.18864\nSensitivity (poss_acc):0.9294 Specificity (negative_acc):0.7217 accuracy:0.8256\n\n\n\n\n\nEpoch 435: loss: 0.19959\nSensitivity (poss_acc):0.9110 Specificity (negative_acc):0.7340 accuracy:0.8225\n\n\n\n\n\nEpoch 436: loss: 0.20152\nSensitivity (poss_acc):0.9224 Specificity (negative_acc):0.7323 accuracy:0.8274\n\n\n\n\n\nEpoch 437: loss: 0.19882\nSensitivity (poss_acc):0.9302 Specificity (negative_acc):0.7252 accuracy:0.8277\n\n\n\n\n\nEpoch 438: loss: 0.20474\nSensitivity (poss_acc):0.9112 Specificity (negative_acc):0.7511 accuracy:0.8312\n\n\n\n\n\nEpoch 439: loss: 0.19753\nSensitivity (poss_acc):0.9229 Specificity (negative_acc):0.7317 accuracy:0.8273\n\n\n\n\n\nEpoch 440: loss: 0.18248\nYoudens  index: 0.9178 Sensitivity: 0.8538 Specificity: 0.749\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 441: loss: 0.18211\nSensitivity (poss_acc):0.9333 Specificity (negative_acc):0.7213 accuracy:0.8273\n\n\n\n\n\nEpoch 442: loss: 0.17687\nSensitivity (poss_acc):0.9340 Specificity (negative_acc):0.7109 accuracy:0.8225\n\n\n\n\n\nEpoch 443: loss: 0.17796\nSensitivity (poss_acc):0.9253 Specificity (negative_acc):0.7260 accuracy:0.8256\n\n\n\n\n\nEpoch 444: loss: 0.19276\nSensitivity (poss_acc):0.9328 Specificity (negative_acc):0.7184 accuracy:0.8256\n\n\n\n\n\nEpoch 445: loss: 0.20067\nSensitivity (poss_acc):0.9249 Specificity (negative_acc):0.7290 accuracy:0.8269\n\n\n\n\n\nEpoch 446: loss: 0.20874\nSensitivity (poss_acc):0.9373 Specificity (negative_acc):0.6993 accuracy:0.8183\n\n\n\n\n\nEpoch 447: loss: 0.1938\nSensitivity (poss_acc):0.9313 Specificity (negative_acc):0.7128 accuracy:0.8221\n\n\n\n\n\nEpoch 448: loss: 0.18856\nSensitivity (poss_acc):0.9137 Specificity (negative_acc):0.7146 accuracy:0.8142\n\n\n\n\n\nEpoch 449: loss: 0.22809\nSensitivity (poss_acc):0.9370 Specificity (negative_acc):0.6977 accuracy:0.8173\n\n\n\n\n\nEpoch 450: loss: 0.19334\nSensitivity (poss_acc):0.9231 Specificity (negative_acc):0.7362 accuracy:0.8297\n\n\n\n\n\nEpoch 451: loss: 0.19978\nSensitivity (poss_acc):0.9325 Specificity (negative_acc):0.7207 accuracy:0.8266\n\n\n\n\n\nEpoch 452: loss: 0.20199\nSensitivity (poss_acc):0.9299 Specificity (negative_acc):0.7205 accuracy:0.8252\n\n\n\n\n\nEpoch 453: loss: 0.1864\nSensitivity (poss_acc):0.9242 Specificity (negative_acc):0.7348 accuracy:0.8295\n\n\n\n\n\nEpoch 454: loss: 0.19218\nSensitivity (poss_acc):0.9217 Specificity (negative_acc):0.7288 accuracy:0.8253\n\n\n\n\n\nEpoch 455: loss: 0.18319\nSensitivity (poss_acc):0.9125 Specificity (negative_acc):0.7487 accuracy:0.8306\n\n\n\n\n\nEpoch 456: loss: 0.19585\nSensitivity (poss_acc):0.9286 Specificity (negative_acc):0.7104 accuracy:0.8195\n\n\n\n\n\nEpoch 457: loss: 0.18792\nSensitivity (poss_acc):0.9224 Specificity (negative_acc):0.7201 accuracy:0.8213\n\n\n\n\n\nEpoch 458: loss: 0.18575\nSensitivity (poss_acc):0.9269 Specificity (negative_acc):0.7318 accuracy:0.8293\n\n\n\n\n\nEpoch 459: loss: 0.17877\nSensitivity (poss_acc):0.9342 Specificity (negative_acc):0.7272 accuracy:0.8307\n\n\n\n\n\nEpoch 460: loss: 0.19606\nYoudens  index: 0.7920 Sensitivity: 0.8774 Specificity: 0.7214\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 461: loss: 0.23033\nSensitivity (poss_acc):0.9176 Specificity (negative_acc):0.7411 accuracy:0.8293\n\n\n\n\n\nEpoch 462: loss: 0.25767\nSensitivity (poss_acc):0.8857 Specificity (negative_acc):0.7621 accuracy:0.8239\n\n\n\n\n\nEpoch 463: loss: 0.2143\nSensitivity (poss_acc):0.9285 Specificity (negative_acc):0.7370 accuracy:0.8328\n\n\n\n\n\nEpoch 464: loss: 0.23429\nSensitivity (poss_acc):0.9166 Specificity (negative_acc):0.7064 accuracy:0.8115\n\n\n\n\n\nEpoch 465: loss: 0.21986\nSensitivity (poss_acc):0.9254 Specificity (negative_acc):0.7141 accuracy:0.8197\n\n\n\n\n\nEpoch 466: loss: 0.19238\nSensitivity (poss_acc):0.9403 Specificity (negative_acc):0.7151 accuracy:0.8277\n\n\n\n\n\nEpoch 467: loss: 0.17515\nSensitivity (poss_acc):0.9365 Specificity (negative_acc):0.7148 accuracy:0.8257\n\n\n\n\n\nEpoch 468: loss: 0.17223\nSensitivity (poss_acc):0.9265 Specificity (negative_acc):0.7199 accuracy:0.8232\n\n\n\n\n\nEpoch 469: loss: 0.16581\nSensitivity (poss_acc):0.9277 Specificity (negative_acc):0.7230 accuracy:0.8254\n\n\n\n\n\nEpoch 470: loss: 0.16664\nSensitivity (poss_acc):0.9215 Specificity (negative_acc):0.7201 accuracy:0.8208\n\n\n\n\n\nEpoch 471: loss: 0.16958\nSensitivity (poss_acc):0.9336 Specificity (negative_acc):0.7371 accuracy:0.8354\n\n\n\n\n\nEpoch 472: loss: 0.17501\nSensitivity (poss_acc):0.9039 Specificity (negative_acc):0.7741 accuracy:0.8390\n\n\n\n\n\nEpoch 473: loss: 0.17548\nSensitivity (poss_acc):0.9379 Specificity (negative_acc):0.7026 accuracy:0.8203\n\n\n\n\n\nEpoch 474: loss: 0.17472\nSensitivity (poss_acc):0.9275 Specificity (negative_acc):0.7344 accuracy:0.8310\n\n\n\n\n\nEpoch 475: loss: 0.17299\nSensitivity (poss_acc):0.9281 Specificity (negative_acc):0.7269 accuracy:0.8275\n\n\n\n\n\nEpoch 476: loss: 0.17259\nSensitivity (poss_acc):0.9233 Specificity (negative_acc):0.7368 accuracy:0.8300\n\n\n\n\n\nEpoch 477: loss: 0.19387\nSensitivity (poss_acc):0.9349 Specificity (negative_acc):0.7090 accuracy:0.8219\n\n\n\n\n\nEpoch 478: loss: 0.23573\nSensitivity (poss_acc):0.9442 Specificity (negative_acc):0.6996 accuracy:0.8219\n\n\n\n\n\nEpoch 479: loss: 0.20471\nSensitivity (poss_acc):0.9392 Specificity (negative_acc):0.7077 accuracy:0.8235\n\n\n\n\n\nEpoch 480: loss: 0.18789\nYoudens  index: 0.9204 Sensitivity: 0.8476 Specificity: 0.7796\n\n\n\n\n\n\n\n\n\n\n\n\nEpoch 481: loss: 0.174\nSensitivity (poss_acc):0.9332 Specificity (negative_acc):0.7282 accuracy:0.8307\n\n\n\n\n\nEpoch 482: loss: 0.17244\nSensitivity (poss_acc):0.9079 Specificity (negative_acc):0.7520 accuracy:0.8299\n\n\n\n\n\nEpoch 483: loss: 0.17065\nSensitivity (poss_acc):0.9281 Specificity (negative_acc):0.7082 accuracy:0.8181\n\n\n\n\n\nEpoch 484: loss: 0.17275\nSensitivity (poss_acc):0.9237 Specificity (negative_acc):0.7147 accuracy:0.8192\n\n\n\n\n\nEpoch 485: loss: 0.1662\nSensitivity (poss_acc):0.9365 Specificity (negative_acc):0.7102 accuracy:0.8233\n\n\n\n\n\nEpoch 486: loss: 0.17545\nSensitivity (poss_acc):0.9126 Specificity (negative_acc):0.7429 accuracy:0.8277\n\n\n\n\n\nEpoch 487: loss: 0.16983\nSensitivity (poss_acc):0.9176 Specificity (negative_acc):0.7375 accuracy:0.8275\n\n\n\n\n\nEpoch 488: loss: 0.16665\nSensitivity (poss_acc):0.9228 Specificity (negative_acc):0.7365 accuracy:0.8297\n\n\n\n\n\nEpoch 489: loss: 0.18032\nSensitivity (poss_acc):0.9280 Specificity (negative_acc):0.7288 accuracy:0.8284\n\n\n\n\n\nEpoch 490: loss: 0.20371\nSensitivity (poss_acc):0.9155 Specificity (negative_acc):0.7284 accuracy:0.8220\n\n\n\n\n\nEpoch 491: loss: 0.20601\nSensitivity (poss_acc):0.9107 Specificity (negative_acc):0.7437 accuracy:0.8272\n\n\n\n\n\nEpoch 492: loss: 0.21267\nSensitivity (poss_acc):0.9346 Specificity (negative_acc):0.7217 accuracy:0.8282\n\n\n\n\n\nEpoch 493: loss: 0.19111\nSensitivity (poss_acc):0.9382 Specificity (negative_acc):0.7030 accuracy:0.8206\n\n\n\n\n\nEpoch 494: loss: 0.1703\nSensitivity (poss_acc):0.9303 Specificity (negative_acc):0.7277 accuracy:0.8290\n\n\n\n\n\nEpoch 495: loss: 0.16025\nSensitivity (poss_acc):0.9240 Specificity (negative_acc):0.7226 accuracy:0.8233\n\n\n\n\n\nEpoch 496: loss: 0.18236\nSensitivity (poss_acc):0.9057 Specificity (negative_acc):0.7365 accuracy:0.8211\n\n\n\n\n\nEpoch 497: loss: 0.18573\nSensitivity (poss_acc):0.9415 Specificity (negative_acc):0.7061 accuracy:0.8238\n\n\n\n\n\nEpoch 498: loss: 0.17085\nSensitivity (poss_acc):0.9250 Specificity (negative_acc):0.7054 accuracy:0.8152\n\n\n\n\n\nEpoch 499: loss: 0.17554\nSensitivity (poss_acc):0.9321 Specificity (negative_acc):0.7151 accuracy:0.8236\nLoading best models:  GraphSage_epoch_404.pt  link_predictor_epoch_404.pt\n\n\n\n\nCode\ntorch.cuda.empty_cache()\n\n\nOnce the training is complete, we can load our best model and use it to see the AUC/ROC and Confussion matrix plot. Also, we can use it with validation data (comming!) to see how well this is performing.\n\n\nCode\nmodel = GNNStack(input_dim, hidden_dim, hidden_dim, dropout,num_layers, emb=True).to(device)\n\nbest_graphsage_model_path      = f\"GraphSage_epoch_{404}.pt\"\nbest_link_predictor_model_path =  f\"link_predictor_epoch_{404}.pt\"\n\nprint(f\"Loading best models:  {best_graphsage_model_path }  {best_link_predictor_model_path}\")\ncheckpoint = torch.load(best_graphsage_model_path)\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.eval()\n\ncheckpoint = torch.load(best_link_predictor_model_path)\nlink_predictor.load_state_dict(checkpoint['model_state_dict'])\n\ndel checkpoint\n\n\nLoading best models:  GraphSage_epoch_404.pt  link_predictor_epoch_404.pt\n\n\nRun this part, to see the loss and accuracy acroos the epochs:\n\n\nCode\nfig, ax = plt.subplots(1, 2,figsize=(10,4))\n\nax[0].set_title(\"Train Loss\")\nax[0].plot(train_loss)\nax[0].set_ylabel(\"Loss\")\nax[0].set_xlabel(\"Epochs\")\n\nax[1].set_title(\"Accuracy\")\nax[1].plot(train_accuracy)\nax[1].set_ylabel(\"accuracy\")\nax[1].set_xlabel(\"Epochs\")\nfig.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/proteinbert_graphsage/BERT2Graphsage.html#evaluate-diferent-ppi-percentages",
    "href": "posts/proteinbert_graphsage/BERT2Graphsage.html#evaluate-diferent-ppi-percentages",
    "title": "Predict Protein-Protein Interactions with GraphSAGE",
    "section": "Evaluate Diferent PPI Percentages",
    "text": "Evaluate Diferent PPI Percentages\nIs important to see how the model behaves with different percentages of protein-protein interactions:\n\n\nCode\nfor i in [0.01, 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n    print(f\"Evaluating Model with {i*100}% of PPI's\")\n    evaluate(model, link_predictor ,test_loader,device=device,ppi_=i,verbose=True,show_extra_metrics=True)\n    print()\n\n\nEvaluating Model with 1.0% of PPI's\n 371 Positive Protein Interactions were used to Embed a graph with 37140 ppi's\n 149 Positive Protein Interactions were used to Embed a graph with 14908 ppi's\n 284 Positive Protein Interactions were used to Embed a graph with 28466 ppi's\n 150 Positive Protein Interactions were used to Embed a graph with 15022 ppi's\n 172 Positive Protein Interactions were used to Embed a graph with 17228 ppi's\n 261 Positive Protein Interactions were used to Embed a graph with 26124 ppi's\n 52 Positive Protein Interactions were used to Embed a graph with 5284 ppi's\n 63 Positive Protein Interactions were used to Embed a graph with 6366 ppi's\n 148 Positive Protein Interactions were used to Embed a graph with 14870 ppi's\n 79 Positive Protein Interactions were used to Embed a graph with 7918 ppi's\nYoudens  index: 0.7248 Sensitivity: 0.035 Specificity: 0.9659\n\n\n\n\n\n\n\n\n\n\nEvaluating Model with 10.0% of PPI's\n 3714 Positive Protein Interactions were used to Embed a graph with 37140 ppi's\n 1490 Positive Protein Interactions were used to Embed a graph with 14908 ppi's\n 2846 Positive Protein Interactions were used to Embed a graph with 28466 ppi's\n 1502 Positive Protein Interactions were used to Embed a graph with 15022 ppi's\n 1722 Positive Protein Interactions were used to Embed a graph with 17228 ppi's\n 2612 Positive Protein Interactions were used to Embed a graph with 26124 ppi's\n 528 Positive Protein Interactions were used to Embed a graph with 5284 ppi's\n 636 Positive Protein Interactions were used to Embed a graph with 6366 ppi's\n 1487 Positive Protein Interactions were used to Embed a graph with 14870 ppi's\n 791 Positive Protein Interactions were used to Embed a graph with 7918 ppi's\nYoudens  index: 0.0496 Sensitivity: 0.6652 Specificity: 0.5561\n\n\n\n\n\n\n\n\n\n\nEvaluating Model with 20.0% of PPI's\n 7428 Positive Protein Interactions were used to Embed a graph with 37140 ppi's\n 2981 Positive Protein Interactions were used to Embed a graph with 14908 ppi's\n 5693 Positive Protein Interactions were used to Embed a graph with 28466 ppi's\n 3004 Positive Protein Interactions were used to Embed a graph with 15022 ppi's\n 3445 Positive Protein Interactions were used to Embed a graph with 17228 ppi's\n 5224 Positive Protein Interactions were used to Embed a graph with 26124 ppi's\n 1056 Positive Protein Interactions were used to Embed a graph with 5284 ppi's\n 1273 Positive Protein Interactions were used to Embed a graph with 6366 ppi's\n 2974 Positive Protein Interactions were used to Embed a graph with 14870 ppi's\n 1583 Positive Protein Interactions were used to Embed a graph with 7918 ppi's\nYoudens  index: 0.1124 Sensitivity: 0.7235 Specificity: 0.6677\n\n\n\n\n\n\n\n\n\n\nEvaluating Model with 30.0% of PPI's\n 11142 Positive Protein Interactions were used to Embed a graph with 37140 ppi's\n 4472 Positive Protein Interactions were used to Embed a graph with 14908 ppi's\n 8539 Positive Protein Interactions were used to Embed a graph with 28466 ppi's\n 4506 Positive Protein Interactions were used to Embed a graph with 15022 ppi's\n 5168 Positive Protein Interactions were used to Embed a graph with 17228 ppi's\n 7837 Positive Protein Interactions were used to Embed a graph with 26124 ppi's\n 1585 Positive Protein Interactions were used to Embed a graph with 5284 ppi's\n 1909 Positive Protein Interactions were used to Embed a graph with 6366 ppi's\n 4461 Positive Protein Interactions were used to Embed a graph with 14870 ppi's\n 2375 Positive Protein Interactions were used to Embed a graph with 7918 ppi's\nYoudens  index: 0.1843 Sensitivity: 0.7657 Specificity: 0.7335\n\n\n\n\n\n\n\n\n\n\nEvaluating Model with 40.0% of PPI's\n 14856 Positive Protein Interactions were used to Embed a graph with 37140 ppi's\n 5963 Positive Protein Interactions were used to Embed a graph with 14908 ppi's\n 11386 Positive Protein Interactions were used to Embed a graph with 28466 ppi's\n 6008 Positive Protein Interactions were used to Embed a graph with 15022 ppi's\n 6891 Positive Protein Interactions were used to Embed a graph with 17228 ppi's\n 10449 Positive Protein Interactions were used to Embed a graph with 26124 ppi's\n 2113 Positive Protein Interactions were used to Embed a graph with 5284 ppi's\n 2546 Positive Protein Interactions were used to Embed a graph with 6366 ppi's\n 5948 Positive Protein Interactions were used to Embed a graph with 14870 ppi's\n 3167 Positive Protein Interactions were used to Embed a graph with 7918 ppi's\nYoudens  index: 0.2490 Sensitivity: 0.7996 Specificity: 0.7621\n\n\n\n\n\n\n\n\n\n\nEvaluating Model with 50.0% of PPI's\n 18570 Positive Protein Interactions were used to Embed a graph with 37140 ppi's\n 7454 Positive Protein Interactions were used to Embed a graph with 14908 ppi's\n 14233 Positive Protein Interactions were used to Embed a graph with 28466 ppi's\n 7511 Positive Protein Interactions were used to Embed a graph with 15022 ppi's\n 8614 Positive Protein Interactions were used to Embed a graph with 17228 ppi's\n 13062 Positive Protein Interactions were used to Embed a graph with 26124 ppi's\n 2642 Positive Protein Interactions were used to Embed a graph with 5284 ppi's\n 3183 Positive Protein Interactions were used to Embed a graph with 6366 ppi's\n 7435 Positive Protein Interactions were used to Embed a graph with 14870 ppi's\n 3959 Positive Protein Interactions were used to Embed a graph with 7918 ppi's\nYoudens  index: 0.3517 Sensitivity: 0.8204 Specificity: 0.8012\n\n\n\n\n\n\n\n\n\n\nEvaluating Model with 60.0% of PPI's\n 22284 Positive Protein Interactions were used to Embed a graph with 37140 ppi's\n 8944 Positive Protein Interactions were used to Embed a graph with 14908 ppi's\n 17079 Positive Protein Interactions were used to Embed a graph with 28466 ppi's\n 9013 Positive Protein Interactions were used to Embed a graph with 15022 ppi's\n 10336 Positive Protein Interactions were used to Embed a graph with 17228 ppi's\n 15674 Positive Protein Interactions were used to Embed a graph with 26124 ppi's\n 3170 Positive Protein Interactions were used to Embed a graph with 5284 ppi's\n 3819 Positive Protein Interactions were used to Embed a graph with 6366 ppi's\n 8922 Positive Protein Interactions were used to Embed a graph with 14870 ppi's\n 4750 Positive Protein Interactions were used to Embed a graph with 7918 ppi's\nYoudens  index: 0.4110 Sensitivity: 0.8645 Specificity: 0.8101\n\n\n\n\n\n\n\n\n\n\nEvaluating Model with 70.0% of PPI's\n 25998 Positive Protein Interactions were used to Embed a graph with 37140 ppi's\n 10435 Positive Protein Interactions were used to Embed a graph with 14908 ppi's\n 19926 Positive Protein Interactions were used to Embed a graph with 28466 ppi's\n 10515 Positive Protein Interactions were used to Embed a graph with 15022 ppi's\n 12059 Positive Protein Interactions were used to Embed a graph with 17228 ppi's\n 18286 Positive Protein Interactions were used to Embed a graph with 26124 ppi's\n 3698 Positive Protein Interactions were used to Embed a graph with 5284 ppi's\n 4456 Positive Protein Interactions were used to Embed a graph with 6366 ppi's\n 10409 Positive Protein Interactions were used to Embed a graph with 14870 ppi's\n 5542 Positive Protein Interactions were used to Embed a graph with 7918 ppi's\nYoudens  index: 0.4037 Sensitivity: 0.8886 Specificity: 0.8195\n\n\n\n\n\n\n\n\n\n\nEvaluating Model with 80.0% of PPI's\n 29712 Positive Protein Interactions were used to Embed a graph with 37140 ppi's\n 11926 Positive Protein Interactions were used to Embed a graph with 14908 ppi's\n 22772 Positive Protein Interactions were used to Embed a graph with 28466 ppi's\n 12017 Positive Protein Interactions were used to Embed a graph with 15022 ppi's\n 13782 Positive Protein Interactions were used to Embed a graph with 17228 ppi's\n 20899 Positive Protein Interactions were used to Embed a graph with 26124 ppi's\n 4227 Positive Protein Interactions were used to Embed a graph with 5284 ppi's\n 5092 Positive Protein Interactions were used to Embed a graph with 6366 ppi's\n 11896 Positive Protein Interactions were used to Embed a graph with 14870 ppi's\n 6334 Positive Protein Interactions were used to Embed a graph with 7918 ppi's\nYoudens  index: 0.5219 Sensitivity: 0.9028 Specificity: 0.8244\n\n\n\n\n\n\n\n\n\n\nEvaluating Model with 90.0% of PPI's\n 33426 Positive Protein Interactions were used to Embed a graph with 37140 ppi's\n 13417 Positive Protein Interactions were used to Embed a graph with 14908 ppi's\n 25619 Positive Protein Interactions were used to Embed a graph with 28466 ppi's\n 13519 Positive Protein Interactions were used to Embed a graph with 15022 ppi's\n 15505 Positive Protein Interactions were used to Embed a graph with 17228 ppi's\n 23511 Positive Protein Interactions were used to Embed a graph with 26124 ppi's\n 4755 Positive Protein Interactions were used to Embed a graph with 5284 ppi's\n 5729 Positive Protein Interactions were used to Embed a graph with 6366 ppi's\n 13383 Positive Protein Interactions were used to Embed a graph with 14870 ppi's\n 7126 Positive Protein Interactions were used to Embed a graph with 7918 ppi's\nYoudens  index: 0.6208 Sensitivity: 0.9041 Specificity: 0.8435\n\n\n\n\n\n\n\n\n\n\n\n\nIt’s obvious that increaings the PPI percentage the model will learn more and get better accuracy.\nOkay! We trained a graph neural network that predict protein-protein interactions!\nIt’s important to mention two things:\n\nBig part of the code on this post is reused from the work of Perez et al.\nPerez et al. also trained a DistMult based prediction model (an a priori model) that doesn’t need graph structure knowledge. I tried to implement this but, due to the small gene set (Unfolded protei binding), this model doesn’t improve larger than 5% percent of accuracy.\n\nFinally, on the next post, I will use this trained model to predict the protein-protein interactions of the proteins expressed by identified genes in a transcriptomic experiment made on Coffea arabica."
  },
  {
    "objectID": "posts/proteinbert/load_string_protein.html",
    "href": "posts/proteinbert/load_string_protein.html",
    "title": "Protein Embedding with ProteinBERT and STRING",
    "section": "",
    "text": "On this project we’ll learn how to use ProteinBERT (a large language model trained developed protein sequences) to get embeddings for aminoacids sequences and how to use this embeddings for visualization.\nLastest deep learning models architectures designed foe sequences (e.g. text, audio) like GPT, BERT or LLama 3, combined with training on massive datasets, have led to a revolution on natural language processing tasks.\nHowever, most sequence-based models have been designed for processing natural languages (with a bias towards English). In this context, their architectures and pretraining tasks are not optimal fo aminoacid sequences, which differe from the human language. To mention some disimilarities, proteins dont have building blocks (words and/or sentences), have more variable length than sentences and have many interactions detween distant positions (secondary and tertiary structure).\nIn this context ProteinBERT was developed and trained on ~106M proteins (representing the entire known protein space) derived from UniProtKB/UniRef90 and on the 8943 most frequent gene ontology annotations Brandes et al. (2022), Rajan and Perez (2023).\nCode\nimport random\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, metrics, preprocessing\nimport copy\nfrom torch_geometric.utils import degree\n\nimport torch\nfrom torch import nn, optim, Tensor\n\nfrom torch_sparse import SparseTensor, matmul\n\nfrom torch_geometric.utils import structured_negative_sampling\nfrom torch_geometric.data import download_url, extract_zip\nfrom torch_geometric.nn.conv.gcn_conv import gcn_norm\nfrom torch_geometric.nn.conv import MessagePassing\nfrom torch_geometric.typing import Adj\n\nfrom Bio import SeqIO\n\nimport zipfile\nimport io\nWe’re gonna use the STRING database from protein interactions to retrieve genes that belong to the ontology Unfolded protein binding (GO:0051082) which belongs to the heat shock response. Specifically, I’m choosing Coffea canephora (robust coffee) due to the results achieved my thesis (Functional analysis of transcriptomes of Coffea arabica L. related to thermal stress) were I studied a related species: Coffea arabica (expensive coffee). Just to mention, the heat shock response is available from prokaryotes to eukaryotes, this means is a “conserved” response on all species.\nFrom this database, we need to download the files “… as tabular text output:” and “… protein sequences:”. These links are below the generated graph on the STRING database.\nThese files and with “_interactions.tsv” and “_sequences.fa”.\nNow, we are ready to load this data."
  },
  {
    "objectID": "posts/proteinbert/load_string_protein.html#data-loading",
    "href": "posts/proteinbert/load_string_protein.html#data-loading",
    "title": "Protein Embedding with ProteinBERT and STRING",
    "section": "Data Loading",
    "text": "Data Loading\n\n\nCode\nwith zipfile.ZipFile(\"coffea_arabica_string_interactions.zip\", 'r') as z:\n    # List all file names in the zip file\n    file_names = z.namelist()\n    \n    tsv_files = [file for file in file_names if file.endswith('interactions.tsv')]\n\n    for tsv_file in tsv_files:\n        with z.open(tsv_file) as f:\n            df = pd.read_csv(f, sep='\\t')\n            print(f\"Data from {tsv_file}:\")\n            print(df.head())  # Display the first few rows of each DataFrame\n\n\nData from coffea_arabica_string_interactions.tsv:\n       #node1       node2   node1_string_id   node2_string_id  \\\n0  A0A068TKM9  A0A068TNA3  49390.A0A068TKM9  49390.A0A068TNA3   \n1  A0A068TKM9  A0A068TLP4  49390.A0A068TKM9  49390.A0A068TLP4   \n2  A0A068TLP4  A0A068TKM9  49390.A0A068TLP4  49390.A0A068TKM9   \n3  A0A068TLP4  A0A068TNA3  49390.A0A068TLP4  49390.A0A068TNA3   \n4  A0A068TMA4  A0A068VEQ2  49390.A0A068TMA4  49390.A0A068VEQ2   \n\n   neighborhood_on_chromosome  gene_fusion  phylogenetic_cooccurrence  \\\n0                         0.0          0.0                      0.000   \n1                         0.0          0.9                      0.431   \n2                         0.0          0.9                      0.431   \n3                         0.0          0.0                      0.000   \n4                         0.0          0.0                      0.000   \n\n   homology  coexpression  experimentally_determined_interaction  \\\n0       0.0         0.000                                  0.122   \n1       0.0         0.000                                  0.000   \n2       0.0         0.000                                  0.000   \n3       0.0         0.000                                  0.122   \n4       0.0         0.316                                  0.204   \n\n   database_annotated  automated_textmining  combined_score  \n0               0.585                 0.000           0.620  \n1               0.000                 0.000           0.940  \n2               0.000                 0.000           0.940  \n3               0.585                 0.000           0.620  \n4               0.000                 0.056           0.441  \n\n\nHere, we are gonna define a function that use biopython to load the fasta file and parse the sequences to a dictionary where the protein names are the key and the sequences are the values:\n\n\nCode\ndef read_proteins_from_fasta(fasta_file):\n    protein_dict = {}\n    for record in SeqIO.parse(fasta_file, \"fasta\"):\n        protein_dict[record.id] = str(record.seq)\n    return protein_dict\n\n\n\n\nCode\nwith zipfile.ZipFile(\"coffea_arabica_string_interactions.zip\", 'r') as z:\n    # List all file names in the zip file\n    file_names = z.namelist()\n    \n    tsv_files = [file for file in file_names if file.endswith('sequences.fa')]\n\n    for tsv_file in tsv_files:\n        with z.open(tsv_file) as f:\n            f_text = io.TextIOWrapper(f)\n            protein_sequences_dict = read_proteins_from_fasta(f_text)            \n            print(f\"Data from {tsv_file}:\")\n            print(protein_sequences_dict)  \n\n\nData from coffea_arabica_string_protein_sequences.fa:\n{'49390.A0A068TKM9': 'MYMYMYVYVYRAVFSLLCFHLIFSSSFHAAYMYLWCIFTGTILDLTCIIAVLGKIYNYQSFTANLKIHYCYLFPVKTIPLLWCEIMDCNCCYTLARPSSSITPVLNFQSVSAVNRNFSVKNLHPRVLPSPGSCRQFGRLSDQFRPFIYQGNSELPCLRTYRGQISSEARRQGWDFGRFLKTLYFFNGPPSPAKFFEFLIEKLSNPSPSKTENRMDPSGVILVAGATGGVGRRVFDILRSKGYTVKVLVRNEDKARRMLGPDVDLIVGDITKASTLVPEYFKGVRKVINAVSVIVGPKEGDTPDRAKYSQGIKFFEPEIKGASPEMVEYIGMKNLINAVKESVGIRRGKLVFGFEENLTRELAWGALDDVVMGGVSESSFVIDPTGGEKGGPTGVFRGVVSTANNGGFTSIRTKNFPVPEDLSAYDGLELRLKGDGRRYKLIVRTSCDWDTVGYTLSFDTIEGQWQSIQLPFSSLRPVFRARTVSDAPPFDARQIASLQA', '49390.A0A068TLP4': 'MFSKFEYDGKLNPTFKEGPFQLPVSSIKTFMKEPVTPRFVHVSSAGVARPERPGLDLSKQPPAVRLNKELGFILTFKLKGEDLIRESGIPHTIVRPCALTEEPAGADLIFDQGDNITGKISREEIARICIAALESPYACDKTFEVKSVIPFSEPYTVDPANPPPEKDYNQYFKSLKDGITGKESLEKSPAAV', '49390.A0A068TMA4': 'MATAVLLRSLRRRELASAPISAYKSLVGNTKSAWISANSSSNWASLTRPFSSKPLGNEVIGIDLGTTNSCVAVMEGKNPKVIENSEGSRTTPSVVAFNQKGELLVGTPAKRQAVTNPNNTLFGTKRLIGRRFDDLQVQKEMKMVPYKIVRAPNGDAWVEANGQQYSPSQVGAFVLTKMKETAEAYLGKTIDKAVITVPAYFNDAQRQATKDAGRIAGLDVQRIINEPTAAALSYGSNNKEGLVAVFDLGGGTFDISILEIANGVFEVKATNGDTFLGGEDFDNALLEFLVSEFKGNEGIDLTKDRLALQRLREAAEKAKIELSSTTQTEINLPFITADASGAKHLNITLTRSKFETLVNHLIERTRQPCKNCLKDAGVSSNEVDEVLLVGGMTRVPKVQEVVAEIFGKSPSKGVNPDEAVAMGAAIQGGILRGDVKELLLLDVTPLSLGIETLGGVFTRLINRNTTIPTKKSSVFSTAADNQTQVGIKVLQGEREMASDNKLLGEFELVGIPPAPRGMPQIEVTFDIDANGIVTVSAKDKSTGKEQQITIRSSGGLSEAEIEKMVREAEVHAQKDQERKALIDLKNQADTAIYSIEKSVSEYKDKVPAEVVSEIQAAVSDLRAALQNDNADEIKAKLDAANKAVSKIGEHMSGSGQSGGSASGGSQGGDQATEAEYEEVKK', '49390.A0A068TMI8': 'MADPVARSPPANLYSILGISKAASLADISKAYKSLVMKWHPDRNTSNKAEAEAKFSTINEAYRVLSSKKREEINGTSHDDPKTPENSYHHRSSSDDDGQFVISSPTLLSSTSTRITPTGTPRSSDGSSHRGYYSGAPSPRNFYGHSRSPNGTDTPSTPTTPEPPLVSLSKITSKRATNPIIYSQTTARRKAQPIQKKLECTLEELCHGCVKKVKITRDVISNAGIIVQEEEILRIKVKPGWKKGTKITFEGKGDERPGMHPADIIFIIDEKRHPLFKREGDDLELGVEIPLVQALTGCTISVPLLGGDQMDLSIGDIIFPGYEKIIPDQGMPISKQHGRRGDLRLRFLVEFPTDLSKQQRSAVVRILEDCC', '49390.A0A068TMJ2': 'MKPHFRSGFWLFFVVLLFVGLSGNLISAQTRSPKNVQVALRAKWSGTPLLLEAGELLSSQWKDFYWDFTEFWLLKGSEDSGSHTAKDCLRTIVNYGKSLLSKPLASVFEFSLTLRSASPRLVLYRQLAEDSLSSFPLVDYSSASSNEGGFETNDNAKSKKVEPLLLGVNSRAPNGKCCWVDTGAALLFDANELLLWLENPDKATTDTFQQPELFEFDHVHPDSSIGSPIAILYGALGTDCFKEFHNVLVGTARQGKITYVVRPILPSGCESKVGHCGAIGTRDAVNLGGYGVELALKNMEYKAMDDSAVKKGVTLEDPHTEDLSQDVRGFIFSRILERKPELTSEVMAFRDYLLSSTISDTLDVWELKDLGHQTAQRIVHASDPLQSMQEINQNFPSIVSSLSRMKLNDSIKDEIIANQRMIPPGKSLLALNGALINIEDVDLYLLVDMVQQELSLADQFSKMKIPSTNVRKLLSILPPSESNMIRVDFRSTHVHYLNDLEHDIIYKRWSSSINEILMPVFPGQLRYIRKNIYHAVYVLDPASICGLEASY', '49390.A0A068TMU0': 'MQTIEMVISLFENNLPMRFGVILYSANIIQKIEANGDELQRSLEDDLKSEEDVSSLVIRLFLHIKENHGNLMAFQFLSNVNKLRIESAPEEAPEIHHVEGAFVETLLPSAKTPPQDILLKLEKEKTYHELSQESSMFVFKLGLAKLQCCLLMNGLVYDSNEEALFNAMNDELPRIQEQVYYGLINSNTDVLDKFLAESGIQRYNPQIIAGGKVKPKFVSLSASILRNGSWINEISYLHSSDTVDDIKPVSHLLAVDFTSKKGIKMLREGLSYLMGGSKIARLGVLFNSNEEANSLSYIFVKVFEIAASSHSHKKGVLEFLDQVCSLYEREYMTSTSPDNEKSQEFIDKVVDLAVASGLPSKGYESPLSTFSVGKLKNHLIKVAQFLYRQLGFHSGVNAVITNGRVVPVGGGVFLSHDLSLLESIEFKQRIKQIADIIEELKWEDMDPDLLTSKFISDIILSISSSMAMRERSSESARFEILSSTCSAVVLDNEDSSIHIDAVIDPLSSSGQKLSSLLRFLSKYIQPSMRLLLNPVSSLVDLPLKNYYRYVVPTLDDFSSIDDTVYGPKAFFANMPLSKTLTMNLDVPEPWLVEPVIAIHDLDNILLENLGDARTLQAVFELEALVLTGHCSEKDHEHPRGLQLILGTKSTPHLVDTLVMANLGYWQMKVFPGVWYLQLAPGRSSELYVMKEDGDGSPYTTLSKQITINDLRGKLVHLEVLKKKGKENEKLLLASDSDESHSRQNRNGDQKSWNSNLLKWASGFIGGSDRSKKIESTSVEHGNTGRRGKTINIFSVASGHLYERFLKIMMLSVLKNTRRPVKFWFIKNYLSPQFKDVIPHMAQEYGFEYELVTYKWPTWLHKQKEKQRIIWAYKILFLDVIFPLALEKVIFVDADQIVRADMGELYDMNLKGRPLAYTPFCDNNKEMDGYRFWKQGFWKEHLRGRPYHISALYVVDLVKFRETAAGDQLRVFYETLSKDPNSLSNLDQDLPNYAQHLVPIFSLPQEWLWCESWCGNATKSKAKTIDLCNNPMTKEPKLQGAKRIVAEWPDLDLEARQFTAKISGEPIDLKEQVALPLESQSSTIHDSSEDWESKSEL', '49390.A0A068TMW0': 'MHNSFVNWSRRGGNRCFKMLYWERISKTAGYVGEDVESILYKLLMVADFNVEAAQKGIVYIDEMDKMTKKAENLSAGRDVSGEGVQQALLKMLEGTIVNVPDNRARRNPHGDSIQIDTKNILFICGGAFVDLEKTISERRQDSSIGFGAPVRANMRQAGLTDAAVTSSLLESVESGDLIAYGLIPEFVGRFPILVSLSALDEDQLVQVLTQPKNALCKQYKRMFAMNKAKLHFEDNALRLVAKKAIAKKTGARGLRAILENILTEAMFEIPDAGSGRNLIDLVLVDEDAVGSLDRPGLGAKIIHGNGGLERSPYETELRDGQEGGEMVRVDLDGELEVSSAALSL', '49390.A0A068TNA3': 'MSRFRGLWQASVNATKKALTWNVDDWIPPSEKYIFSFNSKDELKKWHLYSDSEYGGLSTASLEIKNVGNASSVTTGIFSGNLSSELSESSRWNISRSGFCGMRSRKFDGFIDLESYDSIALKLKGDGRCYISTIYTENWVNSPAQHEDNSWQAFVFVPKDNWYIAKIPIARYLPTWRGNVIDANLEMNPSRVVGMSFSVNAEGGVPGARTGPGDFRVEIDWIKALRTQ', '49390.A0A068TNP3': 'MSEVDEESKQVSYVVVRDENGNVKLDCPAIGKMFAAEEISAQVLRKLVDDASKFLNDKVTKAVVTVPAYFNDSQRTATKDAGRIAGLEVLRIINEPTAASLAYGFEKKNNETILVFDLGGGTFDVSVLEVGDGVFEVLSTSGDTHLGGDDFDKRIVDWLADNFKKDEGIDLLKDKQALQRLTETAEKAKMELSSLTQTNISLPFITATADGPKHIETTLARAKFEELCSDLLDRLKRPVQNSLSDAKLSFSDIDEVILVGGSTRIPAVQEVVKKLTGKDPNVTVNPDEVVALGAAVQAGVLAGDVSDIVLLDVTPLSLGLETLGGVMTKIIPRNTTLPTSKSEVFSTAADGQTSVEINVLQGEREFVRDNKSLGSFRLDGIPPAPRGVPQIEVKFDIDANGILSVAAVDKGSGKKQDITITGASTLPSDEVERMVKEAEKFSREDKEKRDAIDTKNQADSIVYQTEKQLKEFGDKVPAAVKEQVEAKVGELKDAISGDSTQAIKDAMAALNQEVMKLGSSVYGKPGESPDAGAAPGTEPGPSGKGNDGDVIDADFTDSK', '49390.A0A068TP17': 'MSGIFRYKTKLRSLAPKITTLSLSSSKFQSSPRKTLSKISEYFPHPQPRPHLNPLGFVSHIQERHKWHGSSDNYDHIKAEVNCPRCSKLMSVLFSNRPLSISRSEPGVYQAVNLCPNCRTAFYFRPFKLEPLQGSFIELGRLKGGKVDMEGNSESGGTGGRGGENGKKIWEKLRNYSGGSSASSNNVKEGSSNSGGDVEEKAVGPAWVEVGSGGGEFEGANLGKELPTPKEISRGLDDFVVGQERAKKVLSVAVYNHYKRIYHASLHGESGAEYRSTDGKIGDFDADDVELEKSNVLMMGPTGSGKTLLAKTLARVVNVPFVIADATTLTQAGLR', '49390.A0A068TPE5': 'MSTVVEAINHLFNFPETLDKFMLNSSSRAGEGAGSVANDSRGGVGSLPAVDILDSPKAYVFYVDVPGLSKSDIQVTLEDENTLVIRSNGKRKREDGEEEGCKYIRLERSAPQKLSRKFRLPDNANASAISANCENGVLTVAVEKLPPPPKSKTVQVAIS', '49390.A0A068TPQ0': 'MERMKRKPNLRYLLLMLVVGCFFSELKASSNSEFYESFEEAIEGRWVVSQKEDYKGVWKREKSEGHDDYGLLVSEKAKKYAIVKELDEPADLKDGTVVLQYEVRLQEGLECGGAYLKYLRPQDAGWTSKEFDNESPYSIMFGPDKCGATNKVHFILKHKNPKTGEFIEHHLKFPPSVPSDKLTHIYTAILKPDNELRILIDGEEKKKADFLSAEDFEPPLIPSKTIPDPDDKKPEDWDERAKIPDPDATKPDDWDEDAPLEIVDEDAVKPEGWLDDEPEEIDDPEATKPEDWDDEEDGEWEAPKIDNPKCAEGPGCGEWKRPMKRNPAYKGKWHAPMIDNPNYKGIWKPQEIPNPSYFELDRPDFEPIAAIGIEIWTMQDGILFDNILIASDEKVAESYRTTTWKPKFEVEKEKQKAEEAAADTGALKGFQKTVFDLLYKVADLPFLGEHKLKVLDLLEKAEKQPNLTIGVIISIIVVIFTLLLKIIFGGKKPARAREEPEKTDAPESSSNQETTEETTEEKEEPNEDAGAAPRRRIRRDN', '49390.A0A068TPY9': 'MAIVPCGSTWMARCGVQPQIVARFTVTNKLSLPPDCVASRSKVLASPSSTFFSQRPLHVLFNSGSCKDSRQKRGARFAVRAQQDYYSVLGVSKNASKSEIKSAYRKLARSYHPDVNKEPGAEQKFKEISNAYEVLSDDEKRSIYDRYGEAGLKGSMGMGDFSNPFDLFESLFDGLGGMGMGARGSRNRATEGEDQVYNLVLDFKEAIFGVEKEIEIMRLENCGTCDGSGAKPGTRTAKCSACGGQGQVVSSARTPLGVFQQIMPCSACGGAGETSTPCNTCGGDGRVRKSKRISLKVPAGVDSGSRLRVRSEGNAGRRGGPPGDLFVIIEVRPDPVLKRDDTNILYTCKVTYIDAILGTTLKVPTVDGMVDLKVPSGTQPGTTLVMAKKGVPFLNKSNMRGDQLVRVQVEIPKRLSGEERKLIEELANLNKAKAPNSRR', '49390.A0A068TQ83': 'MANSATLTLSSPEPPQSRIAPVFPFSSSSSSFLAGGTHLRSHKKFISVSLSSSSSQFSNKISARRFGRLVVAAADYYSTLGVSKSASGKEIKAAYRRLARQYHPDVNKEPGATDKFKEISAAYEVLSDDKKRALYDQYGEAGVNSSMGGQAGAYTTNPFDLFETFFGPSMGFPGMDATGFGTRQRSTVTKGEDLRYDIRLEFSAAIFGAEKEFELSHLETCEACAGTGAKTGSKMRICSTCGGRGQVMRTEQTPFGMFSQVSICPNCGGNGEMISEYCRKCSGQGRIRVKKDIKVKIPPGVGKGSILRVAGEGDAGPKGGPPGDLYVYLDIEEIPEIQRDGINLSSTVSISYLDAILGTVTKVKTVEGLTDLQIPPGTQPGDVLVLARKGAPKLNRPSIRGDHLFTVKVSIPKKISSQERELLEELASLSSKPGKRSKTRPNVQQTTKTVQSETDSATNNSEESEEQNDLWKKFTDFAGSVANGALKWLKDNL', '49390.A0A068TQM6': 'MVKATRFVFMSLLVLAAVAALLPEQAEALMPYSPRSFWDMMLPNEDPFRILEHSPLTVPKGVETLALARADWKETAKEHVISLDVPGIKKEEVKIEVEDNRVLRVSGERKTEEEVEGDKWHRAERTVGKFWRQFRLPGNADLDKVQAHLENGVLEIVVPKLAEEKKKQPKVINIAEEAGSNTGVDVKAKRDEM', '49390.A0A068TQP9': 'MAAKGEGKAIGIDLGTTYSCVGVWQNDRVEIIPNDQGNRTTPSYVAFTDTERLIGDAAKNQVAMNPQNTVFDAKRLIGRRYSDPSVQADMRHWPFKVIAGPGDKPMMVVRYKGEEKHFAPEEISSMVLTKMKEVAESFLGQTVKNAVITVPAYFNDSQRQATKDAGAIAAINVMRIINEPTAAAIAYGLDKKGSRTGEKNVLIFDLGGGTFDVSLLTIEEGIFEVKATAGDTHLGGEDFDNRLVNHFVQEFKRKNKKDISGNARALRRLRTACERAKRTLSSTAQTTIEIDSLYEGIDFYATITRARFEELNMDLFRKCMEPVEKCLRDAKVDKSHVHDVVLVGGSTRIPKVQQLLQDFFNGKELCKSINPDEAVAYGAAVQAAILGGETDQKVQDLLLLDVTPLSLGLETAGGVMTVLIPRNTTIPTKKEQIFSTYSDNQPGVLIQVYEGERPMTKDNNLLGKFELSGIPPAPRGVPQINVCFDIDANGILNVSAEDKTAGVKNKITITNDKGRLSKGEIERMVQEAERYKAEDEAVKKKVEAKNSLENYAYNMKNTVRDEKFAGKLDPSDKQKIEKAIDEAIEWLDGNQLAEVDEFEDKQKELEALCNPIIAKMYQGAGGDVPMGGGAADMPGAGRGTADSGSNGPGPKIEEVD', '49390.A0A068TQV0': 'MQLAVTPKPNPTNNTFSNPNFYPNFTSPKTQSLKFSSSSSSSNVPINLFYSFSPRRRRLSPVIARATAKTPDYYSVLSVSKNASLQDIKAAYRKLARKYHPDVNKKPGAEEKFKEISAAYEVLSDDEKRSAYDRFGEAGLRGDFVGSTSGSQGVDPFEIFSEYFGESSSFFRGSGEPGGFNFSFRSKSRQDLDIRYDLYMSFEESIFGSQREIEVPSLETCNDCSGTGAKTSNSIKICNACGGRGGVAKTQQTPFGIMSQVSTCAKCGGVGKIITDHCLTCGGNGRIQSKRRINIVIPPGIDNGATMQVQGEGNIDNKRGIAGDLFIVLHIEEKHGIQRDGLNLYSKVKVDFTEAILGTVVKVKTVEGVRDLHIPPGIQPGDTIKMRSMGVPHINKPSVRGDHCFAVNIQIPKDISDAERSLVEELALLRQTSRDSISSSEIPGGDDHDQHTKPALDHRGKSMAYLWKSIKDFLGKKQSGKRFASVGMEAPVSWRVTSPLPRCSLMIYSPAIFIMTLVFTLVGRTAYCKLFRQKPKTKSTSPHPERTQGQR', '49390.A0A068TR15': 'MAAPAAVASAPRASSSKTDTFVDNKRKDDIRMANISAAQSVADAVRTSLGPKGMDKMISTANGEVIITNDGATILNKMEVLQPAAKFLVELSKSQDVVAGDGTTTVVVIAGALLKSCLSLLTSGIHPTIISDALHKASVKAVEVLTAMAVPVELSDRESLVKSASTALNSKVVSQYSTLLAPLAVDAVLSVVDPAKPDLVDLRDIKIVKKLGGTVDDTELVKGLVFDKKVSHAAGGPTRVENAKIAVIQFQISPPKTDIEQSIVVSDYTQMDRILKEERNYILGMIKKIKATGCNVLLIQKSILRDAVTDLSLHYLAKAKILVIKDVERDEIEFITKTLNCLPIANIEHFKAEKLGFAELVEEVSLGDGGKLVKITGIKDMGRTTSVLVRGSNQLVIDEAERSLHDALCVVRCLVNKKFLIAGGGAPEIELSRQLGAWAKVLQGMEGYCVRSFAEALEVIPYTLAENAGLNPIAIVTELRNRHAQGEINAGINVRKGQITNILEENVVQPLLVSTSAIALATECVRMILKIDDIVTVR', '49390.A0A068TRG1': 'MLVNYVHRTLNKHSYISHCCFTLQFPGQLSPDSSFASMGRARTDSDIKSHLVTEICNISDRAVTCAHQHHFRSTNPPFVDWYLVLKVDENAGPDIIRKHYLRLALQLHPDKNKHPKADTAFKLVSEAYACLSDDARRTAFNLERHRNFCFKCSNISDDSPIPSNTKPKRIPTSERTRSNHALQRMKDLRARFMEEATIIENCLKANAASRVSDSSRKELPTFNPADYLSQGYPHRTTSNNKKLERSISRNYGLHILRTKP', '49390.A0A068TRT0': 'MGEDEAIAKSSEDQNDDGVSESKAVPVEDKESINDENVEKFLDSMDDYLILVDSLSSILRQGWLELASARHSMGASRISASSYDMKYHSAATTLQLQHETASSDVGQPHFVLRKWESLDSPKKDPSDSPTRDPCEAKLEEDKWVQSVSSGLRIRTKGTSESSESREKKAENTGSPLSVDGHAQKERLKALSMFGALAPPKLRAAQLSFETALETLADIANVRASLLRAYEQVQKEMESPIQ', '49390.A0A068TS27': 'MYWMLLFVHFCFGDILFCFNCMGEKSIFSRRRGFFSRSFAHGETDEEDTLKESRRIACRKCGNFHVWIHTKKVKSRARWCQECKDFHQAKDGDGWVEQSSHPLLFGMLQKACISRNHCIIY', '49390.A0A068TS31': 'MALARLALKNLQQRVAPASSSLPSFQCASERTVNSVQKRRWGSELLRRISSAAGKEDSAGQQVAVSEGGKKSNKLFPKKKQRSSLWKKEDDNFPPPLWEFFPSGLGNSLVQASENINRLLGNLSPSRLLGKFKEQDDLYKLRLPVPGLAKEDVKVTVDDGVLTIKGERKEEEEGSDDDDDEDDHWASFYGYYNTSVLLPDDAKVDEIRAEMKDGVLTVVIPRTERPKKDVKEISVH', '49390.A0A068TSW5': 'MAAEPAYTVASDSETTGEEKSSSPLSEISIGIDIGTSQCSIAVWNGSQVEVLKNTRNQKLMRSYVTFKSDFPSGGVSNQLAHEYDMLTGATIFNMKRLIGRLDTDSVVHASKNLPFLVQTLNIGVRPFIAALVNNMWRSTTPEEVLAIFLIELRAMAEVQLKRPVRNVVLTIPVSFSRFQLSRIERACAMAGLHVLRLMPEPTAVALLYAQQQQQAVHENMGSGSEKNALIFNMGAGYCDVAVTATAGGVSQIKALAGFTLGGEDMLQNIMHHLLPEMDNLFSSHGIEEIRKIGLLRVATQDAIHKLSFQPSVQINVDLGNGIQICKVLDRNEFEAVNQKVFEKCASLIGQCLREAKVEVEDVNDVILVGGCSYIPKIKSILTSVCKRGELYAEMNPLEAAVCGAALEGAVASGINDPFGSLDLLTIQATPLNIGIRADGNSFVPIVQRNTTMPARRELIFTTVHDNQTEALIIVYEGDETVEETNHLLGYFKITGIPPAPKGIPEINVCMDIDASNVLRVFAGVIMPGAQHPAAPFMEVRMPTVDDGHGWCAEALHRTYGSTLDLITVQKKVQK', '49390.A0A068TSY2': 'MRLNTKEGAKLTETKYRRSPGNYVLLILKLRALSSLYSCAPSPGHPSRHHHHPLPSNCRNKNLPLHPVINSPASNSHISSTKIMAGRAEAEPVNEQAVANVYGSMRAEMNQIYSKITELEMEVSEHSLVINAIQPLDPSRRCYRMIGGVLVERTVKEVLPAVQRNKEGLLEVIARLNEALEKKKKEIADFEAKYKIRIRKADEMKDEGGKKEGSAQGVLVGPAGGDE', '49390.A0A068TTJ9': 'MMHCPACYGRVTCGSCGPIKCVTCMGGGSLLTRKVAVMRWKTLSTRKVSATSRAATVLDDVFHRVQGIQLCNTQAYQCTPTFFADSFFLNKLSSEVTTERALVPHTARVIVRDISSLLSQSLM', '49390.A0A068TTT2': 'MARKKGNQQKKPVPSTASELPAKRERANASEIKVLHEEQLLRNHSDVNSKEGIDNKCHVQAETKGKQQSRKFPRRMEEVVDRKQVEEKPETDAGDCNTTVSAAESLHSMGKDDVPSNTCHSTKNSESSFAYSLNGMHNGDDTMEKVEFSYILILKRLRSLVLSTLKASTEWMERHRPLLITMRASILKACHYVQVKIEQAFPVVLKWIMHFVNIMLLLFMVWLDCTLRGIDSFLRMGTTSFFSVLWCSVLSVTAMVGIFKFLIVLAVAAIAGLLVGLTIAVLLMAISGIVLLWFYGSFWTTMLVLLSGGLAFILGRERVALFIATSYSVYCAWASVGWLGLLFGLNISFISSDVLIFFLRNNINEQRRATGAAEQTAEVPGQSGFVSDDQVRNSSAEAGAAGPSTDRRSGVPSTSGLDSETTSEDEVVRLLNCSDHYAALGLSRFENIDVSVLKREYRKKAMLVHPDKNMGNEKAAEAFKKLQNAYEVLLDSFKRKAYDDELRREELLHYFRQFQEVSQKA', '49390.A0A068TUK4': 'MGTTNSAVAAMEGGKPAIVTNAEGQRTMPSVVAYTKNGDRLVGQVAKRQAVVNLETSFSL', '49390.A0A068TUL0': 'MFGRAPKRSDNTKYYEVLGVSKNASQDDLKKAYRKAAIKNHPDKGGDPEKFKELAQAYEVLSDPEKREIYDQYGEDALKEGMGGGGGVHDPFDIFQSFFGGSPFGGGGSSRGRRQRRGEDVIHPLKVSLEDLYNGTSKKLSLSRNVLCPKCKGKGSKSGASMKCSGCQGSGMKVSIRQLGPSMIQQMQHPCNECKGTGETINDKDRCPQCKGEKVVQEKKVLEVVVEKGMQNGQKITFPGEADEAPDTVTGDIVFVLQQKEHPKFKRKHDDLFYEHTLSLTEALCGFQFILTHLDGRQLLIKSQPGEVLKPDQFKAINDEGMVVYQRPFMRGKLYIHFNVEFPDYLDPEQCKSLEAVLPPKTTKQITDMELDECEETTLHDVNIEDEMRRKQQAQEAYEEDEDMHGGAQRVQCAQQ', '49390.A0A068TUV5': 'MAEKRKREAPAPAVGIDLGTTYSCAGVWQHGRVEIIANDQGNRTTPSFVAFTNTGRFIGDAAKNQVDMNPTNTVFGAKRLIGRKYIDPSVQSDIKHWPFKVIPGLGNKPMIVVTYKGEEKLFATEEISAMVLAKMKETAEAYLGSTVKDAVVTVPAYFNDSQRQATKDAGVIAGLNVLRIINEPTAASIAYGLDTKSESTGEKNVFIFDLGGGTFDVSILTIEEGIFEVKATAGDTHLGGEDFDNTMVNHFVQEFRRKNNLDISGNPRALWRLKTACERAKRILSFSTKTEIEIDSLFQGIDFYSTISRAKFEELNKDFFTKCMELVQKYLCKSINPDEAVAYGAAVQAAVLSGGGLEKFQDFVLVDITPLSLSIELVGEVASVVVPKNTSIPTKLGKVFVTSKDNQTVVRFTVFEGESASTKDNNLLGSFNLSGIPPAPKGVEMFDVYFDIDANGILNVSAVHKTTGQKNHIIITNDRGRLSKEEIEKMVLAAEKYKFEEEMYKKKVEAKNALEIFAYRMKITIMNEKITAKLPPADKKKIENAIELAIQWLDDKKMIKKCVDDASKSVYVNKVKILMYNPNR', '49390.A0A068TVG9': 'MENKLPCSLEELYKGSKRKMQISRIVLDDYGKPVTVEEVLSIHIKPGWKKGTKITFPEKGNYELGRAPGDLIFVVDEKPHAVFKRDGNDLVMNQRISLLDALTGKTLSLTTLDGRELSIPVKDIVKPGHELRIPNEGMPISKEPGKKGNLRIKFDIKFPSRLSSEQKSELRRVLGRTAD', '49390.A0A068TVU9': 'MAEKRKREVPQLAPAVGIDLGTTYSCVGVWQHGRVEIIANDQGNRTTPSYVAFTDTGRLIGDAAKNQVDTNPTNTVFGAKRLIGRKYIDPSVQSDMKHWPFKVIPGSGNKPIIVVTYKGEEKQFATEEISATVLAKMKETAEAYLGSTVKDAVVTVPAYFNDSQRQATKDAGVIAGLNVLRIINEPTAASIGGTFDVSLLTIEEGIFEVKATAGDTHLGGEDFDNTMVNHFVQEFKRKNNMDISGNPRALWRLKTACERAKRILSFSPKTEIEIDSLFQGNDFYSTISRAKFEELNKDFFTKCMELVQKCLNDAKMDKSCIDDVVLVGGSTRIPKVQQLLQAFFHGKDLCKSINPDEAVAYGAADFVLVDITPLSLSIEVVGEIVAVVVPRNTTIPTKLEKVFATSKDNQTVVRFAVFEGESASSKDNNLLGSFNLSGIPPAPKGAEKFDVCFDIDANGILNVSAVHKTTRQKNHIIITNDRGRLSKEEIEKMVLAAEKYKKTIKLEKITAKLLLADRKKIENAIDQAIQWLDGQPHAEAVEFEEKMEELERICKPIPKMYKGAGRPDMACAMDNNTPSARSGSGRAPPKIETID', '49390.A0A068TVX0': 'MGVDYYKILQVDKSAKDEDLKKAYRKLAMKWHPDKNPNNKKEAEAKFKQISEAYEVLSDPEKRAIYDQYGEEGLKGQVPPPGAGGPGRATFFQTGDGPNVFRFNPRNANDIFDEFFGFSTPFGGMGGAGGMNGGGTRFPSSMFGDDIFSSFGEGRTMNSVPRKAPPIEQNLPCSLEELSKGTTKKMKISREIADASGKTLPVQEILTIDIKPGWKKGTKITFPEKGNEQPNVIPSDLVFIIDEKPHSVFKRDGNDLVVTQKISLAEALTGCTVHLTTLDGRKLTVPINAPIHPDYEEVVPREGMPIPKEPSKRGNLRIKFNIKFPTGLTAEQKSGIKKLLSP', '49390.A0A068TW76': 'MEFTSQEFMVGKCQGEKLVHGETMPLVLLPREASKNGFESLVEGLKKNKEWFEQLIIKNSAVLLRGFDVKNAEEFNEVVELFGWEDMRYVGPAPRTHVYKRIWTANEGPLSEFIYYHHEMVLIKESPSKVILFCETPPPEGGQTPFVPSFRVTERMLEEFPEMVEEIEKKGLKYTFTALSKNDTSSMRGRGWEDAFGTSDRAEAEKRTKLLGMDVEWLPNGGVKTLLGPRPLTRVFEGRKERRMWFNTMVGMYGKEHSSAMMADGTEIPENVVKRCEEIIEEESIQFKWEKGDILFLDNMATLHGRRPSLSPRRVLVTICK', '49390.A0A068TWQ3': 'MAPVLSRSVTSASVASLPYQKAPFSSVETKNSRVGVLGSAFLPRNGLRNSLLKSSGLKWKLERRESRVVVKCEGGAAVAEKEAPEVSGEIHDYQAEVSRLLDLIVHSLYSHKEVFLRELVSNASDALDKLRFLSVTEPGLLGDAGDLEIRIKPDPDNGTITIRDTGIGMTKDELIDCLGTIAQSGTSKFLKALKENKDVGADNSLIGQFGVGFYSAFLVAEKVVVSTKSPRSDKQYVWEAVADSSSYVIREETDPEKLLPRGTQITLHLKEDDKYEFSEPTRIQNLVKNYSQFVSFPIYVWLEKSRTVEVEEEEEPKEGEEKPEGEKPKKKKTTTEKYWDWELTNETKPIWMRSPKEVEKEQYQEFYKKTFNEFLDPLAHIHFTTEGEVEFRSILYIPGMAPLNNEEVINPKTKNIRLYVKRVFISDDFDGELFPRYLSFVKGMVDSDDLPLNVSREILQESRIVRIMKKRLVRKAFDMIQELSESENKEDYKKFWENFGKFLKLGCIEDSGNHKRITPLLRFFSSKSEEEPISLDDYVENMEENQKAIYYLATDSLKSAKTAPFVEKLVQKDIEVLYLIEPIDEVAIQNLQTYKEKKFVDISKEDLELGDEDEVKERETKQEYNLLCDWIKQQLGDQVAKVQVSKRLSSSPCVLVSGKFGWSANMERLMRAQTLGDTASLEFMRGRRILEINPEHPIIKDLNAACKNAPNSTDAKRVVELLYDTALISSGFTPDSPAELGNKIYEMMAMAVGGRWGRAEEGEAWAGEDSTESDASSSEASEAQVVEPSEVRTESDPWE', '49390.A0A068TXJ0': 'MAGKGEGPAIGIDLGTTYSCVGVWQHDRVEIIANDQGNRTTPSYVGFTDTERLIGDAAKNQVAMNPLNTVFDAKRLIGRRFSDSSVQSDMKLWPFKVIAGAGDKPMIVVNYKGEEKQFAAEEISSMVLNKMKEIAEAYLGTSIKNAVVTVPAYFNDSQRQATKDAGVISGLNVMRIINEPTAAAIAYGLDKKASSSGEKNVLIFDLGGGTFDVSLLTIEEGIFEVKATAGDTHLGGEDFDNRMVNHFVQEFKRKNKKDISGNPRALRRLRTACERAKRTLSSTAQTTIEIDSLYEGIDFYSTITRARFEELNMDLFRKCMEPVEKCLRDAKMDKSSVHDVVLVGGSTRIPKVQQLLQDFFNGKELCKSINPDEAVAYGAAVQAAILSGEGNEKVQDLLLLDVTPLSQGLETAGGVMTVLIPRNTTIPTKKEQVFSTYSDNQPGVLIQVYEGERTRTRDNNLLGKFELSGIPPAPRGVPQINVCFDIDANGILNVSAEDKTTGQKNKITITNDKGRLSKEEIEKMVQEAEKYKAEDEEHKKKVEAKNALENYAYNMRNTIKDEKISSKLPAADKKKIEDAIEGAIQWLDGNQLAEADEFEDKMKELESICNPIIAKMYQGAGGPDESGPKIEEVD', '49390.A0A068TXK3': 'MAGEGEVPAIGIDLGTTYSCVAVWQHDRRLIGDAAKNQVAMNPVNTVFALNGIKTVGPSVDIADAKRLIGRSFSDSCVQDDIKLWPFKVIRGPGDKPMIDAGVIAGLNVLRIIKEPTAAAIAYGLDKKSNCKGKINVLIFDLGGGTFDVSVLTIEEGFFEVKATAGDTHLGGEDFDNRMVDHFVQEFKRRHNKDISGSPRPLRRLRTACERAKRALSSAAQTSIEIDALFDGIDFQSTITRPRFEELNMDLFLKCIDPVKDCLRDAKMDKIEVHDVVLVGGSTRIPKDLVLVDVTPLSLGVQTIGEVMSVVIPRNTPIPARKERVFHTSSDNQTVVAFRVFEGERARSTDNYFLGKFELRGIPPAPKGVPKINVCFDLDANGILHVSAEDKFTGQKNQITITNDKGRLSKEQIERMVQEAMKFKYEDEQFKKKLSPAEKETIEDAIEASVEWLARNQHAETYEFEEKRSELESIWNPIILEIYRSADGGRVPMQDHPPFTGSGSPFTESGSSSGFGFKLEEVD', '49390.A0A068TXV8': 'MEGWKPTIVTNAEGQRTMPSVVAYTKNGDRLVGQIAKTGIDSSAISDEFKHKSAKHEQTKMPFNSGQICAQSHRKSSKYAFLIV', '49390.A0A068TZG2': 'MALFGDPFRRFFWSPTIYRTTPGSSALLDWIESPDAHIFKINVPGHKDEIKVQVEEGNVLVIKAEAKEEGGGRGKEKDVVWHVAERGGGITGKAAGFSREIELPEDVKADQIRASVENGVLTVVVPKDTTPKSSKVRNVNVTSKL', '49390.A0A068TZK0': 'MARRLIPTLNRVLIEKLVQPSKTTAGILLPEKSAKLNSGKVVAVGPGLKDKAGNTIPVAVKEGDTVLLPEYGGTQVKLGEKEYHLYRDEDILGILHD', '49390.A0A068TZS7': 'MKFSSVLLLICFLASIFIFSGFAADSLDAYKSITGRKHLNGLNPPRTPGKRSLLSDSKEADTALVAALDGTIFLLELDSMKPLWSFESGSEIYSSYQAPVDEDKENTSGLGSDYYIDLGDDWELYAHNRLGKLKLTKTLEEYISSTPQIAEDGGIVLGSKKTTAFLVDAKTGRLIYTYRTPESSCPKQNNSENTVIHNSTVEGLGLSQSTDLKADELPLYITRTDYALTSFAPNSNKVLWNMTVAEIGAAFLCEEMERSFGRAILNSGFSEPGFNMPLPCQSMALVYRFRNHDMLEPFLRHGGLPEAHSPEIMLPTSIPKPMLPSQPNVDKVLEFLPSQQNVGKSLDSHDISGEEFVLSLPSVTEDGEMRNVQELKISPGGRLSVVLERIGAISSFPFAVTVGIVIYHLVARKFMLVDNPSNTSSGTVPSKRKKSRKSGKSGSSVEKKDIDTHPNGDSANMDDDDDKNMWLNLSQPTFNIEGRRIGKLFVTTKEIAKGSNGTVVLEGIYEGRPVAVKRLVRAHHDVAFKEIQNLIASDRHPNIVRWYGVEQDQDFVYLALERCICSLDDLIHMFSDISGNLSFSKNLDVEDMAKYQIHLDSVKVVIQDPRLWKSNGYPSPILLKLLRDVISGLVHLHELGIIHRDLKPQNVLIIKDRSLCAKLSDMGISKRLTGDMASLGCGSSGWQAPEQLLLGRQTRAVDLFSLGCVLFFCITGGRHPFGNRLERDVNITKNQVDLFLVEHIPEAMDLFSHLLNPNAEMRPKAVEVLAHPLFWSADLRLSFLRDTSDRVELEDRETDSELLKAIEATAPIALGGKWDEKLEPAFLYNIGCYRRYKYDSVRDLLRVMRNKLNHYRELPMEIQEILGSVPEGYDEYFASRFPKLLIEVYRVMSMYCKEEECFIKYFKCSMQ', '49390.A0A068U059': 'MSLLCSPSRSVFQLPQNFSGEAFLPPTSNSSFRRPRAGVVSAAYASYATAESERTTSTCVLPPRLTAPTSFYEVLGIPMGATSGEIKAAYRRLAKGCHPDLAGTDEKSSSADEFIKVHAAYSTLSDPEKRADYDRRLFRSLRGVRLYSTPSPTKSRYSGYSGRNWETDQCW', '49390.A0A068U078': 'MSVFPLQSMLLNTFSSESSCCSMDWKETPEADVFKFDLPGLTKEDVKLQIHDNQVVHLSADRKDEDDQETGESDDRKRGGGGGDEYKWHCKERICGGSFQREFRLPEDALVDQIKASMSDGVLVVTVPKDHHLKKKKLKHRAVEISGVDG', '49390.A0A068U2B6': 'MVGFLSNKISRDELKPGDHIYTWRHGYLYSHHGIYVGDERVIHFTRSAEHEIGTGTVLDRVIFSSSPSNSSDTPCPRCGDQSKASGVISSCLECFLYGDELYRFEYGVSPVVFLARVRGGTCTLAASDPAEHVIHRAEFLLQNGFGGYNIFKNNCEDFAIYCKTGLLVFTSVSLGRSGQATSFVAAVTAIVSSPLRFMTTSFPGLAAVGCSLYCLSRFVSDIGIRRDVTKIPVERLVSRSGLDGSDPESETCSTSASETTKED', '49390.A0A068U2I0': 'MATSILLRSALRRPELHTSALAASRSLVGNVRASPATSPLSRMLTSLRYFSSRPLADDVIGIDLGTTNSCVALMEGKTARVIENAEGTRTTPSVVAFSQKGDLLVGATAKRQAVTNPQNTLFATKRYIGRRFDDPQTQKELKMVPYKIVRAPNGDAWVEANGQTYSPSQVGAFILTKMKETAESYLNKSVNRAVITVPAYFNDAQRQATKDAGRIAGLTVERIINEPTAAALSYGVNNKEGTIAVFDLGGGTFDISILEISNGVFEVKATNGDTFLGGEDFDNTMLEFLVSEFKKAERIDLSKDKLALQRLREAAEKAKIELSSTSQTEINLPFITADASGAKHFNVTLTRSKFETLVYHLIERTKAPCISCLKDAGVSTTDIDEILLVGGMTRVPKVQQVVAEIFGKSPSKGVNPDEAVAMGAAIQGGILRGDVKDLLLLDVTPLSLGLETMGGIFTRLINRNTTIPTKKSQVFSTAADNQTQVDIKVLQGEREFAADNKLLGEFNLEGIPPAPRGNPQIEVTFDIDANGIVTVSAKDKTTGKEQQITIRSSGGLSEDEIQKMVKEAELHSQKDLEKKELIDQRNSAETTIYSIEKSLTEFRDKVPAEVVTQIQSAVSDLRKAMDGENVDEIKAKMEAANKAVSKIGEHMAGGSGGNTSGGSDPQGGDEAQETEYQEVRK', '49390.A0A068U2R7': 'MSLRVLNPNAEVLNKSAALHMNINAAKGLQDVLKTNLGPKGTIKMLVGGAGDIKLTKDGNTLLKEMQIQNPTAIMIARTAVAQDDIAGDGTTSTVLFIGELMKQSERHIDDGTHPRILVDSIEIAKRATLQFLEKFKTPVVVGDEPDKEILKMVARTTLRTKLYEALADQLTDIVVNAVLCIRKPEEAIDLFMVEIMHMRHKFDVDTRLVEGLVLDHGSRHPDMKRRAENCYILTCNVSLEYEKSEVNAGFFYSNAEQREAMVAAERRSVDERVQKIIDLKNKVCADNEHNFVVINQKGIDPPSLDLLARAGIIALRRAKRRNMERLVLACGGEAVNSVDGLTPDCLGWAGLVYEHILGEEKYTFIEKVKNPHSCTILIKGPNDHTIAQIKDAVRDGLRAVKNTIEDEAVVLGAGAFEVAARQYLVNEVMKTAQGRAKLGVEAFADALLVVPKTLAENSGLDTQDVIIALTGEHDKGNIVGLNHHTGEPIDPQMEGIFDNYSVKRQIINSGPVIASQLLLVDEVIRAGRNMRKPN', '49390.A0A068U3B4': 'MATAQLTASTISAKGFVSFEGLRASSTTVKASTFAPLRQNGLSTRSFRGLVVKAAAVVAPKYTSLKPLGDRVLVKIKVPEEKSVGGILLPTSAQTKPQGGEVVAVGEGRTIGKSKVDISVKTGTQIVYSKYAGTEVEFNGSNHLILKEDDIVGILDTDDVKDMKPLNDRVLIKVAEAEEKTAGGLLLTEATKERPSIGTVIAVGPGPLDEEGNRKALSVSPGNTVLYSKYAGNDFKGSDDSDYIALRASDVMAVLS', '49390.A0A068U3E9': 'MATKEGKAIGIDLGTTYSCVGVWLNDRVEIITNDQGNRTTPSYVAFTDTERLIGDAAKNQVAMNPHNTVFDAKRLIGRRYSDPSVQADMKLWPFRVVPGPGDKPLIVVTYKGEEKRFAPEEISSMVLTKMREIAESFLGHKVNNAVVTVPAYFNDSQRQATKDAGSIAGLNVMRIINEPTAAAIAYGLDKKHQKRGEQNVLVFDLGGGTFDVSLLTIEEGIFEVKATAGDTHLGGEDFDNRLVNHFVSEFRRKHKKDISGNARALRRLRTACERAKRTLSSTTQTTIEVDSLYEGIDFYATITRARFEELCMDLFLKCMEPVEKVLRDAKIDKSKVDEVVLVGGSTRIQKVQQLLQDFFNGKELCKSINPDEAVAYGAAVQAAILTGEGDSKVQDLLLLDVTPLSLGLETAGGVMTVLIPRNTTIPSKKEQIFSTYSDNQPGVLIQVYEGERARTKDNNLLGKFELSGIPPAPRGVPQINVAFDIDANGILNVTAEDKTAGVKNQITITNDKGRLSKEDIEKMVRDAEKYKSEDEEVKKKVEAKNALENYAYNMRNTVRDEKFDSKLKPDDKQKIEKAVEETIEWLDRNQLAEVDELEDKLKELENICNPIIAQMYQGGGGGGGPMGDDMHGGGGGGGGGSTDGTGAGPKIEEVD', '49390.A0A068U6M9': 'MAGSSHGNSCLLLLLLLAFLLLLCSSFFSTSLAEIIFEERFEDGWQSRWVKSDWKKSEGKAGSFKHTAGKWPGDPDDKGIQTSTDARHFAISAKIPEFSNKNRTLVLQYSIRLEQDIECGGGYIKLLSGFVNQKKFGGDTPYSVMFGPDLCGTQTKKLHVIYSYQGQNYPIKKDLQCETDKFTHFYTFILRPDATYSVLIDGRERDSGSLYTDWDILPPRKIKAVNAKKPADWDDREYIEDPNDVKPKGYDSIPREIPDPNAVKPDHWDEEEDGIWKPPKIPNPAYKGPWKRKKIKNPNYKGKWKIPWIDNPEFEDDPDLYVLKPIKYVGIEVWQVKAGSVYDNILICDDPEYAKEVVQEVLSNREVEKEAFEEAEKIRKAKEEEEAQRAREEGERRRRERGHDRRKDRYIDRYRRHDRHDYDDYHDEL', '49390.A0A068U6U9': 'MNAEVISSGHLQLFPTSSNTRHCGSQLPFSGRASTGSIALKPRRRPGPLRITARAAVYAPTQTQAETFYDMLGISETGSISDIKKAYKQLARKYHPDVSPADRTEEYTKRFIEVQEAYETLSDPQTRALYDMNLGRGLHFAFSTGRRNERMDDVEEWKLRWQSQLDELRLWSMHRDNVSSAVRGKAAASPSSSWGSRMRRKRTDIYDLGFR', '49390.A0A068U861': 'MEYSTFYPSTWNSNLTESLLYPYHFIPENYVHWTETPESHIYSADLPGVKKEQIRVEVEDSRYLIIRTEAATGESTVPAKNFIRKFRLPERVDISGISAGYENGVLTVEVPKSFVRRGFFIEPADMPERMHVLARAA', '49390.A0A068U8U4': 'MPGPVVEELDVDKKLQGDEPVVEDVKDEDDHEDDADDSDDEDDDKEDGAQGTNESSKQSRSEKKSRKAMLKLGMKPVTGVTRVTIKRTKNILFFISKPDVFKSPNSDTYVIFGEAKIEDLSSQLQTQAAQQFRMPDMGSVMAKSDISASGAAVQADEEEEEIDETGVEPRDIDLVMTQAGVTRCRAVKALKAHDGDIVSAIMELTT', '49390.A0A068U8Z8': 'MAGAWARRASLIVFGILFFGSFFAFSIAKEEAAKLGTVIGIDLGTTYSCVGVYKNGHVEIIANDQGNRITPSWVGFTDGERLIGEAAKNQAAVNPERTIFDVKRLIGRKFEDKEVQKDMKLVPYKIVNKDGKPYIEVKIKDGEKKVFSPEEISAMVLTKMKETAEAYLGKPIKDAVVTVPAYFNDAQRQATKDAGIIAGLNVARIINEPTAAAIAYGLDKKGGEKNILVFDLGGGTFDVSILTIDNGVFEVLATNGDTHLGGEDFDQRVMEYFIKLIKKKHGKDISKDNRALGKLRRESERAKRALSSQHQVRVEIESLFDGVDFSEPLTRARFEELNNDLFRKTMGPVKKAMEDAGLEKHQIDEIVLVGGSTRIPKVQQLLKDYFDGKEPNKGVNPDEAVAYGAAVQGGILSGEGGDETKDILLLDVAPLTMGIETVGGVMTKLIPRNTVIPTKKSQVFTTYQDQQTTVTIQVFEGERSLTKDCRLLGKFDLTGIPPAPRGTPQIEVTFEVDANGILNVKAEDKASGKSEKITITNDKGRLSQEEIERMVREAEEFAEEDRKVKEKIDARNSLETYVYNMRNQINDKDKLADKLESDEKEKIETATKEALDWLDDNQNAEKEDYEEKLKEVEAVCNPIVTAVYQRSGGAPGAGSEEEDESHDEL', '49390.A0A068U922': 'MAAALRSKSSREAASLAGSQFRYFILSYMHEGRVSSYQWNSRSKWDNNFFRNPRCNFNFVLAPFKPFSLRGDFVDKVNSNEKNHLNSSKVINNENKVEISSSYGDPPEVWQPPGGIVVRPGAKFVQAGEGEGPGTVSGGGSGSGSKDGCWGGSNLGPNFPTPKEICKGLDKFVIGQDRAKKVLSVAVYNHYKRIYNDSSEKWPAGDSGSNKVDTADIESVELEKSNILLMGPTGSGKTLLAKTLARLVNVPFVIADATTLTQASLIIRCRCEAVKFLVLFSHIRTLHTRVTCCAFGFSSFCH', '49390.A0A068U931': 'MAILSDYEEEDQQKPISSSSSVKPFNAVLDPSNPLGFLEAALEFLAKESDLFKSDSLVKDVNAVVRQVKDKVEAEERKRKEKAAPVNGNAEKKIKEDMPQAVVKEEVKDVEVESKMISEAKEDAKDDDKGPRAPNKGNGLDLDNYSWTQTLQEVNVNIPVPPGTKSRFIACEIKKNHLKFGLKGQPPIIDGELYQPIRVDDSIWSLEDQRFVSICLSKQNQMEWWKCLVKGSPEVDTQKVEPENSKLSDLDPETRSTVEKMMFDQRQKSMGLPTSDEMQKQEILKKFMAEHPEMDFSRAKIS', '49390.A0A068U979': 'MQLLQAGYVGEDVESILYKLLTVADYNVAAAQQGIVYIDEVDKITKKAESLNISRDVSGEGVQQALLKMLEGTIVNVPEKGARKHPRGDNIQIDTKDILFICGGAFVDLDKTISERRQDSSIGFGAPVRANMRTGGVTTAAVTSSLLETVESSDLIAYGLIPEFVGRFPILVSLSALTENQLVQVLTEPRNALGKQYKKMFQMNGVKLHFTEVALRLIARKAITKNTGARGLRSLLESILMDSMYEIPDVRTGNEIIDAVVVNGESVGHEGRGSGAKILYGKGALDRYISQLKFKDRETTAEGSDGEPEVEQELPSIAAL', '49390.A0A068U9F8': 'MADVQMGEAETFAFQAEINQLLSLIINTFYSNKEIFLRELISNASDALDKIRFESLTDKSKLDAQPELFIRLVPDKVNKTLSIIDSGVGMTKADLVNNLGTIARSGTKEFMEALQAGADVSMIGQFGVGFYSAYLVAEKVIVTTKHNDDEQYIWESQAGGSFTVTRDTSGEQLGRGTKITLFLKDDQLEYLEERRIKDLVKKHSEFISYPIYLWTEKTIEKEISDDEEDEPKKEEEGDVEDVDEDKEETKDKKKKKIKEVSHEWQLINKQKPIWLRKPEEITKDEYASFYKSLTNDWEDHLAVKHFSVEGQLEFKAILFVPKRAPFDLFDSRKKPNNIKLYVRRVFIMDNCEELIPEYLSFVKGVVDSDDLPLNISREMLQQNKILKVIRKNLVKKCIEMFNEIAENKEDYNKFYEAFSKNLKLGIHEDSQNRAKLADLLRYYSTKSGDELTSLKDYVTRMKEGQKDIYYITGESKKAVENSPFLERLKKKGYEVLFMVDTIDEYAVGQLKEYDGKKLVSATKEGLKLDDDSEEENKKKEEKKKSFEDLCKVIKDILGDKVEKVVVSDRIVDSPCCLVTGEYGWTANMERIMKAQALRDTSMSSYMSSKKTMEINPDNGIMEELRKRAEADKNDKSVKDLVLLLFETALLTSGFSLDDPNTFAARIHRMLKLGLSIEESDDAGDDADMPALEEDGDEESKMEEVD', '49390.A0A068U9H0': 'MATMLQPQIILLKEGTDTSQGKPQLLSNINACTAVADVVRSTLGPRGMDKLIHDEKGNTTISNDGATIMKLLDIIHPAAKILVDIAKSQDSEVGDGTTTVVLLAAEFLKEAKPFIEDGVHPQNLIRSYRTAGHLAIEKVKELAVSIEGKSLEEKKSLLANCAATSLSSKLIGGEKDFFASMVVDAVLAIGNDDRLNMIGIKKVPGGNMRDSFLVNGVAFKKTFSYAGFEQQPKKFVNPKILLLNIELELKSEKENAEIRLSDPSQYQSIVDAEWNIIYDKLDKCVKSGAKIILSRLAIGDLATQYFADRDVFCAGRVTEEDLHRVAAATGGTIQTTVNNVIDEVLGSCEIFEEKQVGNERFNIFSGCPSGQTATIVLRGGADQFIEEAERSLHDAIMIVRRAVKNSTVVAGGGAIDMEISRYLRQHARTIAGKSQLFINSYAKALEIIPRQLCDNAGFDATDVLNKLRQKHALPSGEGALYGVDINTGGIADSFANFVWEPSVVKINAINAATEAACLILSVDETVKNPKSESAQGDAAASAMGRGRGGAAFRGRGRGMRRR', '49390.A0A068UA30': 'MAASLALKRLVSSTLLSRSVNSLRPAASAASSRLFNTNVARDYDDDDDERGLDVDRRSNCPLYNRRDYSPYFGVFDPFSTRSVSQLLDLVNQFSEPTFASGVRRGWDIKETAEGLNLSLDMPGLGKEDVKVSVEQNTLIIKGEGQKESEDAERGRRFSSRLDLPEKTYKTDGIKAEMKNGVLKVFIPRVKEEERSDVFHVNVQ', '49390.A0A068UBQ0': 'MEGGKPTIVTNAEGQRTMPFVVAYTKNGDRLVGQITKRQAHYNKNNL', '49390.A0A068UCA8': 'MAEKLAPEKRHSFTHNGQKVFEWDQTLEEVNIYIPLPANVPKKLFYSKIESKHLEVGIKGNPPYLNHDLTNPVKTDCSFWTLEDDTMHITLQKRDIGQTWPSPIMGQGQLDPYATDMEQKRLMLQRFQEENPGFDFSQAQFSGSCPDPRTFMGGIRSS', '49390.A0A068UDA4': 'MALIPKLFGDMLAPSGLSDETKGIVNARVDWKETPEAHVFKVDLPGLKKEEVKVEVEDGRVLAISGERAAEKEDKNDKWHRVERSRGRFTRKFLLPENAKVEEVKANMEYGVLTVTIPKQEVKKPEVRAIEISG', '49390.A0A068UDH3': 'MSLMPVFGGRRSVYNNPFSGDGWDAPVNNHQPVHQKQYHGESGVTAWAPPVHGASSHHAVQAPSSFASATVDWRETPEAYIFKTELPPGVRREDVRVELEDNKILKISCEKYTEKEDRHDQNYYHHVIERSRCKFLTAFGLPQDSRVDQIRSTIENGVLTVRVPRWEPMHHSHHHVIPVEIL', '49390.A0A068UED5': 'MEGGKPTIVTNPEGQRTMPSVVAYTKNGDRLVGQIAKRQVVVNLENKFFSVKRFVGRKMSEMDEESKQVSYKAVRDENNN', '49390.A0A068UEW5': 'MQQAGSSGSETEVTWEDQQKINQFSRLNNRFHELEDEIKLAKETNDNLEDASNELILTDDDIVRFQIGEVFAHIAKDGVETRIEQMKEVTSKNLEKLEEEKESIVAQMDELKKILYGKFKDSINLEED', '49390.A0A068UF36': 'MAKRLIPLLNRVLVEKVIPPAKTNAGILLPEKTAKLNMGKVVAVGPGYHDSQGKLIPVTVKEGDNVLLPEYGGTQVKLGEKEYHLYRDDDILGTLHD', '49390.A0A068UFS1': 'MGVDYYKILQVDRNAKEDDLKRAYRKLAMKWHPDKNPNNKKDAEAKFKQISEAYDVLSDPQKRAVYDQYGEEGLKGQVPPPSAYASTSDGGGPTMFRFNPRNPDDIFSEFFGFSSPFGGMGGMGDMGGPRSAGSSFSRGMFSDDIFASFRSATTEGSSGSVPRKAAAIERTLPCSLEDLYKGTTKKMKISRDVNDANGRPTTMEEILSIEIRPGWKKGTKITFPEKGNEQRGFIPSDLVFIVDEKPHIVFKRDGNDLVITQKISLVEALTGYTAQMTTLDGRSLAIPINSIISPTYEEVIKGEGMPIPKEPSKKGNLRIKFNIKFPTKLTSEQKTGIKRLLTSPGAST', '49390.A0A068UFX3': 'MEEPLLSSDKNGARDGGRESDKLRSYEYVGRAGSIIPTAFLAGSQVSVDEIRSAASIPHSDPYPPSLHGALVSPPPPQSPSQPYAQDIIYQGGCYGDTREIDHEARRQEQILDEVEIRELLVDHVGHRCCWGSRPARTWKIHAVEDCNVYVGTLDTFIEEREIIIEREPYVSGNIDGTANGPELGVWELDLRSEFPVLFIPYQETRTRIPHSEAIDKCPDCTGRGHTVCTACNKDLEPGFYKENQMMHCPACFGRGLIAHRDGSDTKCLKCNGKGMLPCATCDSRGLIKCVTCMGGGSLLTRKVAVIRWKTLSTRKVSATSGAASVPDDVFHRAQGIQLCNTQAHQCTPAFFADSFFLNKFSSEVIAERAPVPHAARVICERHIISVVPVTRVTMAHHNRSFSFYIIGNGREVYLKDYPARLCWGLCPCFEWLKS', '49390.A0A068UG80': 'MRGISVRLVFLVILLVLVVVSSLVVVVASGPPSSSRSSDLDDDSDIPASHLPLPLTSKHDTAVVAAPDGTIYLVEINSGKVLWSFASGFPIYSSYQAVHHNEGQRNNATTGADDFFIDIGEDWQLYVNGNGLKNVKLPVSVEEFLKSTPFISASGGIMLGSKKSTIFIVDAKTGKVIHTLCSDTVRAVEHEHSDESTLVARTDFGGWVPHSATNLDGIEEPLYVTRKDYVLKFTNMKTGKILWYLMFADIEASYQCNAIESFLGSVFYTEDEVSLRKNLDAKLQLHCPPKPVVYRIRDRSSFKSLFKTNSLPDAFAGDKVLLLAAPDLDPMLQLVEKILGLHQSNGGDIGLALPTPESEDFGVVALPEGDIDQIHEIGGFANLIGSHFWFVALFGGLMLLIVTFFFIHLVVKEQGKLNKGVEMPNIQALTTRKKKPRKPRTNSKTAERKKKNVSHDQMAKDINVLPDYERAKKFLQLGLPNNSDGFMDGRNIGRLFVSTTEIAMGSNGTVVLEGIYDGRPVAVKRLVQTHHNVAFKEIQNLIASDHHPNIVRWFGVEFDQDFVYLALERCACSLYDLILPCSSSQNQETYQDGDFNCAGNEFVRLGLLGDNHALQLSKLNGYPSHHLLKLMRDVVRGLAHLHELGIIHRDLKPQNVLVTKERVLCAKLSDMGISKRLSGDTSSLTKHATGYGSSGWQAPEQLRHERQTRAVDLFSLGCLLFFCITGGKHPFGEILERDVNIVNNQKDLFLIENLPEATDLIASLLHCNPELRPKATQVACHPLFWDSEMRLSFLRDASDRVELEDREKESELLKALESIGNVALGGKWDEKMDTAFINDIGRYRRYKFDSVRDLLRVIRNKLNHYRELPKDIQGILGQVPEGFDNYFSTRFPKLVIEVFKVFHLYCAEEEEAFIKYFKCDYM', '49390.A0A068UGP7': 'MRKWTVPAVLFLLCLLFLLPDQGRKIHANAEVDADAPVDPPKVEEKIGAVPNGLSTDSDVVKREAESMSRRTLRATAEKFEFQAEVSRLMDIIINSLYSNKDIFLRELISNASDALDKIRFLSLTDKEILGEGDTAKLEIQIKLDKEKKILSIRDRGIGMTKEDLVKNLGTIAKSGTSAFVEKMQTSGDLNLIGQFGVGFYSVYLVADYVEVISKHNDDKQYVWESNADGAFAISEDVWNEPLGRGTEIRLHFRDEAQEYLNESKLKELVKKYSEFINFPIYLWASKEVDVEVPADEEDSSDEDEKPESSSSEEEEEDTEKEEDEKKPKTKKAKETTYEWELLNDVKAIWLRNPKEVTDEEYTKFYHSLAKDFSEEKPLAWSHFTAEGDVEFKAVLFVPPKAPHDLYESYYNTNKSNLKLYVRRVFISDEFDELLPKYLSFLKGLVDSDTLPLNVSREMLQQHSSLRTIKKKLIRKALDMIRKIAEEDPDEANDKEKKDVDESNESDEKKGQYTKFWNEFGKSIKLGIIEDAANRNRLAKLLRFETTKSDGKLTSLDQYISRMKPGQKDIFYITGTSKEQLEKSPFLERLTKKNYEVIFFTDPVDEYLMQYLMDYEDKKFQNVSKEGLKIGKDSKDKELKESFKDLTKWWKGTLASENVDDVKISNRLANTPCVVVTSKYGWSANMERIMQSQTLSDSSKQAYMRGKRVLEINPRHPIIKELRERVVKDPEGESVKQTAHLMYQTALMESGFMLNDPKDFASRIYDSVKSSLHISPDAAIEEEEDAEEAEVESSTKEGSGEDAEEAEPSSVKDEL', '49390.A0A068UHQ8': 'MVRSNGLRLVRRFALRSLASHLLHGSSSSLNEALLRGGYRSFSTAFCNQNRVFRFSNSRNVNDGRERLRLGSLVANLGAARSIHATATTSGDYYDVLGVSRNATPSEIKKAYYGLAKNLHPDTNKSDPGAAAKFQEVQEAYEVLKDEKKRAEYDEVGHDAFKINRQNGGAGYDPFQEGGFNPFQEFFHGFDFMRKNMGGEDVKVSIELSFMEAVQGCSKTISFQTEIPCNTCGGAGVPPGTRPETCPLCRGSGTAKFHGGNVFFQMNCRKCGGSGKIVSDVCKSCKGERVVKGTKTVKLDIKPGVDNDQTMKVYGSGGADPEGNQSGDLYVTIKVREDPVFRREGADIHVDAVLSITQAILGGTIQVPTLTGDVVLKVRPGTQPGQKVVLKRKGIKTSNSFSFGDQFVHFNVSIPANLTQRQRRLIEEFAKEEQGEYDKGAAAGASG', '49390.A0A068UHU0': 'MEASLQISKISTLSGKMVQFNPKGSSKEKFLQHRTMFRCQADRTLQNGRAANFYEVLSLDCSKSVGFNEIRKAYRCKALKLHPDACPPTEKEESTRRFLELRMAYKTLSDPISRELYDLELSLVKVDGRTRHGMSRSMGNKVWERQIAELNKRSMQKMEKRKKMGI', '49390.A0A068UI14': 'MEASLQSSGISTRFGKTVQFNQKGSGKEKFLQHRTVISCQAARTVQTGRAANFYEVLSLDCSKFVGLQEIKKAYRCKALKFHPDACPPSEKEESTRRFLELRMAYETLSDPISRELYDHELSLVDVDGRTRHGMSCSMGSQVWERQIAELNKRSRQKMEKRKEMGMWN', '49390.A0A068UIC6': 'MASSIGSTFAGAAPSCARFKHHLHQPSRISAAHAAAGRTSTSTSHIAPQTSLYEVLGIPMGATCQEIKVAYRRLARVLHPDVASSHNTTRGSQDTSAAADEFMRVHKAYTTLSDPEKRADYDRTLFRLRRPAYVLSATNRGSGYYARRTWETDQCW', '49390.A0A068UIK8': 'MEASLQISRISTRFGKTVQFNQKGSCKEKFLQHRTVISCQAARTVQTGRAANFYEVLSLDCSKFVGLQEIKKAYRCKALKFHPDSCPPSEKEESTRRFLELRMAYETLSDPISRELYDHELSLVDVDGRTRRGMSCSMGSKVWERQIAELNKRSRQKMEKRKEMGMWN', '49390.A0A068UIR8': 'MEASLQISGISTRFGKTVQFNQKGSCKEKFLQHRTVISCQAARTVQTGKAANFYEVLSLDCSKFVGLDEIKKAYRCKALKFHPDACPPSEKEESTRRFLELRMAYETLSDPISRELYDHELSLVDVDGRTRRGMSCFMGNKVWERQIAELNKRSRQKMEKRKEMGMWN', '49390.A0A068UJ52': 'MDLRNLGMDIGGMGFGIDNPILSTIQDMLELSEEHDKGNQNNPSRAYVRDAKAMARTPADIKEYPDSYALVVDMPGIKANEIKVQVEDDNVLVVSGERKREKEEGVKYLKMERRGGKSMRKFVLPENANLDAISAVSRDGVLTVAVQKFPPPQAKKHKTIEVKAG', '49390.A0A068UJS0': 'MAAAPTASASTAYLCSYASPHRPSLPSSSSNYFQTHFPLKPISSRGFCFCLPKNANIPVINNNSSRRCRFLKASQSQSEDSASETDDEDETPLSKTEEEADQELPSRLESTISAYKEAILNGDEKSISDFEEIIHMVEKERNELLEKVSVLSDEIGAQKDKYVRLQADFDNFRKRTENEKLTIRSNAQGEVIESLLPMVDNFERAKQHMKLETEQEKKIDASYQGIYKQFVEIMKNLGVSVVPTVGTLFDPVLHEAIAQEESEEFKEGVIIEEFRRGFLLVDRLLRPAMVKVSSGPGVRQPSSAASEQSEQPATAGVEEIEFSEQSTG', '49390.A0A068UK32': 'MASSTALREQFLSPPVPFLSNPNLLLHIAKNHQVRKKYTIQLGENELVLKELELLNEDANVFKLIGPVLVKQDLAEARANVRKRIDYISAELKRLDATLQDLEDKQKSKQETVFKLQQKVQSFQAGKGKA', '49390.A0A068UKG2': 'MAGKGDGPAIGIDLGTTYSCVGVWQHDRVEIIANDQGNRTTPSYVAFTDSERLIGDAAKNQVAMNPTNTVFDAKRLIGRRLSDSSVQNDIKLWPFKVIAGPGDKPMIAVNYKGEEKQFAAEEISSMVLIKMKEVAEAYLGTTIKNAVVTVPAYFNDSQRQATKDAGVIAGLNVMRIINEPTAAAIAYGLDKKATSAGEKNVLIFDLGGGTFDVSLLTIEEGIFEVKATAGDTHLGGEDFDNRMVNHFVQEFKRKNKKDISGSPRALRRLRTACERAKRTLSSTAQTTIEIDSLYEGIDFYTTITRARFEELNMDLFRKCMEPVEKCLRDAKMDKSSVHDAVLVGGSTRIPKVQQLLQDFFNGKELCKSINPDEAVAYGAAVQAAILSGEGNEKVQDLLLLDVTPLSLGLETAGGVMTVLIPRNTTIPTKKEQVFSTYSDNQPGVLIQVYEGERTRTKDNNLLGKFELSGIPPAPRGVPQITVCFDMDANGILNISAEDKTTGQKNKITITNDKGRLSKEEIERMVQEAEKYKSEDEEHQKKVDTKNALENYAYNMRNTIRDEKISAKLEPTDKKKIEDAVEEAIKWLDSNQLAEADEFEDKMKELESLCNPIIAKMYQGGADGGMGGAMDEDGPSVGGGSGAGPKIEEVD', '49390.A0A068UKG5': 'MAGKGEGPAIGIDLGTTYSCVGVWQHDRVEIIANDQGNRTTPSYVAFTDTERLIGDAAKNQVAMNPTNTVFDAKRLIGRRFSDASVQSDIKLWPFKVIPGPGDKPMIIVNYKGEEKQFAAEEVSSMVLTKMKEIAEAYLGSTVKNAVVTVPAYFNDSQRQATKDAGVISGLNVMRIINEPTAAAIAYGLDKKATSAGEKNVLIFDLGGGTFDVSLLTIEEGIFEVKATAGDTHLGGEDFDNRMVNHFVQEFKRKNKKDISGNPRALRRLRTACERAKRTLSSTAQTTIEIDSLFEGIDFYSTITRARFEELNMDLFRKCMEPVEKCLRDAKMDKSTVHDVVLVGGSTRIPKVQQLLQDFFNGKELCKSINPDEAVAYGAAVQAAILSGEGNEKVQDLLLLDVTPLSLGLETAGGVMTVLIPRNTTIPTKKEQVFSTYSDNQPGVLIQVYEGERTRTRDNNLLGKFELSGIPPAPRGVPQITVCFDIDANGILNVSAEDKTTGQKNKITITNDKGRLSKDEIEKMVQEAEKYKAEDEEHKKKVEAKNALENYAYNMRNTVKDEKIGSKLSPADKKKIEDAIDQAISWLDSNQLAEADEFEDKMKELESICNPIIAKMYQGAGGDMGGGAMDDDAPSGGSSGAGPKIEEVD', '49390.A0A068UKH3': 'MEASLQISKISTLSGKMVQFNQKGSCKEKFLQHRTMIRCQADRTMQNGRAANFYEVLSLDCSKSVGLDEIKKAYRCKALKFHPDACPPTEKEESTR', '49390.A0A068UKL9': 'MRPWIVLTRACKDLHIFLARALLKLSPPNPDDLGYVDSISVDEIGGVKVTIVRNEEGGNSVSTVVLRGSSILDDLDRAVDDGVNAYKAMCRDSQIVPDAAAAEIELARRLKEFSFKETGLDQYAISRFAESFEMVPKTLAKKAGLNAMEIIASLYAEPASGNTGVDIGLEEGVCKDVSTTSVWDPYTIKFFSLKYATNAVCTVLRVDRIIIAKPAGGLKRDPPVEMDGWMDG', '49390.A0A068UKM4': 'MDLDPSTIYAINEVAIFAGAVDTTATETKGTALIHRAQQLENYAKIGAAKVGELIKAIAGSGAKVIVSGAAVGKMALHFCERYKLMVLMISSKFELQRFCHITGAVALLKLSSPNPDDLEYVDSISVDEIGGVKVTIVRNEEGGNSVSTVVLRGSSILDDLERAVDDGVNTYKAICRDSQIVPGAAATEIELARRLKEFSFKETGLDQYAISRFAESFEMVPKTLAKKAGLNAMEIIASLYAEPASGNTGVDIGLEEGVCKDVSTTSGFDSIDRFFALKYAADAVCTVMRVDRIIIAKPAGGLKRDPPMEMDGWMDG', '49390.A0A068UKV4': 'MHGFAPSLTPFRNFLAVKPLLFSEAQSKFLVPDCSKFIVIKQPGFSHTLSCRNYYCYGERRNKRCASVRASRRESPYEVLGVSPSATPNDIKRAYRKLALKYHPDVNKEANAQERFMRIKHAYNTLLNKSDRRFDKGNRGSESSYSTAGRNDNWTVNNDEEFYGFGNFLRDVQISIEDFFKDLQEEFRNWEAGADSQGKPKSLWEELAEIGEEFVEFLEKELNISDVEAEQTKGNQQQWGNASYGSKETGNVNQNGADNSGIEENINDIEAALAQLKKELGL', '49390.A0A068UKZ1': 'MSLIPSFFGNRRSSIFDPFPSDVWDPFRDISLPSSFVGETSSFVNARVDWKETPEAHVFKADLPGIKKEEVKVEVEDDRVLQIRGERNVEKEDKNDTWHRVERSSGQFMRRFRLPENAKMDQIKAAMENGVLTITIPKEEAKKTDVRAIQISG', '49390.A0A068UL97': 'MSEIQEILMIRSHEIAIAELNSLSSSRGVYQRNGNILFRTTIQKAIALEQKQLDVAKVKVQQLSD', '49390.A0A068ULW4': 'MFGRAPRRSNNSKYYEVLGVSKSASQDELKKAYRKAAIKNHPDKGGDPEKFKELAQAYEVLSDPEKRELYDQYGEDALKEGMGGGGVHDPFDIFESFFSPLHRRDGFRGRKKQGEDVVHTLKVSLDDLYKGTSKKLSLSRNKLCPKCKGKGSKSGASGRCYGCQGSGMRVTTRQIAPGMIQQMQHMCPECKGSGEVISERDRCTQCKGNKVVQEKKVLEVHVEKGMKHGQKIVYPGEADEAPDTVTGDIVFVLQQKEHPKFKRKFDDLYVEQSLSLTEALCGFQFVLTHLDGRQLLVKSNPGEVVKPDQYKAINDEGMPHYQRPFMKGRLFIHFNVEFPESGALPSEKCQVLKAMLPSGSLKQSSDMDLDECEETTLHDVNIEEEMRQKQHQRHQEAYDEDDDDEPTMHRMPCNQQ', '49390.A0A068UM55': 'MASTLVTLAAKPFTSQNTNLQFLPTQRPRVLPRNNSLRVSAIAKKFEPTKVVPQADRVLIRLEELPQKSAGGVLLPKSAVKFERYLMGEVISVGTEAGEVNSGKKVLFSDINAYEVDLGTEARHCFCKAGDLLAVVE', '49390.A0A068UMK5': 'MAIAAQTPDILGERQSGQDVRTQNVMACQAVANIVKSSLGPVGLDKMLVDDIGDVTITNDGATILKMLEVEHPAAKVLVELAELQDREVGDGTTSVVIIAAELLKRANDLVRNKIHPTSIISGYRLAMREACKYVDEKLAVKVEKLGKDSLINCAKTSMSSKLIGSDSDFFANLVVEAVQAVKMTNARGEVKYPIKGINILKAHGKSARDSYLLKGYALNTGRAAQGMPMRVAPARIACLDFNLQKTKMQMGVQVLVTDPRELEKIRQSEADMTKERIEKLLKAGANVVLTAKGIDDMALKVSSCIVVFLSQL', '49390.A0A068UN30': 'MHVDDEAAKLRFDFPGVGKEGLKIWFENGNLKIEGTEDATDVDGVPKEGRKYAVTYEIFEPGLLKKDEAKAEMKNGVLKVVIPMVKFEERKEVVHINVA', '49390.A0A068UN39': 'MSLIPSFFGGRKTNVFDPFSLDIWDPFDGFFVTSPSVANWPSSARETAAVATARIDWKETPEAHVFKADVPGLKKEELKVEVEEGRILQISGERSKEQEEKNDKWHRSERRSGKFLRRFRLPENAKVEEVKASLEDGVLTVTVPKVEEKKPEVKSIEISA', '49390.A0A068UNW6': 'MASSLAFRRAANVSSPLLMKLMDVGSLRTLAAAPSMARSFTTNAQMTTYGEGDRSVDVERRPESGVFRRRDSFPSFFSDVFDPFSPTRSVNQLLNLMDRFMEDPFLAARELGPAAVSRRGWDVREDEKALYIKMDMPGLDKENVKVTVEQNTLVIKGEGVKESEEEEHGRRYSSRLDLPPNLYKIEEVKAEMKNGVLKVIVPKVEEEERKDAFQVKVD', '49390.A0A068UPA4': 'MTAQSQEELLAAHLEQQNIDPEEPVIEDDDEEDDEDDDDDKDEDDVEGQGDGSGRSKQSRSEKKSRKAVLKLGMKAIPGVSRVTVKKSKNILFVISKPDVFKSPTSDTYVLFGEAKIEDLSSQLQTQAAEQFKAPNISNVISKPEPSTVAQDDEDVDETGVEPKDIELVMTQAGVSRAKAVKALKAADGDIVTAIMELTN', '49390.A0A068UPY3': 'MGLLSNRIDRGSLKPGDHIYSWRTAYIYAHHGIYVGDDKVIHFTRRGQEVGTGTILDFVLVSSGPSRGHVPCTTCTLTEEGHGVVSTCLNCFLAGGVLYRFEYAVNPALFLAKARGGTCTLAVSDPDDIVVHRASYLLNNGFRCYNVFKSNCEDFAIYCKTGLLVLDHSTMGQSGQAVSIIGGPLAAVLSTPLRLVTTNVYGMAATAVGVYCASRYATDIGMRSDVVKMPVEDLTQRLETGLLGVAIPSLPALPPTPVS', '49390.A0A068UQI7': 'MEAKTGSTARLSYEEFEPFCRWQREEACDTLLVHLPDFKKEQLRVHINNRGILKISGERKLSSTKGSKFYKEVVVARNCNTNAIQAKFSAGQLCIKMTKNVNAAAVPEQKGSTLDPTAKPQAGPEEGQATQPPQKPGEEKYSIIVPSGTPIATASGKSNGTVTEGEETTVSRGKQLANIALNVGMPVALLAALVAFVLYMYKSTIVED', '49390.A0A068UQR1': 'MAFLMAMRRTAASPASSTLFTRFLNGTVLKPSAAGVAPVTTSSITSSIPIILGDEPRVTLNALGGSYPRSEQFPIDRGGYSDEYINPFQTSGSRGAYEINHVDEGLYVRMEMPGIGKEDVKVWNEYGTVYVKGIGNNKQSRFEKLRRAYSATIEIPSDTFHAGKIEVDVKNGVLRMLIPNKESTNLGQV', '49390.A0A068UQV1': 'MNGMHDCRYNEEGSPRGIPKRGSYEKAYFTRSPLSSPPASRNTSPSPLSRSTSKRSLTPIRSAAANLLRSMSRRKSAEATTLPSTLSRSVSRKASITIMYSNSNGLMKPPAMEMTLECTLEELCFGCIKKMKITRDSVTDDGYTLQLIQEDEVLTIKVKPGWRKGTKITFEGMGNEMPGADPADVIFTVLEKRHHMYRREGDDLELAVEIPLVKALTGCIFAIPLLGGEKMILTIDDIIYPGYQKIIPGHGMPKPHEQGERGNLIITMLVKFPTELTDEQRSEIVSILRDSC', '49390.A0A068URJ1': 'MSPIPSVFGGRKTNVFDTFSLVMWDPFGGFFTSSILINLPTSAGETTAFANARIDWKETPQAHVFKADVPGLKKGEVKVEVLEEGRILQIRGERSKEQEEKNDKWHHLERSSRKFLRRFRLPENA', '49390.A0A068USH9': 'MAKGLHLAFSSRRRYQNYDDQMEEKGEWKSRWQDQVSELKRRSMYKDAGSMSWGARMRRQKK', '49390.A0A068UT14': 'MGRWKPLGSSAHSILKNFWFRSSNFLECSAGKRPLQVAFPALDHCRYLCSCRILLYPADFVPKGLLLSKRFIHATGPSNSTERDYYEILGVSRNATKEEIKKAFHALAKKYHPDANKKNPSAKRKFQEIRDAYEILQDPEKRAQYDRISEYGRTGEDMNYSSGDADGFRFTYGTQFSDSFYDVFAEIFKDQAKFHTKDIQVELSLSFSEAAKGCTKHLSFDADVPCDACNGHGYPPNAKRKICHNCQGSGMQTFLRFTETCSMCKGSGVIFKEFCRACQGSGAVEGVKHVKVSIPAGVDTGDTIHVENAGNAGRHGLEPGSLFIKLKVTEDPLFARDGADIYVDSNISFTQAILGGNVEVPTLSGKTKVQIPKGVQPGQLLRLRGKGLPKSGFFVDHGDQYVRFRVNFPVVLNERQRAILEEFANEEISSEHNTSGEGSWLYQQLSTG', '49390.A0A068UTG2': 'MAPLQGSFLEIGRVKTSNGGATRIASDKRSMTEEEWGKRLRASFWGTFKSYGSEPPENLPPPPPANRNGGDGIAVHTPPGPPFAPGVNVVRAASTPNIKGGDTSNNGEKSGWGGSNLGKSLPTPKEICMGLDKFVIGQDHAKKVLSVAVYNHYKRIYHASLNKGSGAEIAPDDDDENVELEKSNVLLMGPTGSGKTLLAKTLARFVNVPFVIADATTLTQASNSWVNLF', '49390.A0A068UTZ3': 'MAGKSAPAIGIDLGTTYSCVAVWEHDRVEIIANDQGNRTTPSYVAFTDTERFVGDAAKNQAAINPVNTIFDSKRLIGRKYTDPSVEYDLKLWPFKEKQFAPEEISAMILTKMKEVAEAYLGLPVKNAVITVPAYFNDSQRQATRDAGAISGLNVLRIIVEPTAAAIAYGLDKELLINTGGQKNVLIFDLGGGTFDVSLLTIEKSMVDVKAVGGDTHLGGEDFDNRMVNHFVQAALRRLRSACERAKRILSSIHQTSIEIDALFEGIDFQSTITRPRFEELNMDLFRQCMEPVESCLRDAKMDKHSVQDIVLVGGSTRIPKVQQLLQDFFNGKTLCKSINPDEAVAYGAAVQAAILDGRGNQKALDIAIMDVTPLSLGFECKGKVMTVVIPRNTTIPTKKETTCTTAYDNLTHVLFLVYEGERARSTENNLLGRFTLGGIPPAPRAVPVINVCFDLDANGILNVSAEDKNTGQKSRITISFDKGRLSREEIEKMVQAAEKYKFEDEEHKKKSKNISSSLASADMKKIEDAIEDAMQWLDGNQLGETDEYEDKMKELESITERLMITKKD', '49390.A0A068UU87': 'MAIISDINADDDQPQQQQTSPVDQPQQHHQTPPVNQPEPEEEKKGENQEPPKPERLAPNKSNGLDMENYTWGQSLQEVTITVPVPPGTKSRFVVCDVKKDRIKVGLKNSPPILDGEFFGLVKAQDSIWSLEDNDISILLTKQDKTNWWKSLLKGGPEIDTQKVQPEPSKLSDLDMETRSAVEKMMFDQRQKQLGLPTSEEIQNQELMKKFKEQFPNMDFSGSKILGGRQK', '49390.A0A068UUJ1': 'MHAPVLVLKDTLKRESGNKVHYANIQASKAVADIIRTTLGPRSMLKMLLDAAGGIVVTNDGNAILRELDLAHPAAKSMIELSRTQDEEVGDGTTSVIVLAGEMLHVAEAFIDNHYHPTVICRAYNKALEDAIAVLEKIAMTVDVKDRATMLGLVKSCIGTKFTSQFGNLIADLAIDATTTVGVEVGQGIREVDIKKYVKVEKVPGGQLEDSQVLKGVMFNKDVVAPGKMRRKIVNPRIILLDCPLEYKKGENQTNAELLREEDWSVLLKMEEEYIENLCMQILKFKPDLVITEKGLSDLACHYLSKAGVSAIRRLRKTDNNRIAKACGAVIVNRPDELQESDVGTGAGLFEVRKIGDEFFAFIVDCKDPKACTVLLRGASKDLLNEVERNLQDAMSVARNIVKNPKLVPGGGATELTVSAILKQKSSSVEGIEKWPYEAAAIAFEAIPRTLAQNCGVNVIRTMTSLRGTHANGENAWIGIDGNTGAIADMKERKIWDSYTVKVQAFKTAIEAACMLLRIDDIVSGIKKKQAPGAGASSKPKVEEEGEAENEALIPE', '49390.A0A068UUL8': 'MAVSWRRSGSFIALAIVFFGCLSAISIAKEEATKLGTVIGIDLGTTYSCVGVYKNGHVEIIANDQGNRITPSWVAFTDSERLIGEAAKNQAAVNAERTIFDVKRLIGRKFEDKEVQRDMKLVPYKIVNKDGKPYIQVKIKDGEVKVFSPEEISAMVLTKMKETAEAFLGKKIKDAVVTVPAYFNDAQRQATKDAGIIAGLNVARIINEPTAAAIAYGLDKKGGEKNILVFDLGGGTFDVSVLTIDNGVFEVLATNGDTHLGGEDFDQRIMEYFIKLIKKKHGKDISKDNRALGKLRREAERAKRALSSQHQVRVEIESLFDGIDFSEPLTRARFEELNNDLFRKTMGPVKKAMEDAGLEKHQIDEIVLVGGSTRIPKVQQLLKDYFDGKEPNKGVNPDEAVAYGAAVQGGILSGEGGDETKDILLLDVAPLTLGIETVGGVMTKLIPRNTVIPTKKSQVFTTYQDQQTTVSIQVFEGERSLTKDCRLLGKFDLTGIPPAPRGTPQIEVTFEVDANGILNVKAEDKGTGKSEKITITNDKGRLSQEEIERMVREAEEFAEEDKKMKERIDARNGLETYVYNMKNQINDKDKLADKLESDEKEKIEAAVKEALEWLDDNQSAEKEDYEEKLKEVEAVCNPIITAVYQRSGGAPGGASEDDDSHDEL', '49390.A0A068UUU1': 'MADVQMAGETETFAFQAEINQLLSLIINTFYSNKEIFLRELTSNASDALDKIRFESLTDKSKLESQPELFIRIVPDKVNRTLSIIDSGVGMTKSDMVNNLGTIARSGTKEFMEALQAGADVSMIGQFGVGFYSSYLVAEKVVVTTKHNDGEQYVWESQAGGSFTVTRDVSGEPLGRGTKVTLYLKEDQLEYLEERRIKDLVKKHSEFISYPIYLLVEKTTEKEISDDEDEETKKDEEGEVEEVDEEKDKDKKKKKKIKEVTNEWQQINKQKPLWLRKPEEVTKEEYAAFYKSLTNDWEDHLAVKHFSVEGQLEFKAILFVPKRAPFDLFDTRKKLNNIKLYVRRVFIMDNCEELIPEYLGFVKGVVDSDDLPLNISRETLQQNKILKVIRKNIVKKCIEMFFEIAENKEDYAKFYDAFSKNIKLGIHEDSQNRAKLADLLRYYSTKSGDELTSLKDYVTRMKEGQQDIYYITGESKKAVENSPFLEKLKRKGYEVLFMVDAIDEYAVAQLKEYDGKKLVSATKEGLKLDESEEEKAAREEKKKSFENLCKVMKDILGERIEKVVVSDRVVDSPCCLVTGEYGWDSKHGEDYEGSSIKGHQHERLHTALLTSGFSLDDPNQFGSRIHRMLKLGLSIEENGTDDDADMPELKEETNEESKMEEVD', '49390.A0A068UV80': 'MVYFFLGSKKVFCCNLNVINLAGYVGEDVESILHKLLTVAEFNVQAAQQGMVYIDEVDKITKKAESLNISRDVSGEGVQQALLKMLEGTIVNVPEKGARKHPRGDHIQIDTKNILFICGGAFIDLEKTISERRQDSSIGFGAPVRANLRTGGITNATVTSSLLESVESSDLIAYGLIPEFVGRFPILVNLSALTEDQLVQVLAEPKNALGKQYQKLFNMNNVKLHFTEKALGLIAKKAMAKNTGARGLRAILEGILTDAMYEIPDIRGGMDRVDAVVVDEESVGTIDAAGCGGKILRGDGALECYLAKTKLKDQVENAAASEADLQGVESEVSSRAISM', '49390.A0A068UVY0': 'MGLYLSVAWFVKFGDCIWLSKSLYNHKDVFLQEFVSNASDALDKLRFLSMIEFGLLRDASDLEIHNKPDPNNGAITIRESGIGMTKNELTDYLETIV', '49390.A0A068UXN7': 'MSYCLSNLPISQLHVTPQRCSTTSNRSYGRSSRHLLSPVSGRNICKGIRAMTGDARDNLDHLQRANKQQTPQPRNKSAPVAPIGVLDRFPTARTVQQMMETMERLMEDPFAYSGGWPSPLAPDTGGYSRGRTPWEIKESEGEYKMRFDMPGMTKEDVKVWVEEKTLVVKAEKVPKKKNEDGEEEEKNEWSAKSYGRYNSRIALPENAQFEKIKAEVRDGVLYITIPKASSHGKILDINVE', '49390.A0A068UYQ6': 'MREREPTASSLGPTPHSLSLPRFLHFQNTPLLSPCRPPLTSIYMSTPSSISHLKLTTHHLNYLNGRNPKVFLWLLESLCQILTRKFPKSRGKRKMSFAVNRITICAAVSEASPPALETRTKPGNLYQVLRVKQNASQVEIKTAYRTLAKIYHPDVAPVAAKHPEESLDGCDFIEIHKAYSTLSDPDSRAVYDLTLTIGSQPQPLGVNYSAPGGFRRHAGFYATRRWETDQCW', '49390.A0A068UZP3': 'MAETETFAFQAEINQLLSLIINTFYSNKEIFLRELISNASDALDKIRFESLTDKSKLDAQPEFFIHIIPDKTNNTLSIVDSGIGMTKADLVNNLGTIARSGTKEFMEALAAGADVSMIGQFGVGFYSAYLVAEKVIVTTKHNDDEQYVWESQAGGSFTVTRDASGENLGRGTKMTLFLKEDQLEYLEERRLKDLIKKHSEFISYPISLWVEKTIEKEISDDEDEEDKKDEEGKVEEVDEEKEKDEKKKKKIKEVSHEWSLVNKQKPIWMRKPEEITKEEYAAFYKSLTNDWEEHLAVKHFSVEGQLEFKAILFVPKRAPFDLFDTRKKPNNIKLYVRRVFIMDNCEELIPEYLSFVKGIVDSEDLPLNISREMLQQNKILKVIRKNLVKKCIELFFEIAENKEDYNKFYEAFSKNLKLGIHEDSQNKTKLAELLRYHSTKSGDELTSLKDYVTRMKEGQNDIYYITGESKKAVENCPFLEKLKKKGYEVLFMVDAIDEYAVGQLKEFEGKKLVSATKEGLKLDESEDEKKKKETLKEKFEGLCKVIKDVLGDKVEKVIVSDRVVDSPCCLVTGEYGWTANMERIMKAQALRDSSMAGYMSSKKTMEINPENPIMEELRKRADADKNDKSVKDLVLLLFETALLTSGFSLDDPNTFGNRIHRMLKLGLSDADAEGSKMEEVD', '49390.A0A068V081': 'MALAFDEFGRPFIIIKEQESKTRLRGLDAQKTNIAAGKAVARILRTSLGPKGMDKMLQSPDGDITITNDGATILEQMDVDNQIAKLMVELSRSQDYEIGDGTTGVVVMAGALLEQAERLLERGIHPIRIAEGYEMASRIAYEHLEHIAQKFEFDATNTEPLIQTCMTTLSSKIVNRCKRSLAEIAVKAVLAVADLERRDVNLDLIKVEGKVGGKLEDTELIYGIIVDKDMSHPQMPKEIQDAKIAILTCPFEPPKPKTKHKVDIDTVEKFRTLRQQEQKYFDDMVQKCKDVGATLVICQWGFDDEANHLLMHRNLPAVRWVGGVELELIAIATGGRIVPRFQELTPEKLGRAGLVREKAFGTTKDRMIYIEHCANSRAVTIFIRGGNKMMIEETKRSIHDALCVARNLIRNNSIVYGGGSAEISCSIAVEAAADKYPGVEQYAIRAFADAMDSVPMALAENSGLQPIETLSAVKSQQIKENNPWCGIDCNDVGTNDMREQNVFETLIGKQQQMLLATQVVKMILKIDDVISPSDY', '49390.A0A068V0S7': 'MADSSGTTLMDLITSDQPSSTVPSSAASTTASSTAPPPQTTTANIGAPIPVVVDKKSKKGTLMQIQSDTISAAKAALNPVRANIMPQKQKKRPVSYAQLARSIHELAAASDQKSSQRQLVHHVFPKLAVYNSVDPSLAPSLLMLDQQCEDRTVLRYVYYYLARILSDTGSQGLSPGGGIPTPNWDALADIDAVGGVTRADVVPRIVDRLTSEALNEDVEFHPRRLQALKALTYAPSSSSEILTKLYEIVFSILDKVADPQKRKKGIFGAKGGDKESIIRSNLQYAAISALRRLPLDPGNPAFLHRAVQGVSFADPVAVRHSLEILSELGTSDPYAVAMALGKVVQPGGALHDVLHLHDVLARVALARLCHTISRARSLDDRPDIRSQFSSVLYQLLLDPSERVCFEAILCVLGKLDNAERTEERAVGWYRLTREILKLPEAPSVKETKADSKDAAPAKSSKEKSSKTKRPQPLIKLVMRRLESSFRSFSRPVLHAAARVVQEMGKSRAAAFAVGLQDIDEGVHINSFSESSDSYDQDLNETSEGLRRVSSVSNGTSGKDTIAGLLASLMEVVRTTVACECVYVRAMVIKALIWMQSPHESFGELESIIASELSDPSWPATLLNDILLTLHARFKATPDMAVTLLEIARVFATKVPGKIDADVLQLLWKTCLVGAGPDGKHTALEAVTIVLDLPPPQPGSMSELTSIDRVSASDPKSALALQRLVQAAVWFLGENANYAASEYAWESATPPGTALMMLDADKMVAAASSRNPTLAGALTRLQRCAFSGSWEVRIIAAQALTTMAIRSGEPYRLQIYEFLHTLEQGGLQSQLADMHVSNGEDQGASGTGLGSLISPMIKVLDEMYGAQDELIKEMRNHDNAKKEWTDDELKKLYETHERLLDLVSLFCYVPRAKYLPLGPTSAKLIDIYRTRHNISASTGLSDPAVATGISDLIYETAKPTPAEPDTLDDDLVNAWAANLGDDGLLGSNAPAMSRVNEFLSGAGTDAPDVEENITSRPSMSYDDMWAKTLLETTEMEEDTRSSGSSSPDSVGSVETSISSHFGGMNYPSLFSSKPSTYGSSQSTERAGGSRFSHPSFGGNSYEGFNSPIREEPPPYSSPTHQRYESFENPLAGPGSQSFGSHDDERLSSTNRQHGTALYDFTAGGDDELNLTAGEEVEIEYEVDGWFYVKKKRPGRDGKMAGLVPVLYVSQS', '49390.A0A068V120': 'MADEANRKAFLEIQSRMIESTAKLKQFQNQIRSKEGEKKRAYLTLEELRQLLDDTNTYKSIGRTFVLEPKSVLMDEQEQKLKDSEAAISALEKSKEYLEKQIAEVENNLRELLQQDPGLARQIMSMSV', '49390.A0A068V168': 'MSSSGGGGGGGWSGDRDVVRVSIPSNVRKIIQSIKEITGNHSEEDIYAMLKECSMDPNETTQKLLLQDTFHEVRRKRDRKKENLNKEPADSRWKSGVQGRGNRGRGTHSSRNISHDKAAGARKLASAKDNESNLDIDKGVSMSSLNTPWESEGKEPNSAASSLGATANGPTAIVSRNLTVMHDNEKLEEHLGPSATSSENRDQFAEQMPDSSNFSTSMSSSQPSGAYFLSSDPVSLSLQDSRQSSAVGTMKHGVGIQSSAVEQISAVSEIASGLDESGNSNVHGKMPSKAHGNGKNQHLDSSHTAASAVSRPSSNYSNRSQVIGPQKVGPNKEWKPKSTIPSLSQGSGTLASSEAPALSVEASTKMATALNDLDSKEANVRLQRKFEELHVSDGQHVIIPHHLHVPEAEKLGFCFGSFDTSFGISTSSINAPENDHSASSSETSDGNEAAEEQFSSNQNAFVAVEEGNSPENNHSSTDALENLSSGEGGVSSSNALDYDESKQESTPGGNQYTASHTTPNYGFGFMPPIVRSQLAPFESSESQTRDVSRLPAFVVQPTIDPTSYYAQFYRSGADSDGRISPFHPAGVASKYSGNFAMLSPQTSQSPQEPSNPLVLSTATPTPLITQAAGVMQSSIAATQQPVSVFRPPAGLHLPHYPSNYVPYGHYISPFYVPPAIHQFISNGAFPQQPQGSNLYPAPPAAAAKYPLPQYKPGTNPNNSSHVGIPGSYMPYGSSMANYNPNAASATGNSTTNEDLATSHLKENSLYESSQQSEGSGVWIAPPGRDFSSLQASSFYNFPQGQMAFAPAQPGHGTFAGIYHPAQPVNATTVNPLLQQSQTMASPLDVVGPTASAYQQPQHSQMNWPNNF', '49390.A0A068V198': 'MVGMGMPAYGIQSMLKEGHKHLSGLDEAVLKNIDACKQLSQITRTSLGPNGMNKMVINHLDKLFITNDAATIVNELEVQHPAAKILVLAGKAQQEEIGDGANLCVSFAGELLQNAEELIRMGLHPSEIIIGYAKAINKTIQVLEELVEAGSDTMDVRDTNQVISRMKAAVASKQFGLEDILCCLIAQACIQVCPKNPANFNVDNVRVTKLLGGGLHDSKIVRGMVLKSDAVGSIKRIEKAKVAVFAGGVDTSATETKGTVLIHSAEQLENYARTEEAKVEQLIKAVAESGAKVIVSGAAVGEMALHFCERYKLMVLKISSKFELRRFCRTTGAVALLKLSPPNPDDLGYVDSISVEEIGGVRVTIARNEEGGNSVSTVVLRGSTDSILDDLERAVDDGVNTYKAMCRDSRIVPGAAATEIELAIRLKEFSLKETGLDQYAISKFAESFEMVPKTLAENAGLNAMEIISSLYAEHASGNARVGIDLEEGTCKDVSTNSIWDLYITKFFALKYAADAVCTVLRVDQIIMAKPAGGPKRDAPAGMDED', '49390.A0A068V1N0': 'MLVSRIAARSSRTMVTQCRNSLLLLARQEQPFVPIPSSQCHSLIEPRNKVVSGQVALLHRSFLNGSPFQLFGFSSSASPQHNEKDTAQPGAENGSDAAAAGTSTETEVHDKTEASASTDSQVKDEKDVSDSDSDSEGDLSRDDLVKLVAEKEEQLKIKHEELQKLQDKALRTYADMQNSMDRTKRDAENLKKFAVQDFAKNLLDVADNLSRASLAVKDNFLKIDASKDAVGAVPLLKTLLQGVEMTEKQLAEVFKKYGLQKYDPVDEEFDPHRHNAVFQVPDPSKPPNTVAVVLKAGYTLHDRVIRPAEVGVTRAVENDAEQSSET', '49390.A0A068V2H1': 'MANMLGAGGRGAAADRRSPHDVIFEEIVPSSGWTEDKDRHCLIIDLPGFKMDEVKLRVDNYGHLLVSGERQVNGIKHIRFQQSYRVPDNSDIQEATAKFEDEILYMIIPKTATAENESNREKVTVPQTDHIQEESQQKNDLDRDHQVIDDDQDKIDNHQRTEKGSSEDPKKEEDCDGEPEEEFHDARKESVWNESSLLETLRLQLKKNTGIVVTAVLAFSLGVFVCQKFQTNPEN', '49390.A0A068V2U0': 'MGVDYYNILKVNRNASDEDLKKAYRRLAMIWHPDKNPTSNKQEAEAKFKQISEAYDVLSDPQKRQIYDLYGEEALKSGQVPPPPRGSGLYANRPHHHHHNQQQHPNPSFRFNPRDADDIYAELFGNETNAGGGGGGGSSSGRSGGAGRENASNNGYFFRSTTMGGSSSGAGNAGGGVGTSGGGGMRKEAPVETVLMCSLEELYKGSVKKLKISRRIIDRAGKFRNLEEILTVDIKPGWKKGTKITFPEKGNQEPGVIPADLVFVVDEKPHSIYVRDGNDLVANQEITLLESLTGKNLELTTLDGRNLLIPLTEIVKPGYEVTIPDEGMPISKDPRKKGNLRIKIDVKYPSRLSEAQKAELRRVLGPSS', '49390.A0A068V362': 'MDGGGSSGSNRSFLSDDNRNHFIHRSLRRRPHPTFTASATAPNSRHHHHHHHHQNHYDVLGVPPDASPSNVRKAYRLLALKHHPDVSKDSGADEIFKSIRHAYDILSNETTRNQYDRALRYQKESRRPLGSSWDYNSEYEDELRIYRWAYLKRKMRQEKYWQQYQSREKRYSFYDEAEEVTEDEERGSFVEVLKSAFLSLFLMQTVGVQLSLTFSALVAFLDQKLDAGYKIGYLVAWMLGGRGGVMLTLCLSFASWVCGKTSSSLVALTIVAMWFGSNLARFAPLPQGALLTLLYMSIKLQVDLK', '49390.A0A068V496': 'MDYKKSKALWIFFLFVSEFLLGITLAAEESQKKNLGTVIGIDLGTTYSCVGVYKNGNVEIIANDQGNRITPSWVAFTDTERLIGEAAKNQAAINAERTIFDVKRLIGRKFDDPEVQRDMKMLPYKIVNKDGKPYIQVKIKDGEVKVFSPEEISAMILQKMKQTAESYLGKEIRSAVITVPAYFNDAQRQATKDAGTIAGLNVARIINEPTAAAIAYGLDKKSKEMNILVFDLGGGTFDVSILSLDNGVFEVLATSGDTHLGGEDFDYRIMDYFVKLIKKKYNKDISNDKKALGKLRKECERAKRALSSQHQVRVEIESLFGGIDFSEPLTRARFEELNMDLFKKTMGPVKQALKDAGLEKTDIHEIVLVGGSTRIPKVQQLLKDFFDGKEPSKGINPDEAVAYGAAVQGGILGGEGGEETKGILLLDVAPLSLGIETVGGVMTKLIPRNSVIPTKKSQIFTTYQDQQTTVTIKVFEGERSLTKDCRELGRFELSGIPPAPRGVPQIEVTFELDANGILNVRAEDKAAKKAQSITITNDKGRLSQEEIERMVKEAEEFAEEDKKVSERIDARNKLETYIYNMKSTINDKDKLADKIDSDDKTKIESALKDALEWLDDNQNADKDDYDEKMKEVEAVCNPVIKMAYEKSSGSSSESTEDEPYDEL', '49390.A0A068V4H2': 'MFGRAPKKSDNTRYYEILGVSKNASPEDLKKAYKKAAIKNHPDKGGDPEKFKELAHAYEVLSDPEKREIYDQYGEDALKEGMGGGGGMHDPFDIFQTFFNGDPFNRGSSRGRRQRRGEDVVHPLKVSLEDLYSGTTKKLSLSRNVICTKCSGKGSKSGASTKCSGCQGTGMKVTIRQLGPGMIQQMQHPCNECKGTGETINDKDRCPLCKGEKVVPEKKVLEVHVEKGMQNGQKITFPGEADEAPDTATGDIVFVVQQKEHPKLKRKHDDIFVEHTLSLTEALCGFQFILTHLDGRQLLIKSKPGEVIKPDQFKAIDDEGMPMYQRPFMRGKMYIHFTVEFPDSLSPDQVKALEGILPPKPQSQLTDMELDECEETTLHDVNIEEEMRRKQAAQQEAYEEDDDMHGGGAQRVQCAQQ', '49390.A0A068V4H8': 'MVENLFTIQIKYYLRKNFHFQTQPKVEALQSTHSKPSYSAITQNPRALFPSLLCCSGRKPPLQPSPPSLTVVQEKASRLSSLPPINNYPFRNLGSLLSLSTCGSVFSLPSSFTMAVEKLFKDEATEEKGERARMASFIGAMAIADLVKTTLGPKGMDKILQSTGRGRSVTVTNDGATILKSLHIDNPAAKVLVDISKVQDDEVGDGTTSVVVLAGELLREAEKLVNAKIHPMTIISGYRVAAECARNALLEKVVDNKQDAEKFKSDLMKIAMTTLSSKILSQDKEHFAKLAVDAVMRLKGSTNLEAIQIIKKPGGSLKDSFLDEGFILDKKIGIGQPKRIENAKILVANTAMDTDKVKIYGARVRVDSMSKVAEIEGAEKEKMREKVQKIIAHGINCFVNRQLIYNFPEELFADAGVLAIEHADFDGIERLALVTGGEIASTFDNPESVKLGQCKLIEEIMIGEDKLIHFSGCEMGQACTVVLRGASSHVLDEAERSLHDALCVLSQTVNDSRVLFGGGWPEMVMAKAVDELARKTPGKKSHAIEAFSRALLAIPTIIADNAGLDSAELVSQLRAEHHEEGSAAGIDVISGSVGDMAELGISEAFKVKQAVLLSATEAAEMILRVDEIITCAPRRREDRM', '49390.A0A068V4J0': 'MVLGTSAAAEGFDKQNVETAISIELGTTNSCVAVRSDSCVSLSPSGLGIETEGGVMADVIPRGSLVPKKKSQIFTTYCDHQTTMSIKATVIIIFSGNERLTKYCRKLGMLQFSGIPPAPRGVAKN', '49390.A0A068V4N8': 'MTKLIPRNSGIPIKKSQVFTTYQDQQTTVSIKVYQGERSLTKDCYELGKFDLSGIPPAPRGVPQIEVTFGVDANGILQVTAMDKAAKKSNSITITNEKGHLTAEEIDRMDALEWLDGNQNAEKLDYDEKMAGLEAAFNPIIRKANESSAGSSADPEDESNYEL', '49390.A0A068V5C9': 'MGLDYYKILGVDKKATDDDMKKAYRKLAMKWHPDKNPNNKKDAEAKFKQISEAYDVLSDPQKRAVYDQYGEEGLKGGVPPPDTAGGPGSATFFSTGGGPTSFRFNPRSPDDIFSEIFGFSGFGGMGGGSGMRGSRFGGMFDDSMFSSFEGGGSGPGGSMHQQTIRKAPAIEQNLPCTLEELYKGTTKKMKISREVLDTNSGKIMPVEEILTINIKPGWKKGTKITFPDKGNELPGVAPADLVFIIDEKPHRVFTREGNDLIVTQKVSLTEALTGYTAHLTTLDGRNLTIPVTSVIHPTYEEVVRGEGMPLPKDPSKKGNLRIKFDIKFPARLTASQKAGIKELLGS', '49390.A0A068V6G5': 'MASSSSVKNKAFWLLLLFVSEFLAGVTLAAEDSQKQNLGTVIGIDLGTTYSCVGVYRNGNVEIIANDQGNRITPSWVAFTDTERLIGEAAKNQAALNPESTVFDVKRFIGRKFNDPEVQRDMKLLPYKVVNKVGKPYIDVKMKNGEMKLLSPEEVSAMVLQRMKQTAESYLGKEVKNAVVTVPAYFNDAQRQATKDAGTIAGLNVVLSTNGNTHLGGEDFDQRVMDHFLRKECERAKRALTTFEELNMDLFKKTMAPVKQALKDAGLEKSAIDEIVLVGGSTRIPKVQQLLKEFFDGKEPSRGINPDEAVAHGAAVQGAILGGHGGEETKDVLVIDVTPLSLGLETVGGVMTKLIPRNSGIPIKKSQVFTTYQDQQTTVSIKVYQGERSLTKDCHELGKFDLSGIPPAPRGVPQIEVTFGVDANGILQVTAMDKAAKKSNSITITNEKGRLTPEEIDRMVKEAEDMKSSIRDDEKVAGKIDSDDKESIETALKDALEWLDDNQNAEKLDYDEKMAELEAAFNPIIRKAYESSAGSSADPEDESNYEL', '49390.A0A068V6R1': 'MSEVDEESKQVSYKVVRDENGNVKLECPAIGKRFAPEEISAQVLRKLVDDASKFLNDKVTKAVITVPAYFNDSQRTATKDAGRIAGLDVLRIINEPTAASLAYGFEKKNNETILVFDLGGGTFDVSVLEVGDGVFEVLSTSGDTHLGGDDFDKRVVDWLAEDFKRNEGIDLLKDKQALQRLTETAEKAKIELSSLTQTNISLPFITATADGPKHIETTVTRAKFEELCSDLLDRLKTPVQTSLRDAKLSFNDIDEVILVGGSTRIPAVQDLVRKLTSKEPNVTVNPDEVVALGAAVQAGVLAGDVSDIVLLDVTPLSLGLETLGGVMTKIIPRNTTLPTSKSEVFSTAADGQTSVEINVLQGEREFVKDNKSLGSFRLDGIPPAPRGVPQIEVKFDIDANGILSVTAVDKGTGKKQDITITGASTLPKDEVDKMVQEAEKFAKEDKEKREAIDTKNQADSIIYQTEKQLKELGEKVPAAVKEKVEAKLTELKDAVSGGSTQAIKDAMAALNQEVMQLGQSLYSQPGTPGDGPTPGADAGASGSTGKSSGGDDGDVIDADFSESK', '49390.A0A068V715': 'MTAQSQEELLAAHLEQQNIDPEEPVIEDEDEEDDDDDDDKDEDDVEGQGDGSGRSKQSRSEKKSRKAMLKLGMKAIPGVSRVTVKKSKNILFVITKPDVFKSPTSDTYVIFGEAKIEDLSSQLQTQAAEQFKAPNISNVISKPEPSTVAQDDEDVDETGVEPKDIELVMTQAGVSRAKAVKALKAADGDIVSAIMELTN', '49390.A0A068V781': 'MLKLEMKAIPSASRVTVKKSKNVNFVYYLKDDEDVDKTGVEPKNIELKMTQASVSRTKAVKSLKVVDGDIVSTFMKLTNKETLYRVS', '49390.A0A068V7L1': 'MNVDSAPGPDGFGMGFYQSCWDIIKVDLLASIHDYFKGVAQPWGWSTFAFDHQYFLQQQGDFPSIELFIRPVPDKVNKTLSLIDSSIGMTKADLVNNLGTIARSGTKEFMEASQAGADVSMIGQFGVGFCSAYTTLHQNSPSRLQIFTEQKHGKPSLSL', '49390.A0A068V8B0': 'MEGEEAKLLLGFPPHSHPSPSQVKTAYKSKVWDTHPDRFPPHLKSNAEHRFKLISEAYACLRSASYSKVVRSGVPRACGSGGHRALIAAPFLLIVLSTVAFGGSIVTRSYKRQKEAYPSHNPFLP', '49390.A0A068V8K6': 'MVTNTSMILTPFFLFKTKFLISCYCYIIELCDSHDFLILYFSWVFFFFLHVYFHQNLGTVIGIDLGTTYSCVGVYRNGNVEIIANDQGNRITPSWVAFTDTERLIGEAAKNQAALNPESTVFDVKRFIGRRVDDPEVQRDMKLLPYKVANKDGKPYIDVKMKNSEMKLLSPEEVSAMVLQRMKKTAESYLGKEVKNAIITVPAYFNDAQRQATKDAGTIAGLNVQEKERNILVFDLGGGTFDVSILALDGGVFEVLSTNGNTHLGGEDFDQRHQVRVEIESLFDGIDFSEPLTRARFEELNMDLFKKTMAPVKQALKDAGLEKTDIDEIVLVGGSTRIPKVQQLLKDFFDGKEPSKGINPDEAVAHGAAVQGAILGGHDVLVIDVTPLSLGIETVGGVMTKLIPRNSGIPTKKSQIFTTYQDQQTAVSIRVYQGERSLTKDCHELGKFDLSGIPPAPRGVPQIEVTFEVDANGILQVTARDKAAKKSNSITISNEKGSLTQEEIDRMVKEAEEFADQDKELAAKIDSDDKESIETALKDALEWLDENQNAEKVDYDEKMAELEAVFNPIIRRAYENNSGSSADSKDEPHDEL', '49390.A0A068V8M1': 'MPCSSSVKNKAFWLLLLFVSEFLAGIALAAEGTQKQNLGTVIGIELGTTYSCVGVYRNGNVEIIPNDQGNRITPSWVAFTDTERLIGEAAKNQAALNPESTVFDVKRFIGRRVDDPEVQRDMKLLPYKVANKDGKPYIDVKMKNSEMKLLSPEEVSAMVLQRMKKTAESYLGKEVKNAIITVPAYFNDAQRQATKDAGTIAGLNVQEKERNILVFDLGGGTFDVSILALDGGVFEVLSTNGNTHLGGEDFDQRVMDYFKGMWRAKRALSNRHQVRVEIESLFDGIDFSEPLTRARFEELNMDLFKKTMAPVKQALKDAGLKKTDIDEIVLVGGSTRIPKVQQLLKDFFDGKEPSKGINPDEAVAHGAAVQGAILGGHGDVLVIDVTPLSLGIETVGGVMTKLIARNSGIPTKKSQIFTTYQDQQTTVSIRLGKFDLSGIPPAPRGVPQIEVTFEVDANGILQVTAIDKAAKKSNSITISNEKGSLTQEEIDRMVKEAEEFADQDKELAAKIDSDDKESIETTLKEALEWLDENQNAEKVNYDEKMAELEAVFNPIIRRVYEEALLIQKMNPMMSCEL', '49390.A0A068V8U1': 'MKVITKVSRVTVKKSKNVINVCHLKAILHETGVKTKDIGLVMTQGKVCRAKAVKAFKSTNGDIVFAIMEQTN', '49390.A0A068V951': 'MVHRRTSKLLFLLCFLSCSLIAIAAKSYYDILQVPRGASDEQIKRAYRKLALKYHPDKNQGNEEANKKFAEINNAYEVLSDSEKRSIYDRYGEEGLKQHAASGGRGGGMNIQDIFSQFFGGGPMEEEEKIVKGDDVIVELDATLEDLYMGGSLKVWREKNVIKPAPGKRRCNCRNEVYHKQIGPGMFQQMTEQVCEQCPNVKYEREGYFVTVDIEKGMQDGQEVVFYEDGEAIIDGEAGDLRFRVRTASHDLFRREGNDLHTTVTITLVQALVGFEKTIKHLDDHLVDIGTKGVTKPKEVRKFKGEGMPLHFSNKKGDLYVTFEVLFPTSLTEDQKTQIKAILG', '49390.A0A068V9E8': 'MAVEKFFKDEATEEKGERFRIASFVGAMAIADLVKTTLGPKGMLCQGINLTMAYDISKVQDDEVGDGTASVVVLAGELLLEAEKLVNTKIHPMTIISGYRMAAECAWNALLEKFLILLLLDSAEIFKLDLMKIAMTTLNSKILSQYKEHFANIAVDAVMRLKGSTNVEAIQIIKKTWRFTKGFTYCLLCCRFALEKKIGIDQSKRIENAKILVANIATDTDKVKIYGARVHVDSMSKVADIKGSEKEKMREKVQKIIAYGKNCLLVLEYLQ', '49390.A0A068V9Q0': 'MVMAKVVDELARKTPGIKSHAIEAFSAELVSQFHAEHHKEGSTADIDVISGSVGDTAELGISEAFKVKRSVLLSATEAAEMILRVDADITCAPCRREDRM', '49390.A0A068VA98': 'MALGRLTKDGQESGRFELSDIPPAPRGVPQIGVTFKVDTNGLLHVIAEDKATKVAIHYL', '49390.A0A068VAY4': 'MFSLTFSYSSSESTKIFFLYLSGKRILDISLSTVTIGHLGGDLFDERIVDWLAENFKRNEGIELLIDKQALQRLTETAERAKI', '49390.A0A068VBM4': 'MEGGKPTIVTNAEGQRTMPSVVAYTKNGDRLVGQVAKRQAVVNLETSFSL', '49390.A0A068VBQ5': 'MASQQRRINPSFLSLCLALGLLFACATAKVFFEERFDDGWEKRWVKSDWKKEDNTAGEWNYTAGKWHGDPNDKGIQTSEDYRFYAISAEFPEFSNKDKTLVFQFSVKHEQKLDCGGGYMKLLSGDVDQKKFGGDTPYSIMFGPDICGYTTKKVHAILNYNETNHLIKKDVPCETDQLSHVYTFILRPDATYSILIDNVEKQTGSLYSDWDLLPPKQIKDPEAKKPEDWDDKEYIPDPEDKKPEGYDDIPKEIPDPDAKKPEDWDDEEDGEWTAPTIPNPEYKGPWKAKKIKNPNYKGKWKAPLIDNPEFKDDADLYVYPNLKYVGIELWQVKSGTLFDNVLVSDDPEYAKKLAEETWGKHKDAEKAAFDEAEKKREEEEAKDDPVDSDAEEGDDDDAADEADSDDADAKSETKEDATAAAEENVKDEL', '49390.A0A068VBU7': 'SRSEKKSRKAMLKLEIKAISSVRRVTVKKSKNPDVFKSPTSDTYVIFGEAKIEDLSSQLQTQTAEQFKARNLSNVISKPEPSKLVMTQVGVSGAKAVKTLKAADGDIVTTIMELTN', '49390.A0A068VCW2': 'MGVDYYNILKVGRNATEDDVKKAYRRLAMKWHPDKNPTNKKEAEAKFKQISEAYEVLSDPQKRQTYDQYGEEGLKDMPPQGSGGGFQNGFNPRNAEDIFAEFFGSSPFGFGSAGPGRSMRFQSDGGGPFGGFGGGDNIFRTYSDGTGASMPKKPPPVESKLNCSLEELYTGSTRKMKISRTVVDVNGRMSTETEILSIEVKPGWKRGTKITFPDKGNEQFNQLPADLVFVIEEKPHNVYNRDGNDLIMKYTVTLAEALGGTTVNITTLDGRELSIPVNDIISPGYELVVDKEGMPIAKEPRNRGDLKINFEVKFPTKMTTEQRAAIKRALGG', '49390.A0A068VDL5': 'MEAAAQAFIKDEEFAPSVETVKDKDYSTILLHLPGFRREKLNVQLTTDGKLRVSGEKEAENNKVIRFQKEFRISSDINTKKITAKFEGDILYVRLPKLIAPGGKQDSKLTIPERPTPQKPADHKPESLRPTDESGGSQKPADHKPESLRPTDESRGSQKPADEPQQSQKPADKSDISRPTDESTVSQKPADEPRQFQKPADEARPQETVQQKTADKTSPIDGPSKQTDVQDVTQKKPEKEEAKAADMKDKATSETVDGSGKTSVDNYNQSALDPAAKLKMSRRAMDVAVVVLLAVVIGLYIIYCIRCFRRTTED', '49390.A0A068VEE6': 'MASSKGIGIGGGAGGPKTTAPVTTELDKLSVEQLRAVKEQADLEVNLLQDSLNNIRTATARLDIASNALNDLSLRPQGKKMLVPLTASLYVPGTLDDADKVLVDVGTGYFIEKTMVEGKDYCERKINLLKSNYDQLLETFYSWLLLQQNSLRILILLRLGEKECPQAKAFLCAPSHAFEAFVLYSSHCHSRNHF', '49390.A0A068VEF6': 'MQIFMKTLIRKTITLEVESSSTIDNVKAKIQDKEGNPPDQQCLIFTDTSASSCFPNFSPINLPNFFPQLPFLLPLRDSFLVNGVAFKKTFSYSGFEQQPKKFVNPKILLLNIELELKSEKENVEIRLSDPSQYQSIVDAEWNIIYDKLDKCVKSGAKIILSRLAIGDLATQLYFNRDVFCAGRVIEEDLHRVATATGGTI', '49390.A0A068VEQ2': 'MQIFMKTLIRKTITLEVESSGTINNVKAKIQDKEGNPPDQQCLIFTDSSASSCFPNFSPINLPKFFSQLAFLLALRDSFLVNGVAFKKTFSYAGFEQQPKKFVNPKILLLNIELELKSEKENAEIRLSDPSQYQSIIDAEWNIIYDKLDKCVKSGAKIILSWLAIGDLATQYFADRDVFYAGRVIEEDLHRVAAATGGTIQTTVEEVQFCY', '49390.A0A068VF92': 'MVDFKEKRWCRKTLFDNILVSLQVKSGTLFDNVLVSDDLEYAKKLAEETWGKHKDAEKVAFDEAEKKREEEVLFINSPLLHDVLSTFEFHFCIVWTLDFLYTALFEQ', '49390.A0A068VF93': 'MATTARRPPPPPPASAAAAAAVSISSIPSILKAYSIPLILFGIALFFQLVVTPGSFPPSHYDVLGVKKYASVEEVTQAYEKLTSTWDSSVPVPSVFDAVKVQYAFELLTNELWKRDYDNFGIDEQSHVINQATEQYAGATVSEIKSPLMEPNSFDLAEHTFNVINSENFLSQFDSTKAWLIQVSLLFNMLPFYVMTKCD', '49390.A0A068VFC4': 'MHRLSGRSVSTILRAGGCRRCRNATASISSSNIFHKSAEENDENVRWYSVLTTRQINCGKPIKQLNFGSSHHLLRIRYESTAAASDSSSNPPPEKYEYQAEVSRLMDLIVNSLYSNKEVFLRELIRHALVLFSPFSVSLPAGLVIHGASFSHAAFVVVVGGKK', '49390.A0A068VFN4': 'MDLELGLKLRRVADEFCLADFQFYKDRTGPVFISTETDSKFFLTAHLKGHRKQNIKIEINEDGTRIIISGEMEIQETVMVEWRLYRKETEIRRFRKAFKIPDGVILDKIKAKYNADECILTISMPKKDKGIRGFDIEEVQEQELAREGSETLEIVPDEVPKQEDEMQAKDQEAEAEHAEGKLEKEEKSQGIEGDMERKHEQPEPLTEVIDQNHHKRDQVDGKESGTQEAEEEEESALVKPPDEVQEDRPSRIEKHRGRCKMCAPILAGSALLLSLVVFVIQFIRKKSHQGKRKE', '49390.A0A068VFQ1': 'MLLIRSLFGGRRGNVFDPYSLDVWDPFVGLAFPDASLANVPNTASETYAFARPRIDWKETPEAHVYKADLSGLRKEEVKVEVEECRVLQISGERRREQEEKNDKWQMVERRSGRFGRRFRLPENAKADQVRASMENGVLTVTVPKEEAKKPEVKAIEISG', '49390.A0A068VG01': 'MSLIPSIFGGRRSNVFDPFSLDIWDSFPFSDASLANVPNTARETSAFASSRIDWKETPEAHVFKADLPGLKKEEVKVEVEDGRVLQISGERSREQEEKNDKWHRIERSSGKFLRRFRLPENAKLDQVKAGMENGVLTITVPKEQVKKPGVKAIEISG', '49390.A0A068VGB2': 'MALVPSIFGGRRSNIFDPFSLDIWDPFEGFPFSRTLANFPSGTDRETAVFTNARVDWRETPEAHIVQADLPGLKKEEVKVEVEDGRILKISGERSREQEEKSDTWHRVERSSGKFIRSFRMPENAKTEEIKASMENGVLTVTVPKVEEKKPEVKAINISG', '49390.A0A068VGE4': 'MSMVPSFFGRRSSTPDEIWDPFQGWPFNSDFSPFSGQLRTTFPSSSSETASFAHASIDWKETPNAHVFKADVPGLRKEEVKVEVEDDRILQISGERKREIEDKGHTWHKVERSSGKFMRRFRLPENAKVEQVKASMENGVLTVTVPKAEIRKPDVKSIEICG', '49390.A0A068VGF3': 'MENQVVRRRVNIIASHFGSPEDLSAAATHLFPTGCSNSLNSVIRRCDSKMYFARQTSSSQPCFMRPVANKQICHTYGNYAESTPRSKSSGSLNKDLYAYEAPMFSRPSITEPSMQNVEELQWLQQACNFHQPAPDPPTFARPSPVDYHAKERTEASKVKGFEWMPKMDVAESGCNYVVTIELPGARASNIRVEVNNQNLRVTGYRSIEWGKVASCSIDSTSAYHRREISQGPYEIVWPLPKNVNKENISAELVEGLLLINVPKLSEARRQLKRVYI', '49390.A0A068VH68': 'MENFLLLLLRLLIFLLIFCFTSSEIIFEERFEDGWRDRWVLSDWKRSEGKAGTFKHTAGKWAADPDDKGLQTYNDARHYAISAKIPEFSNKNRTLVVQYSIKIEQDIECGGGYIKLLSGYVNQKKFGGDTPYSFMFGPDICGTQTKKLQVIVSYQGQNYPIKKEIECETDKLTHFYTFILRPDATYSILIDNRERESGSLYSDWDILPPPKIKDVHAKKPADWDDREYINDPNNVKPEGYDSIPKEIPDPKAKKPADWDDEEDGIWRAKKIPNPAYKGPWKPKRIKNPNYKGKWKIPWIDNPEFEDDPDLYVWKPIKYVGIEVWQVKAGSVYDNILICDDPQYAKEVVEEIWEKNRVAEKEAFEEAEKIRIAREEEDAKRADKDGGKKKSRGRRHHRRHDPDEYLDYDYHDEL', '49390.A0A068VHV6': 'MSSLDCFRIYNASDALDKLRFLSVTEPELLKDAVDLDIRIQTDKDNGIVTITDTGIGMTREELVDCLGTIAQSGTAKFLKALKESKDSGGDSNLIGQFGVGFYSAFLVSERVEVSTKSPKSDKQYVWEGEANSSSYTIREETDPAKLVPRGTRLTLYLKRDDKGFAHPERVQKLVKNYSQFVSFPIYTWQEKGYTKEVEVDEDPSEAKKDDQGDKTEKKKKTKTVVEKYWDWDLTNETQPIWLRNPKEVSTEEYNEFYKKTFNEYLEPLASTHFTTEGEVEFRSILYVPSIAPMGKDDIINPKTKNIRLYVKRVFISDDFDGELFPRYLSFIKGVVDSNDLPLNVSREILQESRIIRIMRKRLVRKAFDMINGIAMSENKDDYDKFWENFGKHIKLGILDDKENHKRLAPLLRFFSSQSEDVPISLDEYVDNMKPEQKNIYYIAADSVNSARNTPFLEKLLEKDLEVLFLVDPIDEVAVQNLKEFKDKQFVDISKEDLDLGEKNEEKEKEMKQEFGQICDWIKKRLGEKVAGVQISNRLSTSPCVLVSAKFGWSANMERLMKAQTMGDSSSLDFMRSRRIFEINPEHPIIKTLNAACQSNPNDEEALRAVDLLYDTAAVSSGFTPENPAQLGGKIYEMMSMALSAKWGTSAGEFKRQTTSSTYVPETIEAEVVEPAAEVQK', '49390.A0A068VHW9': 'MFFVYILIDQVMFLSLQHVINQATEQYAGATVSEIKSPLMEPNSFDLAEHTFNVINSENFLSQFDSTKAWLIQVFSFGSNRCANFSNNWKHIVTLLDGVANSGMVELGDVRLAAYLAEKKPSGHPFFKNGLPTLLAFPPGCSSSRCLHRYGGQLSVDAITDWLATSILGLPRILYYSKESMVQNFLAKSKPHKVRVIFFSRSGERATPFIRQAAKYYWTYAAFAFARWDEGDSSLWWNMFGVESAPAIVILKDPGVKPTIYYGMCLYLAGSINNSMFIDIMENNKYHVLPQLRSVTSMELGCDAQGYSRAGSEMRIWYCVILAGRLSQELNKMRETIRRVQETLNNNGGELNALDQDSLSTPAALAVKQKRLTFTWLDGEAQQKYCFFHVNSEDSYETCGTRRAMIDVPRLLIVRYERNETEDEVKIERQPRNMFEALHHSEPDPASQLVAKYNGPDESTEIISWISRTIEDGDSRNLPPFRTKCPELVPEDSDPLWQAGSEKIISSSKDLKYKITSFINQMHNQLGDPRIGPVLLLVALMLCGRTWLQRSQPTPKNEPNTSNESSDKDKFRQNRETRPRNNPTRPRNDLIPPSITDVEPKDAQQVQFSGSDSDN', '49390.A0A068VID4': 'MQIFMKTLIRKTITLEVESSDTIDNVKAKIQDKEGNPPDQQCLIFTDSSASSWILFSYASFEQQPKKFVNPKILLLNIELELKSEKENAEIRLSDPSQYQSIVDAEWNIIYDKLDKCVKSGAKIILSRLAIGDLATQYFADRDLFGAGRVTEEDLHRVAAATGGTIQTTVNNEVQFYCSVLDIIYALHLFSELVKYAIFIALFLFKKFRKL', '49390.A0A068VJ16': 'MESNIDEALTVKAYAEKRFVERDFAGARNCALKAQMLCPELEGIAQMVATFGVYTASEVKINGEFDFYAILGLNPSADKAKLKKQYRKMAVLLHPDKNKTVGADGAFKLVSEAWTVLSDSAKRNSYDHRRNYFAAHSTGVSGFDNYSKSSGSHQRLDTFWTVCTSCHVQYEYLRKYVNKKLSCKNCRGVFVAVETGVAPVNGSFPYCPWSFVPENGYASHGCGVTYMPTASAYCSGNGISGHHSGHGPGEYVSNVSFQWTSFTGHSAGVSDANGLSAVTEASHQVNGKVNRGKANGRHRMRNATGDVSLNSCTVYAEQPAPKVTRPYKKRKFDSGGNCASGISDSAKSVAEERLANANGSLKINAKPSTPSDTSLRRCSAAPAFDARQLLIDKARTVIRQKLEEIKLASAAAAAAQAEKKRKAEAEADKFSEAPKRTSMTSIRTELKNALSQSRYGLYMMKKMVCHVYIV', '49390.A0A068VJ32': 'MAMRPARGGVGPSIRPRLGPVVQNFYEDFKPMSEWRQDEESDILSLFLPGFMNQHLKVSTEGRNIVRVRGERLVAGNKWSRFQEDYQVPDRCNIRAIRAKFEGGILTITMPWRKDAAAKATPPKATSGLDSTTDQMQQISPPKAPIEPRSKKSADEIPPKVIDPPPRPQKAAAEIHPKVVDPPSRPQTAAAEIRPKGLDQPSKPQKAAAEIHPKGLDSPSRPQKAIDEIQPKVLAPPSVTADKGSKDIDEKLLSQPQTQKGRQDEQARSPGAIKPVTTPITISSDDDEKKETITPKTNAKPMKPEYIENLKEVSDGKRSTEKSKEPLHTLAGNLTRKIIEEKEKQSQTAVASSSKDYGLGNFKKAVTSLAEPNEERQLLVNIVVAVLVIVAVGAHIASRIGSEEA', '49390.A0A068VJY5': 'MLRTSSEWVWTPALFMQLTRSIKTLQSFLQAAIFAGGVGTIATETKGTALIHKAQQALRGASSPLDISKVGELIKAIAGSGAKVIVSGAAVGEMALHFCERYKLMVLKISSKFELQRFCHTTGAVALVSILQSESINDTNTRI', '49390.A0A068VK96': 'MTNARGEVKYPIKGINILKAHGKSARDSYLLKGYALNTGRAAQGMPMRVAPARIACLDFNLQKTKMQMGVQVLVTDPRELEKIRQSEADMTKERIEKLLKAGANVVLTAKGIDDMALKYFVEAGAIAVRRVRKEDLRHVAKATGATVVSTFADMEGEETFDPSLLGHADEVVEEHVADDDMIMIKGTKTTSGVSLILRGANDFMLDEMDSALHDALCIVKRTLESTTVVAGGGAVEAALSVYLENLATTLGSREQLAIAEFAESLLIIPKVLAVNAAKDATELVARLRAYHHTAQTKADKKNLSRYSFLNPENCCLFQIYMSFCSYQIVISFPLSTALLEML', '49390.A0A068VKA4': 'MQIFMKTLIRKTITLEVESSGTIDNVKAKIQDKEGNPLDQQCLIFTDSSASSCFPNFPQLICLNFFPKYFFAKFFVLPWQLAFLLPLRDSFLVNGVAFKKTFSYAGFEQQPKKFVNPKILLLNIELELKSKKENAEIRLLDPSQYQSIVDAEWNIIYDKLDKCVKSGAKIMLSRLAIGDLATQYFADRGVFCAGRVTEEDLHRVAAATGGTIQTTVNNVIDEVQFCCSVLDIIYALHLFSELVKYAIFIALFLFRKFRKL', '49390.A0A068VLK5': 'MKTLIRKTITLEVESSGTIDNVKAKIQDKEGNPPDQQCLIFTDRSVSSCFPNFSPINLPKFFPQLAFLLPLRDSFLVNGVAFKKTFSYAGFEQQPKKFVNPKILLLNIELELKSEKENAEIRSLQYQSIVDAEWNIIYDKLDKCVKSGLKSFYLGWLLYFADRDVFCAGHVIEEDLHRVAAATSGTIQTTVNNVIDEVQFCCSVLDIIYALHLFSELVKYAIFIALFLFRKFRKL', '49390.A0A068VLT1': 'MAYSSSVKNKACWLLLLFVSEFLAGIALAAEGTQKQNLGTVIGIDLGTTYSCVGVYRNGNVEIIANDQGNRITPSWVAFTDTERLIGEAAKNQAALNPESTVFDVKRFIGRKFDDPEVQRDMKLLPYKVVNKDGKPYIDVKMKNGEMKLLSPEEVSAMVLQRMKQTAESYLGKEVKNAVVTVPAYFNDAQRQATKDAGTIAGLNVVRIINEPTAAAIAYALDGGVFEVLSTNGNTHLGGEDFDQRVMDYFVKLIKKKYNKDISNDKKALGKLRKECERAKRALSNQ', '49390.A0A068VM91': 'VSTFADMEGEETFDPSLLGHADEVVEEHVADDDVIMIKGTKTTSGVSLILRGANDFMLDEMDRALHDALCIVKRTLESTTVVAGGGAVEAALSVYLENLATTLGSREQLAIAEFAESLLIIPKVLAVNAAKDATELVARLRAYHHTAQTKADKKNLSRYSFLNPENCCLFQIYMSFCSYQIVISFLYQLHFWKCCSS', '49390.A0A068VMN0': 'MTKADLVNNLGTIARSGTKEFMEASQAGADVSMIGQFGVGFCSAYTTLHQNSPSRLQIFTEQKHGKPSLSP', '49390.A0A068VN26': 'MLRETMGKLCSKGFDKGISHRKVPPPVWCPLRCTLDELYNGVEKTIKFPGGRMKLLPDPGVIAPNADPETLVVEIPAGAKNGLKIVYPRRVILDDRKVPRDVIVDVIEEPHAEFHRQGNDLWAIRKIPLMEYVTNEALTIETLDKRLLTVPKIEPGCVIEIPNEGMPCWHGIGETGSIFVSFEVIYPKNLSLTREEKDELKKLLAKEENNV', '49390.A0A068VNA2': 'MSLIPSVFGGRRSNVFDPFSLDIWDPFEGFPFSNTSLANVPDTARDTSAFATARIDWKETPEAHVLQISGERSREQEEKNDKWHRVERSSGRFLRRFRLPENAKVDKVKASMENGVLTVTVPKEEVKKADVKAIEISG', '49390.A0A068VNL3': 'LSPYLVAFEPLLPSIPETSTLAPRIKPSWIAFAGSERLIREAEKNQLDVNVERTIFDVKIKDSKVKVFSLEEISVMVLTKMKEAAEAFLAKKIKDAVVTVPSIVQFLELLATKNAGIIAGLNVARTINEPRAAAVAYLTTN'}\n\n\nAs as sanity check, we need to match the unique protein sequences on the intarctions dataframe and the protein names on the fasta file.\n\n\nCode\nunique_proteins = set(df['node1_string_id']).union(set(df['node2_string_id']))\nunique_proteins\n\n\n{'49390.A0A068TKM9',\n '49390.A0A068TLP4',\n '49390.A0A068TMA4',\n '49390.A0A068TMI8',\n '49390.A0A068TMJ2',\n '49390.A0A068TMU0',\n '49390.A0A068TMW0',\n '49390.A0A068TNA3',\n '49390.A0A068TNP3',\n '49390.A0A068TP17',\n '49390.A0A068TPE5',\n '49390.A0A068TPQ0',\n '49390.A0A068TPY9',\n '49390.A0A068TQ83',\n '49390.A0A068TQM6',\n '49390.A0A068TQP9',\n '49390.A0A068TQV0',\n '49390.A0A068TR15',\n '49390.A0A068TRG1',\n '49390.A0A068TS31',\n '49390.A0A068TSW5',\n '49390.A0A068TSY2',\n '49390.A0A068TUK4',\n '49390.A0A068TUL0',\n '49390.A0A068TUV5',\n '49390.A0A068TVG9',\n '49390.A0A068TVU9',\n '49390.A0A068TVX0',\n '49390.A0A068TW76',\n '49390.A0A068TWQ3',\n '49390.A0A068TXJ0',\n '49390.A0A068TXK3',\n '49390.A0A068TXV8',\n '49390.A0A068TZG2',\n '49390.A0A068TZK0',\n '49390.A0A068TZS7',\n '49390.A0A068U059',\n '49390.A0A068U2B6',\n '49390.A0A068U2I0',\n '49390.A0A068U2R7',\n '49390.A0A068U3B4',\n '49390.A0A068U3E9',\n '49390.A0A068U6M9',\n '49390.A0A068U6U9',\n '49390.A0A068U861',\n '49390.A0A068U8U4',\n '49390.A0A068U8Z8',\n '49390.A0A068U922',\n '49390.A0A068U979',\n '49390.A0A068U9F8',\n '49390.A0A068U9H0',\n '49390.A0A068UA30',\n '49390.A0A068UBQ0',\n '49390.A0A068UCA8',\n '49390.A0A068UDA4',\n '49390.A0A068UDH3',\n '49390.A0A068UED5',\n '49390.A0A068UEW5',\n '49390.A0A068UF36',\n '49390.A0A068UFS1',\n '49390.A0A068UG80',\n '49390.A0A068UGP7',\n '49390.A0A068UHQ8',\n '49390.A0A068UHU0',\n '49390.A0A068UI14',\n '49390.A0A068UIC6',\n '49390.A0A068UIK8',\n '49390.A0A068UIR8',\n '49390.A0A068UJ52',\n '49390.A0A068UJS0',\n '49390.A0A068UK32',\n '49390.A0A068UKG2',\n '49390.A0A068UKG5',\n '49390.A0A068UKH3',\n '49390.A0A068UKL9',\n '49390.A0A068UKM4',\n '49390.A0A068UKV4',\n '49390.A0A068UKZ1',\n '49390.A0A068UL97',\n '49390.A0A068ULW4',\n '49390.A0A068UM55',\n '49390.A0A068UMK5',\n '49390.A0A068UN30',\n '49390.A0A068UN39',\n '49390.A0A068UNW6',\n '49390.A0A068UPA4',\n '49390.A0A068UPY3',\n '49390.A0A068UQI7',\n '49390.A0A068UQV1',\n '49390.A0A068URJ1',\n '49390.A0A068USH9',\n '49390.A0A068UT14',\n '49390.A0A068UTG2',\n '49390.A0A068UTZ3',\n '49390.A0A068UUJ1',\n '49390.A0A068UUL8',\n '49390.A0A068UUU1',\n '49390.A0A068UV80',\n '49390.A0A068UVY0',\n '49390.A0A068UXN7',\n '49390.A0A068UYQ6',\n '49390.A0A068UZP3',\n '49390.A0A068V081',\n '49390.A0A068V0S7',\n '49390.A0A068V120',\n '49390.A0A068V198',\n '49390.A0A068V1N0',\n '49390.A0A068V2U0',\n '49390.A0A068V362',\n '49390.A0A068V496',\n '49390.A0A068V4H2',\n '49390.A0A068V4H8',\n '49390.A0A068V4J0',\n '49390.A0A068V4N8',\n '49390.A0A068V5C9',\n '49390.A0A068V6G5',\n '49390.A0A068V6R1',\n '49390.A0A068V715',\n '49390.A0A068V781',\n '49390.A0A068V7L1',\n '49390.A0A068V8B0',\n '49390.A0A068V8K6',\n '49390.A0A068V8M1',\n '49390.A0A068V951',\n '49390.A0A068V9E8',\n '49390.A0A068V9Q0',\n '49390.A0A068VA98',\n '49390.A0A068VAY4',\n '49390.A0A068VBM4',\n '49390.A0A068VBQ5',\n '49390.A0A068VCW2',\n '49390.A0A068VEE6',\n '49390.A0A068VEF6',\n '49390.A0A068VEQ2',\n '49390.A0A068VF92',\n '49390.A0A068VF93',\n '49390.A0A068VFC4',\n '49390.A0A068VFN4',\n '49390.A0A068VFQ1',\n '49390.A0A068VG01',\n '49390.A0A068VGB2',\n '49390.A0A068VGE4',\n '49390.A0A068VGF3',\n '49390.A0A068VH68',\n '49390.A0A068VHV6',\n '49390.A0A068VHW9',\n '49390.A0A068VID4',\n '49390.A0A068VJ16',\n '49390.A0A068VJY5',\n '49390.A0A068VK96',\n '49390.A0A068VKA4',\n '49390.A0A068VLK5',\n '49390.A0A068VLT1',\n '49390.A0A068VM91',\n '49390.A0A068VMN0',\n '49390.A0A068VN26',\n '49390.A0A068VNA2',\n '49390.A0A068VNL3'}\n\n\nHere, we filter the dictionary with the unique protein names from the interactions dataframe.\n\n\nCode\nfiltered_protein_dict = {protein: seq for protein, seq in protein_sequences_dict.items() if protein in unique_proteins}\n\nprint(f\"Number of matched sequences: {len(filtered_protein_dict)}\")\nprint(f\"Number of unique proteins in DataFrame: {len(unique_proteins)}\")\n\n\nNumber of matched sequences: 158\nNumber of unique proteins in DataFrame: 158\n\n\n\n\nCode\nfiltered_protein_dict\n\n\n{'49390.A0A068TKM9': 'MYMYMYVYVYRAVFSLLCFHLIFSSSFHAAYMYLWCIFTGTILDLTCIIAVLGKIYNYQSFTANLKIHYCYLFPVKTIPLLWCEIMDCNCCYTLARPSSSITPVLNFQSVSAVNRNFSVKNLHPRVLPSPGSCRQFGRLSDQFRPFIYQGNSELPCLRTYRGQISSEARRQGWDFGRFLKTLYFFNGPPSPAKFFEFLIEKLSNPSPSKTENRMDPSGVILVAGATGGVGRRVFDILRSKGYTVKVLVRNEDKARRMLGPDVDLIVGDITKASTLVPEYFKGVRKVINAVSVIVGPKEGDTPDRAKYSQGIKFFEPEIKGASPEMVEYIGMKNLINAVKESVGIRRGKLVFGFEENLTRELAWGALDDVVMGGVSESSFVIDPTGGEKGGPTGVFRGVVSTANNGGFTSIRTKNFPVPEDLSAYDGLELRLKGDGRRYKLIVRTSCDWDTVGYTLSFDTIEGQWQSIQLPFSSLRPVFRARTVSDAPPFDARQIASLQA',\n '49390.A0A068TLP4': 'MFSKFEYDGKLNPTFKEGPFQLPVSSIKTFMKEPVTPRFVHVSSAGVARPERPGLDLSKQPPAVRLNKELGFILTFKLKGEDLIRESGIPHTIVRPCALTEEPAGADLIFDQGDNITGKISREEIARICIAALESPYACDKTFEVKSVIPFSEPYTVDPANPPPEKDYNQYFKSLKDGITGKESLEKSPAAV',\n '49390.A0A068TMA4': 'MATAVLLRSLRRRELASAPISAYKSLVGNTKSAWISANSSSNWASLTRPFSSKPLGNEVIGIDLGTTNSCVAVMEGKNPKVIENSEGSRTTPSVVAFNQKGELLVGTPAKRQAVTNPNNTLFGTKRLIGRRFDDLQVQKEMKMVPYKIVRAPNGDAWVEANGQQYSPSQVGAFVLTKMKETAEAYLGKTIDKAVITVPAYFNDAQRQATKDAGRIAGLDVQRIINEPTAAALSYGSNNKEGLVAVFDLGGGTFDISILEIANGVFEVKATNGDTFLGGEDFDNALLEFLVSEFKGNEGIDLTKDRLALQRLREAAEKAKIELSSTTQTEINLPFITADASGAKHLNITLTRSKFETLVNHLIERTRQPCKNCLKDAGVSSNEVDEVLLVGGMTRVPKVQEVVAEIFGKSPSKGVNPDEAVAMGAAIQGGILRGDVKELLLLDVTPLSLGIETLGGVFTRLINRNTTIPTKKSSVFSTAADNQTQVGIKVLQGEREMASDNKLLGEFELVGIPPAPRGMPQIEVTFDIDANGIVTVSAKDKSTGKEQQITIRSSGGLSEAEIEKMVREAEVHAQKDQERKALIDLKNQADTAIYSIEKSVSEYKDKVPAEVVSEIQAAVSDLRAALQNDNADEIKAKLDAANKAVSKIGEHMSGSGQSGGSASGGSQGGDQATEAEYEEVKK',\n '49390.A0A068TMI8': 'MADPVARSPPANLYSILGISKAASLADISKAYKSLVMKWHPDRNTSNKAEAEAKFSTINEAYRVLSSKKREEINGTSHDDPKTPENSYHHRSSSDDDGQFVISSPTLLSSTSTRITPTGTPRSSDGSSHRGYYSGAPSPRNFYGHSRSPNGTDTPSTPTTPEPPLVSLSKITSKRATNPIIYSQTTARRKAQPIQKKLECTLEELCHGCVKKVKITRDVISNAGIIVQEEEILRIKVKPGWKKGTKITFEGKGDERPGMHPADIIFIIDEKRHPLFKREGDDLELGVEIPLVQALTGCTISVPLLGGDQMDLSIGDIIFPGYEKIIPDQGMPISKQHGRRGDLRLRFLVEFPTDLSKQQRSAVVRILEDCC',\n '49390.A0A068TMJ2': 'MKPHFRSGFWLFFVVLLFVGLSGNLISAQTRSPKNVQVALRAKWSGTPLLLEAGELLSSQWKDFYWDFTEFWLLKGSEDSGSHTAKDCLRTIVNYGKSLLSKPLASVFEFSLTLRSASPRLVLYRQLAEDSLSSFPLVDYSSASSNEGGFETNDNAKSKKVEPLLLGVNSRAPNGKCCWVDTGAALLFDANELLLWLENPDKATTDTFQQPELFEFDHVHPDSSIGSPIAILYGALGTDCFKEFHNVLVGTARQGKITYVVRPILPSGCESKVGHCGAIGTRDAVNLGGYGVELALKNMEYKAMDDSAVKKGVTLEDPHTEDLSQDVRGFIFSRILERKPELTSEVMAFRDYLLSSTISDTLDVWELKDLGHQTAQRIVHASDPLQSMQEINQNFPSIVSSLSRMKLNDSIKDEIIANQRMIPPGKSLLALNGALINIEDVDLYLLVDMVQQELSLADQFSKMKIPSTNVRKLLSILPPSESNMIRVDFRSTHVHYLNDLEHDIIYKRWSSSINEILMPVFPGQLRYIRKNIYHAVYVLDPASICGLEASY',\n '49390.A0A068TMU0': 'MQTIEMVISLFENNLPMRFGVILYSANIIQKIEANGDELQRSLEDDLKSEEDVSSLVIRLFLHIKENHGNLMAFQFLSNVNKLRIESAPEEAPEIHHVEGAFVETLLPSAKTPPQDILLKLEKEKTYHELSQESSMFVFKLGLAKLQCCLLMNGLVYDSNEEALFNAMNDELPRIQEQVYYGLINSNTDVLDKFLAESGIQRYNPQIIAGGKVKPKFVSLSASILRNGSWINEISYLHSSDTVDDIKPVSHLLAVDFTSKKGIKMLREGLSYLMGGSKIARLGVLFNSNEEANSLSYIFVKVFEIAASSHSHKKGVLEFLDQVCSLYEREYMTSTSPDNEKSQEFIDKVVDLAVASGLPSKGYESPLSTFSVGKLKNHLIKVAQFLYRQLGFHSGVNAVITNGRVVPVGGGVFLSHDLSLLESIEFKQRIKQIADIIEELKWEDMDPDLLTSKFISDIILSISSSMAMRERSSESARFEILSSTCSAVVLDNEDSSIHIDAVIDPLSSSGQKLSSLLRFLSKYIQPSMRLLLNPVSSLVDLPLKNYYRYVVPTLDDFSSIDDTVYGPKAFFANMPLSKTLTMNLDVPEPWLVEPVIAIHDLDNILLENLGDARTLQAVFELEALVLTGHCSEKDHEHPRGLQLILGTKSTPHLVDTLVMANLGYWQMKVFPGVWYLQLAPGRSSELYVMKEDGDGSPYTTLSKQITINDLRGKLVHLEVLKKKGKENEKLLLASDSDESHSRQNRNGDQKSWNSNLLKWASGFIGGSDRSKKIESTSVEHGNTGRRGKTINIFSVASGHLYERFLKIMMLSVLKNTRRPVKFWFIKNYLSPQFKDVIPHMAQEYGFEYELVTYKWPTWLHKQKEKQRIIWAYKILFLDVIFPLALEKVIFVDADQIVRADMGELYDMNLKGRPLAYTPFCDNNKEMDGYRFWKQGFWKEHLRGRPYHISALYVVDLVKFRETAAGDQLRVFYETLSKDPNSLSNLDQDLPNYAQHLVPIFSLPQEWLWCESWCGNATKSKAKTIDLCNNPMTKEPKLQGAKRIVAEWPDLDLEARQFTAKISGEPIDLKEQVALPLESQSSTIHDSSEDWESKSEL',\n '49390.A0A068TMW0': 'MHNSFVNWSRRGGNRCFKMLYWERISKTAGYVGEDVESILYKLLMVADFNVEAAQKGIVYIDEMDKMTKKAENLSAGRDVSGEGVQQALLKMLEGTIVNVPDNRARRNPHGDSIQIDTKNILFICGGAFVDLEKTISERRQDSSIGFGAPVRANMRQAGLTDAAVTSSLLESVESGDLIAYGLIPEFVGRFPILVSLSALDEDQLVQVLTQPKNALCKQYKRMFAMNKAKLHFEDNALRLVAKKAIAKKTGARGLRAILENILTEAMFEIPDAGSGRNLIDLVLVDEDAVGSLDRPGLGAKIIHGNGGLERSPYETELRDGQEGGEMVRVDLDGELEVSSAALSL',\n '49390.A0A068TNA3': 'MSRFRGLWQASVNATKKALTWNVDDWIPPSEKYIFSFNSKDELKKWHLYSDSEYGGLSTASLEIKNVGNASSVTTGIFSGNLSSELSESSRWNISRSGFCGMRSRKFDGFIDLESYDSIALKLKGDGRCYISTIYTENWVNSPAQHEDNSWQAFVFVPKDNWYIAKIPIARYLPTWRGNVIDANLEMNPSRVVGMSFSVNAEGGVPGARTGPGDFRVEIDWIKALRTQ',\n '49390.A0A068TNP3': 'MSEVDEESKQVSYVVVRDENGNVKLDCPAIGKMFAAEEISAQVLRKLVDDASKFLNDKVTKAVVTVPAYFNDSQRTATKDAGRIAGLEVLRIINEPTAASLAYGFEKKNNETILVFDLGGGTFDVSVLEVGDGVFEVLSTSGDTHLGGDDFDKRIVDWLADNFKKDEGIDLLKDKQALQRLTETAEKAKMELSSLTQTNISLPFITATADGPKHIETTLARAKFEELCSDLLDRLKRPVQNSLSDAKLSFSDIDEVILVGGSTRIPAVQEVVKKLTGKDPNVTVNPDEVVALGAAVQAGVLAGDVSDIVLLDVTPLSLGLETLGGVMTKIIPRNTTLPTSKSEVFSTAADGQTSVEINVLQGEREFVRDNKSLGSFRLDGIPPAPRGVPQIEVKFDIDANGILSVAAVDKGSGKKQDITITGASTLPSDEVERMVKEAEKFSREDKEKRDAIDTKNQADSIVYQTEKQLKEFGDKVPAAVKEQVEAKVGELKDAISGDSTQAIKDAMAALNQEVMKLGSSVYGKPGESPDAGAAPGTEPGPSGKGNDGDVIDADFTDSK',\n '49390.A0A068TP17': 'MSGIFRYKTKLRSLAPKITTLSLSSSKFQSSPRKTLSKISEYFPHPQPRPHLNPLGFVSHIQERHKWHGSSDNYDHIKAEVNCPRCSKLMSVLFSNRPLSISRSEPGVYQAVNLCPNCRTAFYFRPFKLEPLQGSFIELGRLKGGKVDMEGNSESGGTGGRGGENGKKIWEKLRNYSGGSSASSNNVKEGSSNSGGDVEEKAVGPAWVEVGSGGGEFEGANLGKELPTPKEISRGLDDFVVGQERAKKVLSVAVYNHYKRIYHASLHGESGAEYRSTDGKIGDFDADDVELEKSNVLMMGPTGSGKTLLAKTLARVVNVPFVIADATTLTQAGLR',\n '49390.A0A068TPE5': 'MSTVVEAINHLFNFPETLDKFMLNSSSRAGEGAGSVANDSRGGVGSLPAVDILDSPKAYVFYVDVPGLSKSDIQVTLEDENTLVIRSNGKRKREDGEEEGCKYIRLERSAPQKLSRKFRLPDNANASAISANCENGVLTVAVEKLPPPPKSKTVQVAIS',\n '49390.A0A068TPQ0': 'MERMKRKPNLRYLLLMLVVGCFFSELKASSNSEFYESFEEAIEGRWVVSQKEDYKGVWKREKSEGHDDYGLLVSEKAKKYAIVKELDEPADLKDGTVVLQYEVRLQEGLECGGAYLKYLRPQDAGWTSKEFDNESPYSIMFGPDKCGATNKVHFILKHKNPKTGEFIEHHLKFPPSVPSDKLTHIYTAILKPDNELRILIDGEEKKKADFLSAEDFEPPLIPSKTIPDPDDKKPEDWDERAKIPDPDATKPDDWDEDAPLEIVDEDAVKPEGWLDDEPEEIDDPEATKPEDWDDEEDGEWEAPKIDNPKCAEGPGCGEWKRPMKRNPAYKGKWHAPMIDNPNYKGIWKPQEIPNPSYFELDRPDFEPIAAIGIEIWTMQDGILFDNILIASDEKVAESYRTTTWKPKFEVEKEKQKAEEAAADTGALKGFQKTVFDLLYKVADLPFLGEHKLKVLDLLEKAEKQPNLTIGVIISIIVVIFTLLLKIIFGGKKPARAREEPEKTDAPESSSNQETTEETTEEKEEPNEDAGAAPRRRIRRDN',\n '49390.A0A068TPY9': 'MAIVPCGSTWMARCGVQPQIVARFTVTNKLSLPPDCVASRSKVLASPSSTFFSQRPLHVLFNSGSCKDSRQKRGARFAVRAQQDYYSVLGVSKNASKSEIKSAYRKLARSYHPDVNKEPGAEQKFKEISNAYEVLSDDEKRSIYDRYGEAGLKGSMGMGDFSNPFDLFESLFDGLGGMGMGARGSRNRATEGEDQVYNLVLDFKEAIFGVEKEIEIMRLENCGTCDGSGAKPGTRTAKCSACGGQGQVVSSARTPLGVFQQIMPCSACGGAGETSTPCNTCGGDGRVRKSKRISLKVPAGVDSGSRLRVRSEGNAGRRGGPPGDLFVIIEVRPDPVLKRDDTNILYTCKVTYIDAILGTTLKVPTVDGMVDLKVPSGTQPGTTLVMAKKGVPFLNKSNMRGDQLVRVQVEIPKRLSGEERKLIEELANLNKAKAPNSRR',\n '49390.A0A068TQ83': 'MANSATLTLSSPEPPQSRIAPVFPFSSSSSSFLAGGTHLRSHKKFISVSLSSSSSQFSNKISARRFGRLVVAAADYYSTLGVSKSASGKEIKAAYRRLARQYHPDVNKEPGATDKFKEISAAYEVLSDDKKRALYDQYGEAGVNSSMGGQAGAYTTNPFDLFETFFGPSMGFPGMDATGFGTRQRSTVTKGEDLRYDIRLEFSAAIFGAEKEFELSHLETCEACAGTGAKTGSKMRICSTCGGRGQVMRTEQTPFGMFSQVSICPNCGGNGEMISEYCRKCSGQGRIRVKKDIKVKIPPGVGKGSILRVAGEGDAGPKGGPPGDLYVYLDIEEIPEIQRDGINLSSTVSISYLDAILGTVTKVKTVEGLTDLQIPPGTQPGDVLVLARKGAPKLNRPSIRGDHLFTVKVSIPKKISSQERELLEELASLSSKPGKRSKTRPNVQQTTKTVQSETDSATNNSEESEEQNDLWKKFTDFAGSVANGALKWLKDNL',\n '49390.A0A068TQM6': 'MVKATRFVFMSLLVLAAVAALLPEQAEALMPYSPRSFWDMMLPNEDPFRILEHSPLTVPKGVETLALARADWKETAKEHVISLDVPGIKKEEVKIEVEDNRVLRVSGERKTEEEVEGDKWHRAERTVGKFWRQFRLPGNADLDKVQAHLENGVLEIVVPKLAEEKKKQPKVINIAEEAGSNTGVDVKAKRDEM',\n '49390.A0A068TQP9': 'MAAKGEGKAIGIDLGTTYSCVGVWQNDRVEIIPNDQGNRTTPSYVAFTDTERLIGDAAKNQVAMNPQNTVFDAKRLIGRRYSDPSVQADMRHWPFKVIAGPGDKPMMVVRYKGEEKHFAPEEISSMVLTKMKEVAESFLGQTVKNAVITVPAYFNDSQRQATKDAGAIAAINVMRIINEPTAAAIAYGLDKKGSRTGEKNVLIFDLGGGTFDVSLLTIEEGIFEVKATAGDTHLGGEDFDNRLVNHFVQEFKRKNKKDISGNARALRRLRTACERAKRTLSSTAQTTIEIDSLYEGIDFYATITRARFEELNMDLFRKCMEPVEKCLRDAKVDKSHVHDVVLVGGSTRIPKVQQLLQDFFNGKELCKSINPDEAVAYGAAVQAAILGGETDQKVQDLLLLDVTPLSLGLETAGGVMTVLIPRNTTIPTKKEQIFSTYSDNQPGVLIQVYEGERPMTKDNNLLGKFELSGIPPAPRGVPQINVCFDIDANGILNVSAEDKTAGVKNKITITNDKGRLSKGEIERMVQEAERYKAEDEAVKKKVEAKNSLENYAYNMKNTVRDEKFAGKLDPSDKQKIEKAIDEAIEWLDGNQLAEVDEFEDKQKELEALCNPIIAKMYQGAGGDVPMGGGAADMPGAGRGTADSGSNGPGPKIEEVD',\n '49390.A0A068TQV0': 'MQLAVTPKPNPTNNTFSNPNFYPNFTSPKTQSLKFSSSSSSSNVPINLFYSFSPRRRRLSPVIARATAKTPDYYSVLSVSKNASLQDIKAAYRKLARKYHPDVNKKPGAEEKFKEISAAYEVLSDDEKRSAYDRFGEAGLRGDFVGSTSGSQGVDPFEIFSEYFGESSSFFRGSGEPGGFNFSFRSKSRQDLDIRYDLYMSFEESIFGSQREIEVPSLETCNDCSGTGAKTSNSIKICNACGGRGGVAKTQQTPFGIMSQVSTCAKCGGVGKIITDHCLTCGGNGRIQSKRRINIVIPPGIDNGATMQVQGEGNIDNKRGIAGDLFIVLHIEEKHGIQRDGLNLYSKVKVDFTEAILGTVVKVKTVEGVRDLHIPPGIQPGDTIKMRSMGVPHINKPSVRGDHCFAVNIQIPKDISDAERSLVEELALLRQTSRDSISSSEIPGGDDHDQHTKPALDHRGKSMAYLWKSIKDFLGKKQSGKRFASVGMEAPVSWRVTSPLPRCSLMIYSPAIFIMTLVFTLVGRTAYCKLFRQKPKTKSTSPHPERTQGQR',\n '49390.A0A068TR15': 'MAAPAAVASAPRASSSKTDTFVDNKRKDDIRMANISAAQSVADAVRTSLGPKGMDKMISTANGEVIITNDGATILNKMEVLQPAAKFLVELSKSQDVVAGDGTTTVVVIAGALLKSCLSLLTSGIHPTIISDALHKASVKAVEVLTAMAVPVELSDRESLVKSASTALNSKVVSQYSTLLAPLAVDAVLSVVDPAKPDLVDLRDIKIVKKLGGTVDDTELVKGLVFDKKVSHAAGGPTRVENAKIAVIQFQISPPKTDIEQSIVVSDYTQMDRILKEERNYILGMIKKIKATGCNVLLIQKSILRDAVTDLSLHYLAKAKILVIKDVERDEIEFITKTLNCLPIANIEHFKAEKLGFAELVEEVSLGDGGKLVKITGIKDMGRTTSVLVRGSNQLVIDEAERSLHDALCVVRCLVNKKFLIAGGGAPEIELSRQLGAWAKVLQGMEGYCVRSFAEALEVIPYTLAENAGLNPIAIVTELRNRHAQGEINAGINVRKGQITNILEENVVQPLLVSTSAIALATECVRMILKIDDIVTVR',\n '49390.A0A068TRG1': 'MLVNYVHRTLNKHSYISHCCFTLQFPGQLSPDSSFASMGRARTDSDIKSHLVTEICNISDRAVTCAHQHHFRSTNPPFVDWYLVLKVDENAGPDIIRKHYLRLALQLHPDKNKHPKADTAFKLVSEAYACLSDDARRTAFNLERHRNFCFKCSNISDDSPIPSNTKPKRIPTSERTRSNHALQRMKDLRARFMEEATIIENCLKANAASRVSDSSRKELPTFNPADYLSQGYPHRTTSNNKKLERSISRNYGLHILRTKP',\n '49390.A0A068TS31': 'MALARLALKNLQQRVAPASSSLPSFQCASERTVNSVQKRRWGSELLRRISSAAGKEDSAGQQVAVSEGGKKSNKLFPKKKQRSSLWKKEDDNFPPPLWEFFPSGLGNSLVQASENINRLLGNLSPSRLLGKFKEQDDLYKLRLPVPGLAKEDVKVTVDDGVLTIKGERKEEEEGSDDDDDEDDHWASFYGYYNTSVLLPDDAKVDEIRAEMKDGVLTVVIPRTERPKKDVKEISVH',\n '49390.A0A068TSW5': 'MAAEPAYTVASDSETTGEEKSSSPLSEISIGIDIGTSQCSIAVWNGSQVEVLKNTRNQKLMRSYVTFKSDFPSGGVSNQLAHEYDMLTGATIFNMKRLIGRLDTDSVVHASKNLPFLVQTLNIGVRPFIAALVNNMWRSTTPEEVLAIFLIELRAMAEVQLKRPVRNVVLTIPVSFSRFQLSRIERACAMAGLHVLRLMPEPTAVALLYAQQQQQAVHENMGSGSEKNALIFNMGAGYCDVAVTATAGGVSQIKALAGFTLGGEDMLQNIMHHLLPEMDNLFSSHGIEEIRKIGLLRVATQDAIHKLSFQPSVQINVDLGNGIQICKVLDRNEFEAVNQKVFEKCASLIGQCLREAKVEVEDVNDVILVGGCSYIPKIKSILTSVCKRGELYAEMNPLEAAVCGAALEGAVASGINDPFGSLDLLTIQATPLNIGIRADGNSFVPIVQRNTTMPARRELIFTTVHDNQTEALIIVYEGDETVEETNHLLGYFKITGIPPAPKGIPEINVCMDIDASNVLRVFAGVIMPGAQHPAAPFMEVRMPTVDDGHGWCAEALHRTYGSTLDLITVQKKVQK',\n '49390.A0A068TSY2': 'MRLNTKEGAKLTETKYRRSPGNYVLLILKLRALSSLYSCAPSPGHPSRHHHHPLPSNCRNKNLPLHPVINSPASNSHISSTKIMAGRAEAEPVNEQAVANVYGSMRAEMNQIYSKITELEMEVSEHSLVINAIQPLDPSRRCYRMIGGVLVERTVKEVLPAVQRNKEGLLEVIARLNEALEKKKKEIADFEAKYKIRIRKADEMKDEGGKKEGSAQGVLVGPAGGDE',\n '49390.A0A068TUK4': 'MGTTNSAVAAMEGGKPAIVTNAEGQRTMPSVVAYTKNGDRLVGQVAKRQAVVNLETSFSL',\n '49390.A0A068TUL0': 'MFGRAPKRSDNTKYYEVLGVSKNASQDDLKKAYRKAAIKNHPDKGGDPEKFKELAQAYEVLSDPEKREIYDQYGEDALKEGMGGGGGVHDPFDIFQSFFGGSPFGGGGSSRGRRQRRGEDVIHPLKVSLEDLYNGTSKKLSLSRNVLCPKCKGKGSKSGASMKCSGCQGSGMKVSIRQLGPSMIQQMQHPCNECKGTGETINDKDRCPQCKGEKVVQEKKVLEVVVEKGMQNGQKITFPGEADEAPDTVTGDIVFVLQQKEHPKFKRKHDDLFYEHTLSLTEALCGFQFILTHLDGRQLLIKSQPGEVLKPDQFKAINDEGMVVYQRPFMRGKLYIHFNVEFPDYLDPEQCKSLEAVLPPKTTKQITDMELDECEETTLHDVNIEDEMRRKQQAQEAYEEDEDMHGGAQRVQCAQQ',\n '49390.A0A068TUV5': 'MAEKRKREAPAPAVGIDLGTTYSCAGVWQHGRVEIIANDQGNRTTPSFVAFTNTGRFIGDAAKNQVDMNPTNTVFGAKRLIGRKYIDPSVQSDIKHWPFKVIPGLGNKPMIVVTYKGEEKLFATEEISAMVLAKMKETAEAYLGSTVKDAVVTVPAYFNDSQRQATKDAGVIAGLNVLRIINEPTAASIAYGLDTKSESTGEKNVFIFDLGGGTFDVSILTIEEGIFEVKATAGDTHLGGEDFDNTMVNHFVQEFRRKNNLDISGNPRALWRLKTACERAKRILSFSTKTEIEIDSLFQGIDFYSTISRAKFEELNKDFFTKCMELVQKYLCKSINPDEAVAYGAAVQAAVLSGGGLEKFQDFVLVDITPLSLSIELVGEVASVVVPKNTSIPTKLGKVFVTSKDNQTVVRFTVFEGESASTKDNNLLGSFNLSGIPPAPKGVEMFDVYFDIDANGILNVSAVHKTTGQKNHIIITNDRGRLSKEEIEKMVLAAEKYKFEEEMYKKKVEAKNALEIFAYRMKITIMNEKITAKLPPADKKKIENAIELAIQWLDDKKMIKKCVDDASKSVYVNKVKILMYNPNR',\n '49390.A0A068TVG9': 'MENKLPCSLEELYKGSKRKMQISRIVLDDYGKPVTVEEVLSIHIKPGWKKGTKITFPEKGNYELGRAPGDLIFVVDEKPHAVFKRDGNDLVMNQRISLLDALTGKTLSLTTLDGRELSIPVKDIVKPGHELRIPNEGMPISKEPGKKGNLRIKFDIKFPSRLSSEQKSELRRVLGRTAD',\n '49390.A0A068TVU9': 'MAEKRKREVPQLAPAVGIDLGTTYSCVGVWQHGRVEIIANDQGNRTTPSYVAFTDTGRLIGDAAKNQVDTNPTNTVFGAKRLIGRKYIDPSVQSDMKHWPFKVIPGSGNKPIIVVTYKGEEKQFATEEISATVLAKMKETAEAYLGSTVKDAVVTVPAYFNDSQRQATKDAGVIAGLNVLRIINEPTAASIGGTFDVSLLTIEEGIFEVKATAGDTHLGGEDFDNTMVNHFVQEFKRKNNMDISGNPRALWRLKTACERAKRILSFSPKTEIEIDSLFQGNDFYSTISRAKFEELNKDFFTKCMELVQKCLNDAKMDKSCIDDVVLVGGSTRIPKVQQLLQAFFHGKDLCKSINPDEAVAYGAADFVLVDITPLSLSIEVVGEIVAVVVPRNTTIPTKLEKVFATSKDNQTVVRFAVFEGESASSKDNNLLGSFNLSGIPPAPKGAEKFDVCFDIDANGILNVSAVHKTTRQKNHIIITNDRGRLSKEEIEKMVLAAEKYKKTIKLEKITAKLLLADRKKIENAIDQAIQWLDGQPHAEAVEFEEKMEELERICKPIPKMYKGAGRPDMACAMDNNTPSARSGSGRAPPKIETID',\n '49390.A0A068TVX0': 'MGVDYYKILQVDKSAKDEDLKKAYRKLAMKWHPDKNPNNKKEAEAKFKQISEAYEVLSDPEKRAIYDQYGEEGLKGQVPPPGAGGPGRATFFQTGDGPNVFRFNPRNANDIFDEFFGFSTPFGGMGGAGGMNGGGTRFPSSMFGDDIFSSFGEGRTMNSVPRKAPPIEQNLPCSLEELSKGTTKKMKISREIADASGKTLPVQEILTIDIKPGWKKGTKITFPEKGNEQPNVIPSDLVFIIDEKPHSVFKRDGNDLVVTQKISLAEALTGCTVHLTTLDGRKLTVPINAPIHPDYEEVVPREGMPIPKEPSKRGNLRIKFNIKFPTGLTAEQKSGIKKLLSP',\n '49390.A0A068TW76': 'MEFTSQEFMVGKCQGEKLVHGETMPLVLLPREASKNGFESLVEGLKKNKEWFEQLIIKNSAVLLRGFDVKNAEEFNEVVELFGWEDMRYVGPAPRTHVYKRIWTANEGPLSEFIYYHHEMVLIKESPSKVILFCETPPPEGGQTPFVPSFRVTERMLEEFPEMVEEIEKKGLKYTFTALSKNDTSSMRGRGWEDAFGTSDRAEAEKRTKLLGMDVEWLPNGGVKTLLGPRPLTRVFEGRKERRMWFNTMVGMYGKEHSSAMMADGTEIPENVVKRCEEIIEEESIQFKWEKGDILFLDNMATLHGRRPSLSPRRVLVTICK',\n '49390.A0A068TWQ3': 'MAPVLSRSVTSASVASLPYQKAPFSSVETKNSRVGVLGSAFLPRNGLRNSLLKSSGLKWKLERRESRVVVKCEGGAAVAEKEAPEVSGEIHDYQAEVSRLLDLIVHSLYSHKEVFLRELVSNASDALDKLRFLSVTEPGLLGDAGDLEIRIKPDPDNGTITIRDTGIGMTKDELIDCLGTIAQSGTSKFLKALKENKDVGADNSLIGQFGVGFYSAFLVAEKVVVSTKSPRSDKQYVWEAVADSSSYVIREETDPEKLLPRGTQITLHLKEDDKYEFSEPTRIQNLVKNYSQFVSFPIYVWLEKSRTVEVEEEEEPKEGEEKPEGEKPKKKKTTTEKYWDWELTNETKPIWMRSPKEVEKEQYQEFYKKTFNEFLDPLAHIHFTTEGEVEFRSILYIPGMAPLNNEEVINPKTKNIRLYVKRVFISDDFDGELFPRYLSFVKGMVDSDDLPLNVSREILQESRIVRIMKKRLVRKAFDMIQELSESENKEDYKKFWENFGKFLKLGCIEDSGNHKRITPLLRFFSSKSEEEPISLDDYVENMEENQKAIYYLATDSLKSAKTAPFVEKLVQKDIEVLYLIEPIDEVAIQNLQTYKEKKFVDISKEDLELGDEDEVKERETKQEYNLLCDWIKQQLGDQVAKVQVSKRLSSSPCVLVSGKFGWSANMERLMRAQTLGDTASLEFMRGRRILEINPEHPIIKDLNAACKNAPNSTDAKRVVELLYDTALISSGFTPDSPAELGNKIYEMMAMAVGGRWGRAEEGEAWAGEDSTESDASSSEASEAQVVEPSEVRTESDPWE',\n '49390.A0A068TXJ0': 'MAGKGEGPAIGIDLGTTYSCVGVWQHDRVEIIANDQGNRTTPSYVGFTDTERLIGDAAKNQVAMNPLNTVFDAKRLIGRRFSDSSVQSDMKLWPFKVIAGAGDKPMIVVNYKGEEKQFAAEEISSMVLNKMKEIAEAYLGTSIKNAVVTVPAYFNDSQRQATKDAGVISGLNVMRIINEPTAAAIAYGLDKKASSSGEKNVLIFDLGGGTFDVSLLTIEEGIFEVKATAGDTHLGGEDFDNRMVNHFVQEFKRKNKKDISGNPRALRRLRTACERAKRTLSSTAQTTIEIDSLYEGIDFYSTITRARFEELNMDLFRKCMEPVEKCLRDAKMDKSSVHDVVLVGGSTRIPKVQQLLQDFFNGKELCKSINPDEAVAYGAAVQAAILSGEGNEKVQDLLLLDVTPLSQGLETAGGVMTVLIPRNTTIPTKKEQVFSTYSDNQPGVLIQVYEGERTRTRDNNLLGKFELSGIPPAPRGVPQINVCFDIDANGILNVSAEDKTTGQKNKITITNDKGRLSKEEIEKMVQEAEKYKAEDEEHKKKVEAKNALENYAYNMRNTIKDEKISSKLPAADKKKIEDAIEGAIQWLDGNQLAEADEFEDKMKELESICNPIIAKMYQGAGGPDESGPKIEEVD',\n '49390.A0A068TXK3': 'MAGEGEVPAIGIDLGTTYSCVAVWQHDRRLIGDAAKNQVAMNPVNTVFALNGIKTVGPSVDIADAKRLIGRSFSDSCVQDDIKLWPFKVIRGPGDKPMIDAGVIAGLNVLRIIKEPTAAAIAYGLDKKSNCKGKINVLIFDLGGGTFDVSVLTIEEGFFEVKATAGDTHLGGEDFDNRMVDHFVQEFKRRHNKDISGSPRPLRRLRTACERAKRALSSAAQTSIEIDALFDGIDFQSTITRPRFEELNMDLFLKCIDPVKDCLRDAKMDKIEVHDVVLVGGSTRIPKDLVLVDVTPLSLGVQTIGEVMSVVIPRNTPIPARKERVFHTSSDNQTVVAFRVFEGERARSTDNYFLGKFELRGIPPAPKGVPKINVCFDLDANGILHVSAEDKFTGQKNQITITNDKGRLSKEQIERMVQEAMKFKYEDEQFKKKLSPAEKETIEDAIEASVEWLARNQHAETYEFEEKRSELESIWNPIILEIYRSADGGRVPMQDHPPFTGSGSPFTESGSSSGFGFKLEEVD',\n '49390.A0A068TXV8': 'MEGWKPTIVTNAEGQRTMPSVVAYTKNGDRLVGQIAKTGIDSSAISDEFKHKSAKHEQTKMPFNSGQICAQSHRKSSKYAFLIV',\n '49390.A0A068TZG2': 'MALFGDPFRRFFWSPTIYRTTPGSSALLDWIESPDAHIFKINVPGHKDEIKVQVEEGNVLVIKAEAKEEGGGRGKEKDVVWHVAERGGGITGKAAGFSREIELPEDVKADQIRASVENGVLTVVVPKDTTPKSSKVRNVNVTSKL',\n '49390.A0A068TZK0': 'MARRLIPTLNRVLIEKLVQPSKTTAGILLPEKSAKLNSGKVVAVGPGLKDKAGNTIPVAVKEGDTVLLPEYGGTQVKLGEKEYHLYRDEDILGILHD',\n '49390.A0A068TZS7': 'MKFSSVLLLICFLASIFIFSGFAADSLDAYKSITGRKHLNGLNPPRTPGKRSLLSDSKEADTALVAALDGTIFLLELDSMKPLWSFESGSEIYSSYQAPVDEDKENTSGLGSDYYIDLGDDWELYAHNRLGKLKLTKTLEEYISSTPQIAEDGGIVLGSKKTTAFLVDAKTGRLIYTYRTPESSCPKQNNSENTVIHNSTVEGLGLSQSTDLKADELPLYITRTDYALTSFAPNSNKVLWNMTVAEIGAAFLCEEMERSFGRAILNSGFSEPGFNMPLPCQSMALVYRFRNHDMLEPFLRHGGLPEAHSPEIMLPTSIPKPMLPSQPNVDKVLEFLPSQQNVGKSLDSHDISGEEFVLSLPSVTEDGEMRNVQELKISPGGRLSVVLERIGAISSFPFAVTVGIVIYHLVARKFMLVDNPSNTSSGTVPSKRKKSRKSGKSGSSVEKKDIDTHPNGDSANMDDDDDKNMWLNLSQPTFNIEGRRIGKLFVTTKEIAKGSNGTVVLEGIYEGRPVAVKRLVRAHHDVAFKEIQNLIASDRHPNIVRWYGVEQDQDFVYLALERCICSLDDLIHMFSDISGNLSFSKNLDVEDMAKYQIHLDSVKVVIQDPRLWKSNGYPSPILLKLLRDVISGLVHLHELGIIHRDLKPQNVLIIKDRSLCAKLSDMGISKRLTGDMASLGCGSSGWQAPEQLLLGRQTRAVDLFSLGCVLFFCITGGRHPFGNRLERDVNITKNQVDLFLVEHIPEAMDLFSHLLNPNAEMRPKAVEVLAHPLFWSADLRLSFLRDTSDRVELEDRETDSELLKAIEATAPIALGGKWDEKLEPAFLYNIGCYRRYKYDSVRDLLRVMRNKLNHYRELPMEIQEILGSVPEGYDEYFASRFPKLLIEVYRVMSMYCKEEECFIKYFKCSMQ',\n '49390.A0A068U059': 'MSLLCSPSRSVFQLPQNFSGEAFLPPTSNSSFRRPRAGVVSAAYASYATAESERTTSTCVLPPRLTAPTSFYEVLGIPMGATSGEIKAAYRRLAKGCHPDLAGTDEKSSSADEFIKVHAAYSTLSDPEKRADYDRRLFRSLRGVRLYSTPSPTKSRYSGYSGRNWETDQCW',\n '49390.A0A068U2B6': 'MVGFLSNKISRDELKPGDHIYTWRHGYLYSHHGIYVGDERVIHFTRSAEHEIGTGTVLDRVIFSSSPSNSSDTPCPRCGDQSKASGVISSCLECFLYGDELYRFEYGVSPVVFLARVRGGTCTLAASDPAEHVIHRAEFLLQNGFGGYNIFKNNCEDFAIYCKTGLLVFTSVSLGRSGQATSFVAAVTAIVSSPLRFMTTSFPGLAAVGCSLYCLSRFVSDIGIRRDVTKIPVERLVSRSGLDGSDPESETCSTSASETTKED',\n '49390.A0A068U2I0': 'MATSILLRSALRRPELHTSALAASRSLVGNVRASPATSPLSRMLTSLRYFSSRPLADDVIGIDLGTTNSCVALMEGKTARVIENAEGTRTTPSVVAFSQKGDLLVGATAKRQAVTNPQNTLFATKRYIGRRFDDPQTQKELKMVPYKIVRAPNGDAWVEANGQTYSPSQVGAFILTKMKETAESYLNKSVNRAVITVPAYFNDAQRQATKDAGRIAGLTVERIINEPTAAALSYGVNNKEGTIAVFDLGGGTFDISILEISNGVFEVKATNGDTFLGGEDFDNTMLEFLVSEFKKAERIDLSKDKLALQRLREAAEKAKIELSSTSQTEINLPFITADASGAKHFNVTLTRSKFETLVYHLIERTKAPCISCLKDAGVSTTDIDEILLVGGMTRVPKVQQVVAEIFGKSPSKGVNPDEAVAMGAAIQGGILRGDVKDLLLLDVTPLSLGLETMGGIFTRLINRNTTIPTKKSQVFSTAADNQTQVDIKVLQGEREFAADNKLLGEFNLEGIPPAPRGNPQIEVTFDIDANGIVTVSAKDKTTGKEQQITIRSSGGLSEDEIQKMVKEAELHSQKDLEKKELIDQRNSAETTIYSIEKSLTEFRDKVPAEVVTQIQSAVSDLRKAMDGENVDEIKAKMEAANKAVSKIGEHMAGGSGGNTSGGSDPQGGDEAQETEYQEVRK',\n '49390.A0A068U2R7': 'MSLRVLNPNAEVLNKSAALHMNINAAKGLQDVLKTNLGPKGTIKMLVGGAGDIKLTKDGNTLLKEMQIQNPTAIMIARTAVAQDDIAGDGTTSTVLFIGELMKQSERHIDDGTHPRILVDSIEIAKRATLQFLEKFKTPVVVGDEPDKEILKMVARTTLRTKLYEALADQLTDIVVNAVLCIRKPEEAIDLFMVEIMHMRHKFDVDTRLVEGLVLDHGSRHPDMKRRAENCYILTCNVSLEYEKSEVNAGFFYSNAEQREAMVAAERRSVDERVQKIIDLKNKVCADNEHNFVVINQKGIDPPSLDLLARAGIIALRRAKRRNMERLVLACGGEAVNSVDGLTPDCLGWAGLVYEHILGEEKYTFIEKVKNPHSCTILIKGPNDHTIAQIKDAVRDGLRAVKNTIEDEAVVLGAGAFEVAARQYLVNEVMKTAQGRAKLGVEAFADALLVVPKTLAENSGLDTQDVIIALTGEHDKGNIVGLNHHTGEPIDPQMEGIFDNYSVKRQIINSGPVIASQLLLVDEVIRAGRNMRKPN',\n '49390.A0A068U3B4': 'MATAQLTASTISAKGFVSFEGLRASSTTVKASTFAPLRQNGLSTRSFRGLVVKAAAVVAPKYTSLKPLGDRVLVKIKVPEEKSVGGILLPTSAQTKPQGGEVVAVGEGRTIGKSKVDISVKTGTQIVYSKYAGTEVEFNGSNHLILKEDDIVGILDTDDVKDMKPLNDRVLIKVAEAEEKTAGGLLLTEATKERPSIGTVIAVGPGPLDEEGNRKALSVSPGNTVLYSKYAGNDFKGSDDSDYIALRASDVMAVLS',\n '49390.A0A068U3E9': 'MATKEGKAIGIDLGTTYSCVGVWLNDRVEIITNDQGNRTTPSYVAFTDTERLIGDAAKNQVAMNPHNTVFDAKRLIGRRYSDPSVQADMKLWPFRVVPGPGDKPLIVVTYKGEEKRFAPEEISSMVLTKMREIAESFLGHKVNNAVVTVPAYFNDSQRQATKDAGSIAGLNVMRIINEPTAAAIAYGLDKKHQKRGEQNVLVFDLGGGTFDVSLLTIEEGIFEVKATAGDTHLGGEDFDNRLVNHFVSEFRRKHKKDISGNARALRRLRTACERAKRTLSSTTQTTIEVDSLYEGIDFYATITRARFEELCMDLFLKCMEPVEKVLRDAKIDKSKVDEVVLVGGSTRIQKVQQLLQDFFNGKELCKSINPDEAVAYGAAVQAAILTGEGDSKVQDLLLLDVTPLSLGLETAGGVMTVLIPRNTTIPSKKEQIFSTYSDNQPGVLIQVYEGERARTKDNNLLGKFELSGIPPAPRGVPQINVAFDIDANGILNVTAEDKTAGVKNQITITNDKGRLSKEDIEKMVRDAEKYKSEDEEVKKKVEAKNALENYAYNMRNTVRDEKFDSKLKPDDKQKIEKAVEETIEWLDRNQLAEVDELEDKLKELENICNPIIAQMYQGGGGGGGPMGDDMHGGGGGGGGGSTDGTGAGPKIEEVD',\n '49390.A0A068U6M9': 'MAGSSHGNSCLLLLLLLAFLLLLCSSFFSTSLAEIIFEERFEDGWQSRWVKSDWKKSEGKAGSFKHTAGKWPGDPDDKGIQTSTDARHFAISAKIPEFSNKNRTLVLQYSIRLEQDIECGGGYIKLLSGFVNQKKFGGDTPYSVMFGPDLCGTQTKKLHVIYSYQGQNYPIKKDLQCETDKFTHFYTFILRPDATYSVLIDGRERDSGSLYTDWDILPPRKIKAVNAKKPADWDDREYIEDPNDVKPKGYDSIPREIPDPNAVKPDHWDEEEDGIWKPPKIPNPAYKGPWKRKKIKNPNYKGKWKIPWIDNPEFEDDPDLYVLKPIKYVGIEVWQVKAGSVYDNILICDDPEYAKEVVQEVLSNREVEKEAFEEAEKIRKAKEEEEAQRAREEGERRRRERGHDRRKDRYIDRYRRHDRHDYDDYHDEL',\n '49390.A0A068U6U9': 'MNAEVISSGHLQLFPTSSNTRHCGSQLPFSGRASTGSIALKPRRRPGPLRITARAAVYAPTQTQAETFYDMLGISETGSISDIKKAYKQLARKYHPDVSPADRTEEYTKRFIEVQEAYETLSDPQTRALYDMNLGRGLHFAFSTGRRNERMDDVEEWKLRWQSQLDELRLWSMHRDNVSSAVRGKAAASPSSSWGSRMRRKRTDIYDLGFR',\n '49390.A0A068U861': 'MEYSTFYPSTWNSNLTESLLYPYHFIPENYVHWTETPESHIYSADLPGVKKEQIRVEVEDSRYLIIRTEAATGESTVPAKNFIRKFRLPERVDISGISAGYENGVLTVEVPKSFVRRGFFIEPADMPERMHVLARAA',\n '49390.A0A068U8U4': 'MPGPVVEELDVDKKLQGDEPVVEDVKDEDDHEDDADDSDDEDDDKEDGAQGTNESSKQSRSEKKSRKAMLKLGMKPVTGVTRVTIKRTKNILFFISKPDVFKSPNSDTYVIFGEAKIEDLSSQLQTQAAQQFRMPDMGSVMAKSDISASGAAVQADEEEEEIDETGVEPRDIDLVMTQAGVTRCRAVKALKAHDGDIVSAIMELTT',\n '49390.A0A068U8Z8': 'MAGAWARRASLIVFGILFFGSFFAFSIAKEEAAKLGTVIGIDLGTTYSCVGVYKNGHVEIIANDQGNRITPSWVGFTDGERLIGEAAKNQAAVNPERTIFDVKRLIGRKFEDKEVQKDMKLVPYKIVNKDGKPYIEVKIKDGEKKVFSPEEISAMVLTKMKETAEAYLGKPIKDAVVTVPAYFNDAQRQATKDAGIIAGLNVARIINEPTAAAIAYGLDKKGGEKNILVFDLGGGTFDVSILTIDNGVFEVLATNGDTHLGGEDFDQRVMEYFIKLIKKKHGKDISKDNRALGKLRRESERAKRALSSQHQVRVEIESLFDGVDFSEPLTRARFEELNNDLFRKTMGPVKKAMEDAGLEKHQIDEIVLVGGSTRIPKVQQLLKDYFDGKEPNKGVNPDEAVAYGAAVQGGILSGEGGDETKDILLLDVAPLTMGIETVGGVMTKLIPRNTVIPTKKSQVFTTYQDQQTTVTIQVFEGERSLTKDCRLLGKFDLTGIPPAPRGTPQIEVTFEVDANGILNVKAEDKASGKSEKITITNDKGRLSQEEIERMVREAEEFAEEDRKVKEKIDARNSLETYVYNMRNQINDKDKLADKLESDEKEKIETATKEALDWLDDNQNAEKEDYEEKLKEVEAVCNPIVTAVYQRSGGAPGAGSEEEDESHDEL',\n '49390.A0A068U922': 'MAAALRSKSSREAASLAGSQFRYFILSYMHEGRVSSYQWNSRSKWDNNFFRNPRCNFNFVLAPFKPFSLRGDFVDKVNSNEKNHLNSSKVINNENKVEISSSYGDPPEVWQPPGGIVVRPGAKFVQAGEGEGPGTVSGGGSGSGSKDGCWGGSNLGPNFPTPKEICKGLDKFVIGQDRAKKVLSVAVYNHYKRIYNDSSEKWPAGDSGSNKVDTADIESVELEKSNILLMGPTGSGKTLLAKTLARLVNVPFVIADATTLTQASLIIRCRCEAVKFLVLFSHIRTLHTRVTCCAFGFSSFCH',\n '49390.A0A068U979': 'MQLLQAGYVGEDVESILYKLLTVADYNVAAAQQGIVYIDEVDKITKKAESLNISRDVSGEGVQQALLKMLEGTIVNVPEKGARKHPRGDNIQIDTKDILFICGGAFVDLDKTISERRQDSSIGFGAPVRANMRTGGVTTAAVTSSLLETVESSDLIAYGLIPEFVGRFPILVSLSALTENQLVQVLTEPRNALGKQYKKMFQMNGVKLHFTEVALRLIARKAITKNTGARGLRSLLESILMDSMYEIPDVRTGNEIIDAVVVNGESVGHEGRGSGAKILYGKGALDRYISQLKFKDRETTAEGSDGEPEVEQELPSIAAL',\n '49390.A0A068U9F8': 'MADVQMGEAETFAFQAEINQLLSLIINTFYSNKEIFLRELISNASDALDKIRFESLTDKSKLDAQPELFIRLVPDKVNKTLSIIDSGVGMTKADLVNNLGTIARSGTKEFMEALQAGADVSMIGQFGVGFYSAYLVAEKVIVTTKHNDDEQYIWESQAGGSFTVTRDTSGEQLGRGTKITLFLKDDQLEYLEERRIKDLVKKHSEFISYPIYLWTEKTIEKEISDDEEDEPKKEEEGDVEDVDEDKEETKDKKKKKIKEVSHEWQLINKQKPIWLRKPEEITKDEYASFYKSLTNDWEDHLAVKHFSVEGQLEFKAILFVPKRAPFDLFDSRKKPNNIKLYVRRVFIMDNCEELIPEYLSFVKGVVDSDDLPLNISREMLQQNKILKVIRKNLVKKCIEMFNEIAENKEDYNKFYEAFSKNLKLGIHEDSQNRAKLADLLRYYSTKSGDELTSLKDYVTRMKEGQKDIYYITGESKKAVENSPFLERLKKKGYEVLFMVDTIDEYAVGQLKEYDGKKLVSATKEGLKLDDDSEEENKKKEEKKKSFEDLCKVIKDILGDKVEKVVVSDRIVDSPCCLVTGEYGWTANMERIMKAQALRDTSMSSYMSSKKTMEINPDNGIMEELRKRAEADKNDKSVKDLVLLLFETALLTSGFSLDDPNTFAARIHRMLKLGLSIEESDDAGDDADMPALEEDGDEESKMEEVD',\n '49390.A0A068U9H0': 'MATMLQPQIILLKEGTDTSQGKPQLLSNINACTAVADVVRSTLGPRGMDKLIHDEKGNTTISNDGATIMKLLDIIHPAAKILVDIAKSQDSEVGDGTTTVVLLAAEFLKEAKPFIEDGVHPQNLIRSYRTAGHLAIEKVKELAVSIEGKSLEEKKSLLANCAATSLSSKLIGGEKDFFASMVVDAVLAIGNDDRLNMIGIKKVPGGNMRDSFLVNGVAFKKTFSYAGFEQQPKKFVNPKILLLNIELELKSEKENAEIRLSDPSQYQSIVDAEWNIIYDKLDKCVKSGAKIILSRLAIGDLATQYFADRDVFCAGRVTEEDLHRVAAATGGTIQTTVNNVIDEVLGSCEIFEEKQVGNERFNIFSGCPSGQTATIVLRGGADQFIEEAERSLHDAIMIVRRAVKNSTVVAGGGAIDMEISRYLRQHARTIAGKSQLFINSYAKALEIIPRQLCDNAGFDATDVLNKLRQKHALPSGEGALYGVDINTGGIADSFANFVWEPSVVKINAINAATEAACLILSVDETVKNPKSESAQGDAAASAMGRGRGGAAFRGRGRGMRRR',\n '49390.A0A068UA30': 'MAASLALKRLVSSTLLSRSVNSLRPAASAASSRLFNTNVARDYDDDDDERGLDVDRRSNCPLYNRRDYSPYFGVFDPFSTRSVSQLLDLVNQFSEPTFASGVRRGWDIKETAEGLNLSLDMPGLGKEDVKVSVEQNTLIIKGEGQKESEDAERGRRFSSRLDLPEKTYKTDGIKAEMKNGVLKVFIPRVKEEERSDVFHVNVQ',\n '49390.A0A068UBQ0': 'MEGGKPTIVTNAEGQRTMPFVVAYTKNGDRLVGQITKRQAHYNKNNL',\n '49390.A0A068UCA8': 'MAEKLAPEKRHSFTHNGQKVFEWDQTLEEVNIYIPLPANVPKKLFYSKIESKHLEVGIKGNPPYLNHDLTNPVKTDCSFWTLEDDTMHITLQKRDIGQTWPSPIMGQGQLDPYATDMEQKRLMLQRFQEENPGFDFSQAQFSGSCPDPRTFMGGIRSS',\n '49390.A0A068UDA4': 'MALIPKLFGDMLAPSGLSDETKGIVNARVDWKETPEAHVFKVDLPGLKKEEVKVEVEDGRVLAISGERAAEKEDKNDKWHRVERSRGRFTRKFLLPENAKVEEVKANMEYGVLTVTIPKQEVKKPEVRAIEISG',\n '49390.A0A068UDH3': 'MSLMPVFGGRRSVYNNPFSGDGWDAPVNNHQPVHQKQYHGESGVTAWAPPVHGASSHHAVQAPSSFASATVDWRETPEAYIFKTELPPGVRREDVRVELEDNKILKISCEKYTEKEDRHDQNYYHHVIERSRCKFLTAFGLPQDSRVDQIRSTIENGVLTVRVPRWEPMHHSHHHVIPVEIL',\n '49390.A0A068UED5': 'MEGGKPTIVTNPEGQRTMPSVVAYTKNGDRLVGQIAKRQVVVNLENKFFSVKRFVGRKMSEMDEESKQVSYKAVRDENNN',\n '49390.A0A068UEW5': 'MQQAGSSGSETEVTWEDQQKINQFSRLNNRFHELEDEIKLAKETNDNLEDASNELILTDDDIVRFQIGEVFAHIAKDGVETRIEQMKEVTSKNLEKLEEEKESIVAQMDELKKILYGKFKDSINLEED',\n '49390.A0A068UF36': 'MAKRLIPLLNRVLVEKVIPPAKTNAGILLPEKTAKLNMGKVVAVGPGYHDSQGKLIPVTVKEGDNVLLPEYGGTQVKLGEKEYHLYRDDDILGTLHD',\n '49390.A0A068UFS1': 'MGVDYYKILQVDRNAKEDDLKRAYRKLAMKWHPDKNPNNKKDAEAKFKQISEAYDVLSDPQKRAVYDQYGEEGLKGQVPPPSAYASTSDGGGPTMFRFNPRNPDDIFSEFFGFSSPFGGMGGMGDMGGPRSAGSSFSRGMFSDDIFASFRSATTEGSSGSVPRKAAAIERTLPCSLEDLYKGTTKKMKISRDVNDANGRPTTMEEILSIEIRPGWKKGTKITFPEKGNEQRGFIPSDLVFIVDEKPHIVFKRDGNDLVITQKISLVEALTGYTAQMTTLDGRSLAIPINSIISPTYEEVIKGEGMPIPKEPSKKGNLRIKFNIKFPTKLTSEQKTGIKRLLTSPGAST',\n '49390.A0A068UG80': 'MRGISVRLVFLVILLVLVVVSSLVVVVASGPPSSSRSSDLDDDSDIPASHLPLPLTSKHDTAVVAAPDGTIYLVEINSGKVLWSFASGFPIYSSYQAVHHNEGQRNNATTGADDFFIDIGEDWQLYVNGNGLKNVKLPVSVEEFLKSTPFISASGGIMLGSKKSTIFIVDAKTGKVIHTLCSDTVRAVEHEHSDESTLVARTDFGGWVPHSATNLDGIEEPLYVTRKDYVLKFTNMKTGKILWYLMFADIEASYQCNAIESFLGSVFYTEDEVSLRKNLDAKLQLHCPPKPVVYRIRDRSSFKSLFKTNSLPDAFAGDKVLLLAAPDLDPMLQLVEKILGLHQSNGGDIGLALPTPESEDFGVVALPEGDIDQIHEIGGFANLIGSHFWFVALFGGLMLLIVTFFFIHLVVKEQGKLNKGVEMPNIQALTTRKKKPRKPRTNSKTAERKKKNVSHDQMAKDINVLPDYERAKKFLQLGLPNNSDGFMDGRNIGRLFVSTTEIAMGSNGTVVLEGIYDGRPVAVKRLVQTHHNVAFKEIQNLIASDHHPNIVRWFGVEFDQDFVYLALERCACSLYDLILPCSSSQNQETYQDGDFNCAGNEFVRLGLLGDNHALQLSKLNGYPSHHLLKLMRDVVRGLAHLHELGIIHRDLKPQNVLVTKERVLCAKLSDMGISKRLSGDTSSLTKHATGYGSSGWQAPEQLRHERQTRAVDLFSLGCLLFFCITGGKHPFGEILERDVNIVNNQKDLFLIENLPEATDLIASLLHCNPELRPKATQVACHPLFWDSEMRLSFLRDASDRVELEDREKESELLKALESIGNVALGGKWDEKMDTAFINDIGRYRRYKFDSVRDLLRVIRNKLNHYRELPKDIQGILGQVPEGFDNYFSTRFPKLVIEVFKVFHLYCAEEEEAFIKYFKCDYM',\n '49390.A0A068UGP7': 'MRKWTVPAVLFLLCLLFLLPDQGRKIHANAEVDADAPVDPPKVEEKIGAVPNGLSTDSDVVKREAESMSRRTLRATAEKFEFQAEVSRLMDIIINSLYSNKDIFLRELISNASDALDKIRFLSLTDKEILGEGDTAKLEIQIKLDKEKKILSIRDRGIGMTKEDLVKNLGTIAKSGTSAFVEKMQTSGDLNLIGQFGVGFYSVYLVADYVEVISKHNDDKQYVWESNADGAFAISEDVWNEPLGRGTEIRLHFRDEAQEYLNESKLKELVKKYSEFINFPIYLWASKEVDVEVPADEEDSSDEDEKPESSSSEEEEEDTEKEEDEKKPKTKKAKETTYEWELLNDVKAIWLRNPKEVTDEEYTKFYHSLAKDFSEEKPLAWSHFTAEGDVEFKAVLFVPPKAPHDLYESYYNTNKSNLKLYVRRVFISDEFDELLPKYLSFLKGLVDSDTLPLNVSREMLQQHSSLRTIKKKLIRKALDMIRKIAEEDPDEANDKEKKDVDESNESDEKKGQYTKFWNEFGKSIKLGIIEDAANRNRLAKLLRFETTKSDGKLTSLDQYISRMKPGQKDIFYITGTSKEQLEKSPFLERLTKKNYEVIFFTDPVDEYLMQYLMDYEDKKFQNVSKEGLKIGKDSKDKELKESFKDLTKWWKGTLASENVDDVKISNRLANTPCVVVTSKYGWSANMERIMQSQTLSDSSKQAYMRGKRVLEINPRHPIIKELRERVVKDPEGESVKQTAHLMYQTALMESGFMLNDPKDFASRIYDSVKSSLHISPDAAIEEEEDAEEAEVESSTKEGSGEDAEEAEPSSVKDEL',\n '49390.A0A068UHQ8': 'MVRSNGLRLVRRFALRSLASHLLHGSSSSLNEALLRGGYRSFSTAFCNQNRVFRFSNSRNVNDGRERLRLGSLVANLGAARSIHATATTSGDYYDVLGVSRNATPSEIKKAYYGLAKNLHPDTNKSDPGAAAKFQEVQEAYEVLKDEKKRAEYDEVGHDAFKINRQNGGAGYDPFQEGGFNPFQEFFHGFDFMRKNMGGEDVKVSIELSFMEAVQGCSKTISFQTEIPCNTCGGAGVPPGTRPETCPLCRGSGTAKFHGGNVFFQMNCRKCGGSGKIVSDVCKSCKGERVVKGTKTVKLDIKPGVDNDQTMKVYGSGGADPEGNQSGDLYVTIKVREDPVFRREGADIHVDAVLSITQAILGGTIQVPTLTGDVVLKVRPGTQPGQKVVLKRKGIKTSNSFSFGDQFVHFNVSIPANLTQRQRRLIEEFAKEEQGEYDKGAAAGASG',\n '49390.A0A068UHU0': 'MEASLQISKISTLSGKMVQFNPKGSSKEKFLQHRTMFRCQADRTLQNGRAANFYEVLSLDCSKSVGFNEIRKAYRCKALKLHPDACPPTEKEESTRRFLELRMAYKTLSDPISRELYDLELSLVKVDGRTRHGMSRSMGNKVWERQIAELNKRSMQKMEKRKKMGI',\n '49390.A0A068UI14': 'MEASLQSSGISTRFGKTVQFNQKGSGKEKFLQHRTVISCQAARTVQTGRAANFYEVLSLDCSKFVGLQEIKKAYRCKALKFHPDACPPSEKEESTRRFLELRMAYETLSDPISRELYDHELSLVDVDGRTRHGMSCSMGSQVWERQIAELNKRSRQKMEKRKEMGMWN',\n '49390.A0A068UIC6': 'MASSIGSTFAGAAPSCARFKHHLHQPSRISAAHAAAGRTSTSTSHIAPQTSLYEVLGIPMGATCQEIKVAYRRLARVLHPDVASSHNTTRGSQDTSAAADEFMRVHKAYTTLSDPEKRADYDRTLFRLRRPAYVLSATNRGSGYYARRTWETDQCW',\n '49390.A0A068UIK8': 'MEASLQISRISTRFGKTVQFNQKGSCKEKFLQHRTVISCQAARTVQTGRAANFYEVLSLDCSKFVGLQEIKKAYRCKALKFHPDSCPPSEKEESTRRFLELRMAYETLSDPISRELYDHELSLVDVDGRTRRGMSCSMGSKVWERQIAELNKRSRQKMEKRKEMGMWN',\n '49390.A0A068UIR8': 'MEASLQISGISTRFGKTVQFNQKGSCKEKFLQHRTVISCQAARTVQTGKAANFYEVLSLDCSKFVGLDEIKKAYRCKALKFHPDACPPSEKEESTRRFLELRMAYETLSDPISRELYDHELSLVDVDGRTRRGMSCFMGNKVWERQIAELNKRSRQKMEKRKEMGMWN',\n '49390.A0A068UJ52': 'MDLRNLGMDIGGMGFGIDNPILSTIQDMLELSEEHDKGNQNNPSRAYVRDAKAMARTPADIKEYPDSYALVVDMPGIKANEIKVQVEDDNVLVVSGERKREKEEGVKYLKMERRGGKSMRKFVLPENANLDAISAVSRDGVLTVAVQKFPPPQAKKHKTIEVKAG',\n '49390.A0A068UJS0': 'MAAAPTASASTAYLCSYASPHRPSLPSSSSNYFQTHFPLKPISSRGFCFCLPKNANIPVINNNSSRRCRFLKASQSQSEDSASETDDEDETPLSKTEEEADQELPSRLESTISAYKEAILNGDEKSISDFEEIIHMVEKERNELLEKVSVLSDEIGAQKDKYVRLQADFDNFRKRTENEKLTIRSNAQGEVIESLLPMVDNFERAKQHMKLETEQEKKIDASYQGIYKQFVEIMKNLGVSVVPTVGTLFDPVLHEAIAQEESEEFKEGVIIEEFRRGFLLVDRLLRPAMVKVSSGPGVRQPSSAASEQSEQPATAGVEEIEFSEQSTG',\n '49390.A0A068UK32': 'MASSTALREQFLSPPVPFLSNPNLLLHIAKNHQVRKKYTIQLGENELVLKELELLNEDANVFKLIGPVLVKQDLAEARANVRKRIDYISAELKRLDATLQDLEDKQKSKQETVFKLQQKVQSFQAGKGKA',\n '49390.A0A068UKG2': 'MAGKGDGPAIGIDLGTTYSCVGVWQHDRVEIIANDQGNRTTPSYVAFTDSERLIGDAAKNQVAMNPTNTVFDAKRLIGRRLSDSSVQNDIKLWPFKVIAGPGDKPMIAVNYKGEEKQFAAEEISSMVLIKMKEVAEAYLGTTIKNAVVTVPAYFNDSQRQATKDAGVIAGLNVMRIINEPTAAAIAYGLDKKATSAGEKNVLIFDLGGGTFDVSLLTIEEGIFEVKATAGDTHLGGEDFDNRMVNHFVQEFKRKNKKDISGSPRALRRLRTACERAKRTLSSTAQTTIEIDSLYEGIDFYTTITRARFEELNMDLFRKCMEPVEKCLRDAKMDKSSVHDAVLVGGSTRIPKVQQLLQDFFNGKELCKSINPDEAVAYGAAVQAAILSGEGNEKVQDLLLLDVTPLSLGLETAGGVMTVLIPRNTTIPTKKEQVFSTYSDNQPGVLIQVYEGERTRTKDNNLLGKFELSGIPPAPRGVPQITVCFDMDANGILNISAEDKTTGQKNKITITNDKGRLSKEEIERMVQEAEKYKSEDEEHQKKVDTKNALENYAYNMRNTIRDEKISAKLEPTDKKKIEDAVEEAIKWLDSNQLAEADEFEDKMKELESLCNPIIAKMYQGGADGGMGGAMDEDGPSVGGGSGAGPKIEEVD',\n '49390.A0A068UKG5': 'MAGKGEGPAIGIDLGTTYSCVGVWQHDRVEIIANDQGNRTTPSYVAFTDTERLIGDAAKNQVAMNPTNTVFDAKRLIGRRFSDASVQSDIKLWPFKVIPGPGDKPMIIVNYKGEEKQFAAEEVSSMVLTKMKEIAEAYLGSTVKNAVVTVPAYFNDSQRQATKDAGVISGLNVMRIINEPTAAAIAYGLDKKATSAGEKNVLIFDLGGGTFDVSLLTIEEGIFEVKATAGDTHLGGEDFDNRMVNHFVQEFKRKNKKDISGNPRALRRLRTACERAKRTLSSTAQTTIEIDSLFEGIDFYSTITRARFEELNMDLFRKCMEPVEKCLRDAKMDKSTVHDVVLVGGSTRIPKVQQLLQDFFNGKELCKSINPDEAVAYGAAVQAAILSGEGNEKVQDLLLLDVTPLSLGLETAGGVMTVLIPRNTTIPTKKEQVFSTYSDNQPGVLIQVYEGERTRTRDNNLLGKFELSGIPPAPRGVPQITVCFDIDANGILNVSAEDKTTGQKNKITITNDKGRLSKDEIEKMVQEAEKYKAEDEEHKKKVEAKNALENYAYNMRNTVKDEKIGSKLSPADKKKIEDAIDQAISWLDSNQLAEADEFEDKMKELESICNPIIAKMYQGAGGDMGGGAMDDDAPSGGSSGAGPKIEEVD',\n '49390.A0A068UKH3': 'MEASLQISKISTLSGKMVQFNQKGSCKEKFLQHRTMIRCQADRTMQNGRAANFYEVLSLDCSKSVGLDEIKKAYRCKALKFHPDACPPTEKEESTR',\n '49390.A0A068UKL9': 'MRPWIVLTRACKDLHIFLARALLKLSPPNPDDLGYVDSISVDEIGGVKVTIVRNEEGGNSVSTVVLRGSSILDDLDRAVDDGVNAYKAMCRDSQIVPDAAAAEIELARRLKEFSFKETGLDQYAISRFAESFEMVPKTLAKKAGLNAMEIIASLYAEPASGNTGVDIGLEEGVCKDVSTTSVWDPYTIKFFSLKYATNAVCTVLRVDRIIIAKPAGGLKRDPPVEMDGWMDG',\n '49390.A0A068UKM4': 'MDLDPSTIYAINEVAIFAGAVDTTATETKGTALIHRAQQLENYAKIGAAKVGELIKAIAGSGAKVIVSGAAVGKMALHFCERYKLMVLMISSKFELQRFCHITGAVALLKLSSPNPDDLEYVDSISVDEIGGVKVTIVRNEEGGNSVSTVVLRGSSILDDLERAVDDGVNTYKAICRDSQIVPGAAATEIELARRLKEFSFKETGLDQYAISRFAESFEMVPKTLAKKAGLNAMEIIASLYAEPASGNTGVDIGLEEGVCKDVSTTSGFDSIDRFFALKYAADAVCTVMRVDRIIIAKPAGGLKRDPPMEMDGWMDG',\n '49390.A0A068UKV4': 'MHGFAPSLTPFRNFLAVKPLLFSEAQSKFLVPDCSKFIVIKQPGFSHTLSCRNYYCYGERRNKRCASVRASRRESPYEVLGVSPSATPNDIKRAYRKLALKYHPDVNKEANAQERFMRIKHAYNTLLNKSDRRFDKGNRGSESSYSTAGRNDNWTVNNDEEFYGFGNFLRDVQISIEDFFKDLQEEFRNWEAGADSQGKPKSLWEELAEIGEEFVEFLEKELNISDVEAEQTKGNQQQWGNASYGSKETGNVNQNGADNSGIEENINDIEAALAQLKKELGL',\n '49390.A0A068UKZ1': 'MSLIPSFFGNRRSSIFDPFPSDVWDPFRDISLPSSFVGETSSFVNARVDWKETPEAHVFKADLPGIKKEEVKVEVEDDRVLQIRGERNVEKEDKNDTWHRVERSSGQFMRRFRLPENAKMDQIKAAMENGVLTITIPKEEAKKTDVRAIQISG',\n '49390.A0A068UL97': 'MSEIQEILMIRSHEIAIAELNSLSSSRGVYQRNGNILFRTTIQKAIALEQKQLDVAKVKVQQLSD',\n '49390.A0A068ULW4': 'MFGRAPRRSNNSKYYEVLGVSKSASQDELKKAYRKAAIKNHPDKGGDPEKFKELAQAYEVLSDPEKRELYDQYGEDALKEGMGGGGVHDPFDIFESFFSPLHRRDGFRGRKKQGEDVVHTLKVSLDDLYKGTSKKLSLSRNKLCPKCKGKGSKSGASGRCYGCQGSGMRVTTRQIAPGMIQQMQHMCPECKGSGEVISERDRCTQCKGNKVVQEKKVLEVHVEKGMKHGQKIVYPGEADEAPDTVTGDIVFVLQQKEHPKFKRKFDDLYVEQSLSLTEALCGFQFVLTHLDGRQLLVKSNPGEVVKPDQYKAINDEGMPHYQRPFMKGRLFIHFNVEFPESGALPSEKCQVLKAMLPSGSLKQSSDMDLDECEETTLHDVNIEEEMRQKQHQRHQEAYDEDDDDEPTMHRMPCNQQ',\n '49390.A0A068UM55': 'MASTLVTLAAKPFTSQNTNLQFLPTQRPRVLPRNNSLRVSAIAKKFEPTKVVPQADRVLIRLEELPQKSAGGVLLPKSAVKFERYLMGEVISVGTEAGEVNSGKKVLFSDINAYEVDLGTEARHCFCKAGDLLAVVE',\n '49390.A0A068UMK5': 'MAIAAQTPDILGERQSGQDVRTQNVMACQAVANIVKSSLGPVGLDKMLVDDIGDVTITNDGATILKMLEVEHPAAKVLVELAELQDREVGDGTTSVVIIAAELLKRANDLVRNKIHPTSIISGYRLAMREACKYVDEKLAVKVEKLGKDSLINCAKTSMSSKLIGSDSDFFANLVVEAVQAVKMTNARGEVKYPIKGINILKAHGKSARDSYLLKGYALNTGRAAQGMPMRVAPARIACLDFNLQKTKMQMGVQVLVTDPRELEKIRQSEADMTKERIEKLLKAGANVVLTAKGIDDMALKVSSCIVVFLSQL',\n '49390.A0A068UN30': 'MHVDDEAAKLRFDFPGVGKEGLKIWFENGNLKIEGTEDATDVDGVPKEGRKYAVTYEIFEPGLLKKDEAKAEMKNGVLKVVIPMVKFEERKEVVHINVA',\n '49390.A0A068UN39': 'MSLIPSFFGGRKTNVFDPFSLDIWDPFDGFFVTSPSVANWPSSARETAAVATARIDWKETPEAHVFKADVPGLKKEELKVEVEEGRILQISGERSKEQEEKNDKWHRSERRSGKFLRRFRLPENAKVEEVKASLEDGVLTVTVPKVEEKKPEVKSIEISA',\n '49390.A0A068UNW6': 'MASSLAFRRAANVSSPLLMKLMDVGSLRTLAAAPSMARSFTTNAQMTTYGEGDRSVDVERRPESGVFRRRDSFPSFFSDVFDPFSPTRSVNQLLNLMDRFMEDPFLAARELGPAAVSRRGWDVREDEKALYIKMDMPGLDKENVKVTVEQNTLVIKGEGVKESEEEEHGRRYSSRLDLPPNLYKIEEVKAEMKNGVLKVIVPKVEEEERKDAFQVKVD',\n '49390.A0A068UPA4': 'MTAQSQEELLAAHLEQQNIDPEEPVIEDDDEEDDEDDDDDKDEDDVEGQGDGSGRSKQSRSEKKSRKAVLKLGMKAIPGVSRVTVKKSKNILFVISKPDVFKSPTSDTYVLFGEAKIEDLSSQLQTQAAEQFKAPNISNVISKPEPSTVAQDDEDVDETGVEPKDIELVMTQAGVSRAKAVKALKAADGDIVTAIMELTN',\n '49390.A0A068UPY3': 'MGLLSNRIDRGSLKPGDHIYSWRTAYIYAHHGIYVGDDKVIHFTRRGQEVGTGTILDFVLVSSGPSRGHVPCTTCTLTEEGHGVVSTCLNCFLAGGVLYRFEYAVNPALFLAKARGGTCTLAVSDPDDIVVHRASYLLNNGFRCYNVFKSNCEDFAIYCKTGLLVLDHSTMGQSGQAVSIIGGPLAAVLSTPLRLVTTNVYGMAATAVGVYCASRYATDIGMRSDVVKMPVEDLTQRLETGLLGVAIPSLPALPPTPVS',\n '49390.A0A068UQI7': 'MEAKTGSTARLSYEEFEPFCRWQREEACDTLLVHLPDFKKEQLRVHINNRGILKISGERKLSSTKGSKFYKEVVVARNCNTNAIQAKFSAGQLCIKMTKNVNAAAVPEQKGSTLDPTAKPQAGPEEGQATQPPQKPGEEKYSIIVPSGTPIATASGKSNGTVTEGEETTVSRGKQLANIALNVGMPVALLAALVAFVLYMYKSTIVED',\n '49390.A0A068UQV1': 'MNGMHDCRYNEEGSPRGIPKRGSYEKAYFTRSPLSSPPASRNTSPSPLSRSTSKRSLTPIRSAAANLLRSMSRRKSAEATTLPSTLSRSVSRKASITIMYSNSNGLMKPPAMEMTLECTLEELCFGCIKKMKITRDSVTDDGYTLQLIQEDEVLTIKVKPGWRKGTKITFEGMGNEMPGADPADVIFTVLEKRHHMYRREGDDLELAVEIPLVKALTGCIFAIPLLGGEKMILTIDDIIYPGYQKIIPGHGMPKPHEQGERGNLIITMLVKFPTELTDEQRSEIVSILRDSC',\n '49390.A0A068URJ1': 'MSPIPSVFGGRKTNVFDTFSLVMWDPFGGFFTSSILINLPTSAGETTAFANARIDWKETPQAHVFKADVPGLKKGEVKVEVLEEGRILQIRGERSKEQEEKNDKWHHLERSSRKFLRRFRLPENA',\n '49390.A0A068USH9': 'MAKGLHLAFSSRRRYQNYDDQMEEKGEWKSRWQDQVSELKRRSMYKDAGSMSWGARMRRQKK',\n '49390.A0A068UT14': 'MGRWKPLGSSAHSILKNFWFRSSNFLECSAGKRPLQVAFPALDHCRYLCSCRILLYPADFVPKGLLLSKRFIHATGPSNSTERDYYEILGVSRNATKEEIKKAFHALAKKYHPDANKKNPSAKRKFQEIRDAYEILQDPEKRAQYDRISEYGRTGEDMNYSSGDADGFRFTYGTQFSDSFYDVFAEIFKDQAKFHTKDIQVELSLSFSEAAKGCTKHLSFDADVPCDACNGHGYPPNAKRKICHNCQGSGMQTFLRFTETCSMCKGSGVIFKEFCRACQGSGAVEGVKHVKVSIPAGVDTGDTIHVENAGNAGRHGLEPGSLFIKLKVTEDPLFARDGADIYVDSNISFTQAILGGNVEVPTLSGKTKVQIPKGVQPGQLLRLRGKGLPKSGFFVDHGDQYVRFRVNFPVVLNERQRAILEEFANEEISSEHNTSGEGSWLYQQLSTG',\n '49390.A0A068UTG2': 'MAPLQGSFLEIGRVKTSNGGATRIASDKRSMTEEEWGKRLRASFWGTFKSYGSEPPENLPPPPPANRNGGDGIAVHTPPGPPFAPGVNVVRAASTPNIKGGDTSNNGEKSGWGGSNLGKSLPTPKEICMGLDKFVIGQDHAKKVLSVAVYNHYKRIYHASLNKGSGAEIAPDDDDENVELEKSNVLLMGPTGSGKTLLAKTLARFVNVPFVIADATTLTQASNSWVNLF',\n '49390.A0A068UTZ3': 'MAGKSAPAIGIDLGTTYSCVAVWEHDRVEIIANDQGNRTTPSYVAFTDTERFVGDAAKNQAAINPVNTIFDSKRLIGRKYTDPSVEYDLKLWPFKEKQFAPEEISAMILTKMKEVAEAYLGLPVKNAVITVPAYFNDSQRQATRDAGAISGLNVLRIIVEPTAAAIAYGLDKELLINTGGQKNVLIFDLGGGTFDVSLLTIEKSMVDVKAVGGDTHLGGEDFDNRMVNHFVQAALRRLRSACERAKRILSSIHQTSIEIDALFEGIDFQSTITRPRFEELNMDLFRQCMEPVESCLRDAKMDKHSVQDIVLVGGSTRIPKVQQLLQDFFNGKTLCKSINPDEAVAYGAAVQAAILDGRGNQKALDIAIMDVTPLSLGFECKGKVMTVVIPRNTTIPTKKETTCTTAYDNLTHVLFLVYEGERARSTENNLLGRFTLGGIPPAPRAVPVINVCFDLDANGILNVSAEDKNTGQKSRITISFDKGRLSREEIEKMVQAAEKYKFEDEEHKKKSKNISSSLASADMKKIEDAIEDAMQWLDGNQLGETDEYEDKMKELESITERLMITKKD',\n '49390.A0A068UUJ1': 'MHAPVLVLKDTLKRESGNKVHYANIQASKAVADIIRTTLGPRSMLKMLLDAAGGIVVTNDGNAILRELDLAHPAAKSMIELSRTQDEEVGDGTTSVIVLAGEMLHVAEAFIDNHYHPTVICRAYNKALEDAIAVLEKIAMTVDVKDRATMLGLVKSCIGTKFTSQFGNLIADLAIDATTTVGVEVGQGIREVDIKKYVKVEKVPGGQLEDSQVLKGVMFNKDVVAPGKMRRKIVNPRIILLDCPLEYKKGENQTNAELLREEDWSVLLKMEEEYIENLCMQILKFKPDLVITEKGLSDLACHYLSKAGVSAIRRLRKTDNNRIAKACGAVIVNRPDELQESDVGTGAGLFEVRKIGDEFFAFIVDCKDPKACTVLLRGASKDLLNEVERNLQDAMSVARNIVKNPKLVPGGGATELTVSAILKQKSSSVEGIEKWPYEAAAIAFEAIPRTLAQNCGVNVIRTMTSLRGTHANGENAWIGIDGNTGAIADMKERKIWDSYTVKVQAFKTAIEAACMLLRIDDIVSGIKKKQAPGAGASSKPKVEEEGEAENEALIPE',\n '49390.A0A068UUL8': 'MAVSWRRSGSFIALAIVFFGCLSAISIAKEEATKLGTVIGIDLGTTYSCVGVYKNGHVEIIANDQGNRITPSWVAFTDSERLIGEAAKNQAAVNAERTIFDVKRLIGRKFEDKEVQRDMKLVPYKIVNKDGKPYIQVKIKDGEVKVFSPEEISAMVLTKMKETAEAFLGKKIKDAVVTVPAYFNDAQRQATKDAGIIAGLNVARIINEPTAAAIAYGLDKKGGEKNILVFDLGGGTFDVSVLTIDNGVFEVLATNGDTHLGGEDFDQRIMEYFIKLIKKKHGKDISKDNRALGKLRREAERAKRALSSQHQVRVEIESLFDGIDFSEPLTRARFEELNNDLFRKTMGPVKKAMEDAGLEKHQIDEIVLVGGSTRIPKVQQLLKDYFDGKEPNKGVNPDEAVAYGAAVQGGILSGEGGDETKDILLLDVAPLTLGIETVGGVMTKLIPRNTVIPTKKSQVFTTYQDQQTTVSIQVFEGERSLTKDCRLLGKFDLTGIPPAPRGTPQIEVTFEVDANGILNVKAEDKGTGKSEKITITNDKGRLSQEEIERMVREAEEFAEEDKKMKERIDARNGLETYVYNMKNQINDKDKLADKLESDEKEKIEAAVKEALEWLDDNQSAEKEDYEEKLKEVEAVCNPIITAVYQRSGGAPGGASEDDDSHDEL',\n '49390.A0A068UUU1': 'MADVQMAGETETFAFQAEINQLLSLIINTFYSNKEIFLRELTSNASDALDKIRFESLTDKSKLESQPELFIRIVPDKVNRTLSIIDSGVGMTKSDMVNNLGTIARSGTKEFMEALQAGADVSMIGQFGVGFYSSYLVAEKVVVTTKHNDGEQYVWESQAGGSFTVTRDVSGEPLGRGTKVTLYLKEDQLEYLEERRIKDLVKKHSEFISYPIYLLVEKTTEKEISDDEDEETKKDEEGEVEEVDEEKDKDKKKKKKIKEVTNEWQQINKQKPLWLRKPEEVTKEEYAAFYKSLTNDWEDHLAVKHFSVEGQLEFKAILFVPKRAPFDLFDTRKKLNNIKLYVRRVFIMDNCEELIPEYLGFVKGVVDSDDLPLNISRETLQQNKILKVIRKNIVKKCIEMFFEIAENKEDYAKFYDAFSKNIKLGIHEDSQNRAKLADLLRYYSTKSGDELTSLKDYVTRMKEGQQDIYYITGESKKAVENSPFLEKLKRKGYEVLFMVDAIDEYAVAQLKEYDGKKLVSATKEGLKLDESEEEKAAREEKKKSFENLCKVMKDILGERIEKVVVSDRVVDSPCCLVTGEYGWDSKHGEDYEGSSIKGHQHERLHTALLTSGFSLDDPNQFGSRIHRMLKLGLSIEENGTDDDADMPELKEETNEESKMEEVD',\n '49390.A0A068UV80': 'MVYFFLGSKKVFCCNLNVINLAGYVGEDVESILHKLLTVAEFNVQAAQQGMVYIDEVDKITKKAESLNISRDVSGEGVQQALLKMLEGTIVNVPEKGARKHPRGDHIQIDTKNILFICGGAFIDLEKTISERRQDSSIGFGAPVRANLRTGGITNATVTSSLLESVESSDLIAYGLIPEFVGRFPILVNLSALTEDQLVQVLAEPKNALGKQYQKLFNMNNVKLHFTEKALGLIAKKAMAKNTGARGLRAILEGILTDAMYEIPDIRGGMDRVDAVVVDEESVGTIDAAGCGGKILRGDGALECYLAKTKLKDQVENAAASEADLQGVESEVSSRAISM',\n '49390.A0A068UVY0': 'MGLYLSVAWFVKFGDCIWLSKSLYNHKDVFLQEFVSNASDALDKLRFLSMIEFGLLRDASDLEIHNKPDPNNGAITIRESGIGMTKNELTDYLETIV',\n '49390.A0A068UXN7': 'MSYCLSNLPISQLHVTPQRCSTTSNRSYGRSSRHLLSPVSGRNICKGIRAMTGDARDNLDHLQRANKQQTPQPRNKSAPVAPIGVLDRFPTARTVQQMMETMERLMEDPFAYSGGWPSPLAPDTGGYSRGRTPWEIKESEGEYKMRFDMPGMTKEDVKVWVEEKTLVVKAEKVPKKKNEDGEEEEKNEWSAKSYGRYNSRIALPENAQFEKIKAEVRDGVLYITIPKASSHGKILDINVE',\n '49390.A0A068UYQ6': 'MREREPTASSLGPTPHSLSLPRFLHFQNTPLLSPCRPPLTSIYMSTPSSISHLKLTTHHLNYLNGRNPKVFLWLLESLCQILTRKFPKSRGKRKMSFAVNRITICAAVSEASPPALETRTKPGNLYQVLRVKQNASQVEIKTAYRTLAKIYHPDVAPVAAKHPEESLDGCDFIEIHKAYSTLSDPDSRAVYDLTLTIGSQPQPLGVNYSAPGGFRRHAGFYATRRWETDQCW',\n '49390.A0A068UZP3': 'MAETETFAFQAEINQLLSLIINTFYSNKEIFLRELISNASDALDKIRFESLTDKSKLDAQPEFFIHIIPDKTNNTLSIVDSGIGMTKADLVNNLGTIARSGTKEFMEALAAGADVSMIGQFGVGFYSAYLVAEKVIVTTKHNDDEQYVWESQAGGSFTVTRDASGENLGRGTKMTLFLKEDQLEYLEERRLKDLIKKHSEFISYPISLWVEKTIEKEISDDEDEEDKKDEEGKVEEVDEEKEKDEKKKKKIKEVSHEWSLVNKQKPIWMRKPEEITKEEYAAFYKSLTNDWEEHLAVKHFSVEGQLEFKAILFVPKRAPFDLFDTRKKPNNIKLYVRRVFIMDNCEELIPEYLSFVKGIVDSEDLPLNISREMLQQNKILKVIRKNLVKKCIELFFEIAENKEDYNKFYEAFSKNLKLGIHEDSQNKTKLAELLRYHSTKSGDELTSLKDYVTRMKEGQNDIYYITGESKKAVENCPFLEKLKKKGYEVLFMVDAIDEYAVGQLKEFEGKKLVSATKEGLKLDESEDEKKKKETLKEKFEGLCKVIKDVLGDKVEKVIVSDRVVDSPCCLVTGEYGWTANMERIMKAQALRDSSMAGYMSSKKTMEINPENPIMEELRKRADADKNDKSVKDLVLLLFETALLTSGFSLDDPNTFGNRIHRMLKLGLSDADAEGSKMEEVD',\n '49390.A0A068V081': 'MALAFDEFGRPFIIIKEQESKTRLRGLDAQKTNIAAGKAVARILRTSLGPKGMDKMLQSPDGDITITNDGATILEQMDVDNQIAKLMVELSRSQDYEIGDGTTGVVVMAGALLEQAERLLERGIHPIRIAEGYEMASRIAYEHLEHIAQKFEFDATNTEPLIQTCMTTLSSKIVNRCKRSLAEIAVKAVLAVADLERRDVNLDLIKVEGKVGGKLEDTELIYGIIVDKDMSHPQMPKEIQDAKIAILTCPFEPPKPKTKHKVDIDTVEKFRTLRQQEQKYFDDMVQKCKDVGATLVICQWGFDDEANHLLMHRNLPAVRWVGGVELELIAIATGGRIVPRFQELTPEKLGRAGLVREKAFGTTKDRMIYIEHCANSRAVTIFIRGGNKMMIEETKRSIHDALCVARNLIRNNSIVYGGGSAEISCSIAVEAAADKYPGVEQYAIRAFADAMDSVPMALAENSGLQPIETLSAVKSQQIKENNPWCGIDCNDVGTNDMREQNVFETLIGKQQQMLLATQVVKMILKIDDVISPSDY',\n '49390.A0A068V0S7': 'MADSSGTTLMDLITSDQPSSTVPSSAASTTASSTAPPPQTTTANIGAPIPVVVDKKSKKGTLMQIQSDTISAAKAALNPVRANIMPQKQKKRPVSYAQLARSIHELAAASDQKSSQRQLVHHVFPKLAVYNSVDPSLAPSLLMLDQQCEDRTVLRYVYYYLARILSDTGSQGLSPGGGIPTPNWDALADIDAVGGVTRADVVPRIVDRLTSEALNEDVEFHPRRLQALKALTYAPSSSSEILTKLYEIVFSILDKVADPQKRKKGIFGAKGGDKESIIRSNLQYAAISALRRLPLDPGNPAFLHRAVQGVSFADPVAVRHSLEILSELGTSDPYAVAMALGKVVQPGGALHDVLHLHDVLARVALARLCHTISRARSLDDRPDIRSQFSSVLYQLLLDPSERVCFEAILCVLGKLDNAERTEERAVGWYRLTREILKLPEAPSVKETKADSKDAAPAKSSKEKSSKTKRPQPLIKLVMRRLESSFRSFSRPVLHAAARVVQEMGKSRAAAFAVGLQDIDEGVHINSFSESSDSYDQDLNETSEGLRRVSSVSNGTSGKDTIAGLLASLMEVVRTTVACECVYVRAMVIKALIWMQSPHESFGELESIIASELSDPSWPATLLNDILLTLHARFKATPDMAVTLLEIARVFATKVPGKIDADVLQLLWKTCLVGAGPDGKHTALEAVTIVLDLPPPQPGSMSELTSIDRVSASDPKSALALQRLVQAAVWFLGENANYAASEYAWESATPPGTALMMLDADKMVAAASSRNPTLAGALTRLQRCAFSGSWEVRIIAAQALTTMAIRSGEPYRLQIYEFLHTLEQGGLQSQLADMHVSNGEDQGASGTGLGSLISPMIKVLDEMYGAQDELIKEMRNHDNAKKEWTDDELKKLYETHERLLDLVSLFCYVPRAKYLPLGPTSAKLIDIYRTRHNISASTGLSDPAVATGISDLIYETAKPTPAEPDTLDDDLVNAWAANLGDDGLLGSNAPAMSRVNEFLSGAGTDAPDVEENITSRPSMSYDDMWAKTLLETTEMEEDTRSSGSSSPDSVGSVETSISSHFGGMNYPSLFSSKPSTYGSSQSTERAGGSRFSHPSFGGNSYEGFNSPIREEPPPYSSPTHQRYESFENPLAGPGSQSFGSHDDERLSSTNRQHGTALYDFTAGGDDELNLTAGEEVEIEYEVDGWFYVKKKRPGRDGKMAGLVPVLYVSQS',\n '49390.A0A068V120': 'MADEANRKAFLEIQSRMIESTAKLKQFQNQIRSKEGEKKRAYLTLEELRQLLDDTNTYKSIGRTFVLEPKSVLMDEQEQKLKDSEAAISALEKSKEYLEKQIAEVENNLRELLQQDPGLARQIMSMSV',\n '49390.A0A068V198': 'MVGMGMPAYGIQSMLKEGHKHLSGLDEAVLKNIDACKQLSQITRTSLGPNGMNKMVINHLDKLFITNDAATIVNELEVQHPAAKILVLAGKAQQEEIGDGANLCVSFAGELLQNAEELIRMGLHPSEIIIGYAKAINKTIQVLEELVEAGSDTMDVRDTNQVISRMKAAVASKQFGLEDILCCLIAQACIQVCPKNPANFNVDNVRVTKLLGGGLHDSKIVRGMVLKSDAVGSIKRIEKAKVAVFAGGVDTSATETKGTVLIHSAEQLENYARTEEAKVEQLIKAVAESGAKVIVSGAAVGEMALHFCERYKLMVLKISSKFELRRFCRTTGAVALLKLSPPNPDDLGYVDSISVEEIGGVRVTIARNEEGGNSVSTVVLRGSTDSILDDLERAVDDGVNTYKAMCRDSRIVPGAAATEIELAIRLKEFSLKETGLDQYAISKFAESFEMVPKTLAENAGLNAMEIISSLYAEHASGNARVGIDLEEGTCKDVSTNSIWDLYITKFFALKYAADAVCTVLRVDQIIMAKPAGGPKRDAPAGMDED',\n '49390.A0A068V1N0': 'MLVSRIAARSSRTMVTQCRNSLLLLARQEQPFVPIPSSQCHSLIEPRNKVVSGQVALLHRSFLNGSPFQLFGFSSSASPQHNEKDTAQPGAENGSDAAAAGTSTETEVHDKTEASASTDSQVKDEKDVSDSDSDSEGDLSRDDLVKLVAEKEEQLKIKHEELQKLQDKALRTYADMQNSMDRTKRDAENLKKFAVQDFAKNLLDVADNLSRASLAVKDNFLKIDASKDAVGAVPLLKTLLQGVEMTEKQLAEVFKKYGLQKYDPVDEEFDPHRHNAVFQVPDPSKPPNTVAVVLKAGYTLHDRVIRPAEVGVTRAVENDAEQSSET',\n '49390.A0A068V2U0': 'MGVDYYNILKVNRNASDEDLKKAYRRLAMIWHPDKNPTSNKQEAEAKFKQISEAYDVLSDPQKRQIYDLYGEEALKSGQVPPPPRGSGLYANRPHHHHHNQQQHPNPSFRFNPRDADDIYAELFGNETNAGGGGGGGSSSGRSGGAGRENASNNGYFFRSTTMGGSSSGAGNAGGGVGTSGGGGMRKEAPVETVLMCSLEELYKGSVKKLKISRRIIDRAGKFRNLEEILTVDIKPGWKKGTKITFPEKGNQEPGVIPADLVFVVDEKPHSIYVRDGNDLVANQEITLLESLTGKNLELTTLDGRNLLIPLTEIVKPGYEVTIPDEGMPISKDPRKKGNLRIKIDVKYPSRLSEAQKAELRRVLGPSS',\n '49390.A0A068V362': 'MDGGGSSGSNRSFLSDDNRNHFIHRSLRRRPHPTFTASATAPNSRHHHHHHHHQNHYDVLGVPPDASPSNVRKAYRLLALKHHPDVSKDSGADEIFKSIRHAYDILSNETTRNQYDRALRYQKESRRPLGSSWDYNSEYEDELRIYRWAYLKRKMRQEKYWQQYQSREKRYSFYDEAEEVTEDEERGSFVEVLKSAFLSLFLMQTVGVQLSLTFSALVAFLDQKLDAGYKIGYLVAWMLGGRGGVMLTLCLSFASWVCGKTSSSLVALTIVAMWFGSNLARFAPLPQGALLTLLYMSIKLQVDLK',\n '49390.A0A068V496': 'MDYKKSKALWIFFLFVSEFLLGITLAAEESQKKNLGTVIGIDLGTTYSCVGVYKNGNVEIIANDQGNRITPSWVAFTDTERLIGEAAKNQAAINAERTIFDVKRLIGRKFDDPEVQRDMKMLPYKIVNKDGKPYIQVKIKDGEVKVFSPEEISAMILQKMKQTAESYLGKEIRSAVITVPAYFNDAQRQATKDAGTIAGLNVARIINEPTAAAIAYGLDKKSKEMNILVFDLGGGTFDVSILSLDNGVFEVLATSGDTHLGGEDFDYRIMDYFVKLIKKKYNKDISNDKKALGKLRKECERAKRALSSQHQVRVEIESLFGGIDFSEPLTRARFEELNMDLFKKTMGPVKQALKDAGLEKTDIHEIVLVGGSTRIPKVQQLLKDFFDGKEPSKGINPDEAVAYGAAVQGGILGGEGGEETKGILLLDVAPLSLGIETVGGVMTKLIPRNSVIPTKKSQIFTTYQDQQTTVTIKVFEGERSLTKDCRELGRFELSGIPPAPRGVPQIEVTFELDANGILNVRAEDKAAKKAQSITITNDKGRLSQEEIERMVKEAEEFAEEDKKVSERIDARNKLETYIYNMKSTINDKDKLADKIDSDDKTKIESALKDALEWLDDNQNADKDDYDEKMKEVEAVCNPVIKMAYEKSSGSSSESTEDEPYDEL',\n '49390.A0A068V4H2': 'MFGRAPKKSDNTRYYEILGVSKNASPEDLKKAYKKAAIKNHPDKGGDPEKFKELAHAYEVLSDPEKREIYDQYGEDALKEGMGGGGGMHDPFDIFQTFFNGDPFNRGSSRGRRQRRGEDVVHPLKVSLEDLYSGTTKKLSLSRNVICTKCSGKGSKSGASTKCSGCQGTGMKVTIRQLGPGMIQQMQHPCNECKGTGETINDKDRCPLCKGEKVVPEKKVLEVHVEKGMQNGQKITFPGEADEAPDTATGDIVFVVQQKEHPKLKRKHDDIFVEHTLSLTEALCGFQFILTHLDGRQLLIKSKPGEVIKPDQFKAIDDEGMPMYQRPFMRGKMYIHFTVEFPDSLSPDQVKALEGILPPKPQSQLTDMELDECEETTLHDVNIEEEMRRKQAAQQEAYEEDDDMHGGGAQRVQCAQQ',\n '49390.A0A068V4H8': 'MVENLFTIQIKYYLRKNFHFQTQPKVEALQSTHSKPSYSAITQNPRALFPSLLCCSGRKPPLQPSPPSLTVVQEKASRLSSLPPINNYPFRNLGSLLSLSTCGSVFSLPSSFTMAVEKLFKDEATEEKGERARMASFIGAMAIADLVKTTLGPKGMDKILQSTGRGRSVTVTNDGATILKSLHIDNPAAKVLVDISKVQDDEVGDGTTSVVVLAGELLREAEKLVNAKIHPMTIISGYRVAAECARNALLEKVVDNKQDAEKFKSDLMKIAMTTLSSKILSQDKEHFAKLAVDAVMRLKGSTNLEAIQIIKKPGGSLKDSFLDEGFILDKKIGIGQPKRIENAKILVANTAMDTDKVKIYGARVRVDSMSKVAEIEGAEKEKMREKVQKIIAHGINCFVNRQLIYNFPEELFADAGVLAIEHADFDGIERLALVTGGEIASTFDNPESVKLGQCKLIEEIMIGEDKLIHFSGCEMGQACTVVLRGASSHVLDEAERSLHDALCVLSQTVNDSRVLFGGGWPEMVMAKAVDELARKTPGKKSHAIEAFSRALLAIPTIIADNAGLDSAELVSQLRAEHHEEGSAAGIDVISGSVGDMAELGISEAFKVKQAVLLSATEAAEMILRVDEIITCAPRRREDRM',\n '49390.A0A068V4J0': 'MVLGTSAAAEGFDKQNVETAISIELGTTNSCVAVRSDSCVSLSPSGLGIETEGGVMADVIPRGSLVPKKKSQIFTTYCDHQTTMSIKATVIIIFSGNERLTKYCRKLGMLQFSGIPPAPRGVAKN',\n '49390.A0A068V4N8': 'MTKLIPRNSGIPIKKSQVFTTYQDQQTTVSIKVYQGERSLTKDCYELGKFDLSGIPPAPRGVPQIEVTFGVDANGILQVTAMDKAAKKSNSITITNEKGHLTAEEIDRMDALEWLDGNQNAEKLDYDEKMAGLEAAFNPIIRKANESSAGSSADPEDESNYEL',\n '49390.A0A068V5C9': 'MGLDYYKILGVDKKATDDDMKKAYRKLAMKWHPDKNPNNKKDAEAKFKQISEAYDVLSDPQKRAVYDQYGEEGLKGGVPPPDTAGGPGSATFFSTGGGPTSFRFNPRSPDDIFSEIFGFSGFGGMGGGSGMRGSRFGGMFDDSMFSSFEGGGSGPGGSMHQQTIRKAPAIEQNLPCTLEELYKGTTKKMKISREVLDTNSGKIMPVEEILTINIKPGWKKGTKITFPDKGNELPGVAPADLVFIIDEKPHRVFTREGNDLIVTQKVSLTEALTGYTAHLTTLDGRNLTIPVTSVIHPTYEEVVRGEGMPLPKDPSKKGNLRIKFDIKFPARLTASQKAGIKELLGS',\n '49390.A0A068V6G5': 'MASSSSVKNKAFWLLLLFVSEFLAGVTLAAEDSQKQNLGTVIGIDLGTTYSCVGVYRNGNVEIIANDQGNRITPSWVAFTDTERLIGEAAKNQAALNPESTVFDVKRFIGRKFNDPEVQRDMKLLPYKVVNKVGKPYIDVKMKNGEMKLLSPEEVSAMVLQRMKQTAESYLGKEVKNAVVTVPAYFNDAQRQATKDAGTIAGLNVVLSTNGNTHLGGEDFDQRVMDHFLRKECERAKRALTTFEELNMDLFKKTMAPVKQALKDAGLEKSAIDEIVLVGGSTRIPKVQQLLKEFFDGKEPSRGINPDEAVAHGAAVQGAILGGHGGEETKDVLVIDVTPLSLGLETVGGVMTKLIPRNSGIPIKKSQVFTTYQDQQTTVSIKVYQGERSLTKDCHELGKFDLSGIPPAPRGVPQIEVTFGVDANGILQVTAMDKAAKKSNSITITNEKGRLTPEEIDRMVKEAEDMKSSIRDDEKVAGKIDSDDKESIETALKDALEWLDDNQNAEKLDYDEKMAELEAAFNPIIRKAYESSAGSSADPEDESNYEL',\n '49390.A0A068V6R1': 'MSEVDEESKQVSYKVVRDENGNVKLECPAIGKRFAPEEISAQVLRKLVDDASKFLNDKVTKAVITVPAYFNDSQRTATKDAGRIAGLDVLRIINEPTAASLAYGFEKKNNETILVFDLGGGTFDVSVLEVGDGVFEVLSTSGDTHLGGDDFDKRVVDWLAEDFKRNEGIDLLKDKQALQRLTETAEKAKIELSSLTQTNISLPFITATADGPKHIETTVTRAKFEELCSDLLDRLKTPVQTSLRDAKLSFNDIDEVILVGGSTRIPAVQDLVRKLTSKEPNVTVNPDEVVALGAAVQAGVLAGDVSDIVLLDVTPLSLGLETLGGVMTKIIPRNTTLPTSKSEVFSTAADGQTSVEINVLQGEREFVKDNKSLGSFRLDGIPPAPRGVPQIEVKFDIDANGILSVTAVDKGTGKKQDITITGASTLPKDEVDKMVQEAEKFAKEDKEKREAIDTKNQADSIIYQTEKQLKELGEKVPAAVKEKVEAKLTELKDAVSGGSTQAIKDAMAALNQEVMQLGQSLYSQPGTPGDGPTPGADAGASGSTGKSSGGDDGDVIDADFSESK',\n '49390.A0A068V715': 'MTAQSQEELLAAHLEQQNIDPEEPVIEDEDEEDDDDDDDKDEDDVEGQGDGSGRSKQSRSEKKSRKAMLKLGMKAIPGVSRVTVKKSKNILFVITKPDVFKSPTSDTYVIFGEAKIEDLSSQLQTQAAEQFKAPNISNVISKPEPSTVAQDDEDVDETGVEPKDIELVMTQAGVSRAKAVKALKAADGDIVSAIMELTN',\n '49390.A0A068V781': 'MLKLEMKAIPSASRVTVKKSKNVNFVYYLKDDEDVDKTGVEPKNIELKMTQASVSRTKAVKSLKVVDGDIVSTFMKLTNKETLYRVS',\n '49390.A0A068V7L1': 'MNVDSAPGPDGFGMGFYQSCWDIIKVDLLASIHDYFKGVAQPWGWSTFAFDHQYFLQQQGDFPSIELFIRPVPDKVNKTLSLIDSSIGMTKADLVNNLGTIARSGTKEFMEASQAGADVSMIGQFGVGFCSAYTTLHQNSPSRLQIFTEQKHGKPSLSL',\n '49390.A0A068V8B0': 'MEGEEAKLLLGFPPHSHPSPSQVKTAYKSKVWDTHPDRFPPHLKSNAEHRFKLISEAYACLRSASYSKVVRSGVPRACGSGGHRALIAAPFLLIVLSTVAFGGSIVTRSYKRQKEAYPSHNPFLP',\n '49390.A0A068V8K6': 'MVTNTSMILTPFFLFKTKFLISCYCYIIELCDSHDFLILYFSWVFFFFLHVYFHQNLGTVIGIDLGTTYSCVGVYRNGNVEIIANDQGNRITPSWVAFTDTERLIGEAAKNQAALNPESTVFDVKRFIGRRVDDPEVQRDMKLLPYKVANKDGKPYIDVKMKNSEMKLLSPEEVSAMVLQRMKKTAESYLGKEVKNAIITVPAYFNDAQRQATKDAGTIAGLNVQEKERNILVFDLGGGTFDVSILALDGGVFEVLSTNGNTHLGGEDFDQRHQVRVEIESLFDGIDFSEPLTRARFEELNMDLFKKTMAPVKQALKDAGLEKTDIDEIVLVGGSTRIPKVQQLLKDFFDGKEPSKGINPDEAVAHGAAVQGAILGGHDVLVIDVTPLSLGIETVGGVMTKLIPRNSGIPTKKSQIFTTYQDQQTAVSIRVYQGERSLTKDCHELGKFDLSGIPPAPRGVPQIEVTFEVDANGILQVTARDKAAKKSNSITISNEKGSLTQEEIDRMVKEAEEFADQDKELAAKIDSDDKESIETALKDALEWLDENQNAEKVDYDEKMAELEAVFNPIIRRAYENNSGSSADSKDEPHDEL',\n '49390.A0A068V8M1': 'MPCSSSVKNKAFWLLLLFVSEFLAGIALAAEGTQKQNLGTVIGIELGTTYSCVGVYRNGNVEIIPNDQGNRITPSWVAFTDTERLIGEAAKNQAALNPESTVFDVKRFIGRRVDDPEVQRDMKLLPYKVANKDGKPYIDVKMKNSEMKLLSPEEVSAMVLQRMKKTAESYLGKEVKNAIITVPAYFNDAQRQATKDAGTIAGLNVQEKERNILVFDLGGGTFDVSILALDGGVFEVLSTNGNTHLGGEDFDQRVMDYFKGMWRAKRALSNRHQVRVEIESLFDGIDFSEPLTRARFEELNMDLFKKTMAPVKQALKDAGLKKTDIDEIVLVGGSTRIPKVQQLLKDFFDGKEPSKGINPDEAVAHGAAVQGAILGGHGDVLVIDVTPLSLGIETVGGVMTKLIARNSGIPTKKSQIFTTYQDQQTTVSIRLGKFDLSGIPPAPRGVPQIEVTFEVDANGILQVTAIDKAAKKSNSITISNEKGSLTQEEIDRMVKEAEEFADQDKELAAKIDSDDKESIETTLKEALEWLDENQNAEKVNYDEKMAELEAVFNPIIRRVYEEALLIQKMNPMMSCEL',\n '49390.A0A068V951': 'MVHRRTSKLLFLLCFLSCSLIAIAAKSYYDILQVPRGASDEQIKRAYRKLALKYHPDKNQGNEEANKKFAEINNAYEVLSDSEKRSIYDRYGEEGLKQHAASGGRGGGMNIQDIFSQFFGGGPMEEEEKIVKGDDVIVELDATLEDLYMGGSLKVWREKNVIKPAPGKRRCNCRNEVYHKQIGPGMFQQMTEQVCEQCPNVKYEREGYFVTVDIEKGMQDGQEVVFYEDGEAIIDGEAGDLRFRVRTASHDLFRREGNDLHTTVTITLVQALVGFEKTIKHLDDHLVDIGTKGVTKPKEVRKFKGEGMPLHFSNKKGDLYVTFEVLFPTSLTEDQKTQIKAILG',\n '49390.A0A068V9E8': 'MAVEKFFKDEATEEKGERFRIASFVGAMAIADLVKTTLGPKGMLCQGINLTMAYDISKVQDDEVGDGTASVVVLAGELLLEAEKLVNTKIHPMTIISGYRMAAECAWNALLEKFLILLLLDSAEIFKLDLMKIAMTTLNSKILSQYKEHFANIAVDAVMRLKGSTNVEAIQIIKKTWRFTKGFTYCLLCCRFALEKKIGIDQSKRIENAKILVANIATDTDKVKIYGARVHVDSMSKVADIKGSEKEKMREKVQKIIAYGKNCLLVLEYLQ',\n '49390.A0A068V9Q0': 'MVMAKVVDELARKTPGIKSHAIEAFSAELVSQFHAEHHKEGSTADIDVISGSVGDTAELGISEAFKVKRSVLLSATEAAEMILRVDADITCAPCRREDRM',\n '49390.A0A068VA98': 'MALGRLTKDGQESGRFELSDIPPAPRGVPQIGVTFKVDTNGLLHVIAEDKATKVAIHYL',\n '49390.A0A068VAY4': 'MFSLTFSYSSSESTKIFFLYLSGKRILDISLSTVTIGHLGGDLFDERIVDWLAENFKRNEGIELLIDKQALQRLTETAERAKI',\n '49390.A0A068VBM4': 'MEGGKPTIVTNAEGQRTMPSVVAYTKNGDRLVGQVAKRQAVVNLETSFSL',\n '49390.A0A068VBQ5': 'MASQQRRINPSFLSLCLALGLLFACATAKVFFEERFDDGWEKRWVKSDWKKEDNTAGEWNYTAGKWHGDPNDKGIQTSEDYRFYAISAEFPEFSNKDKTLVFQFSVKHEQKLDCGGGYMKLLSGDVDQKKFGGDTPYSIMFGPDICGYTTKKVHAILNYNETNHLIKKDVPCETDQLSHVYTFILRPDATYSILIDNVEKQTGSLYSDWDLLPPKQIKDPEAKKPEDWDDKEYIPDPEDKKPEGYDDIPKEIPDPDAKKPEDWDDEEDGEWTAPTIPNPEYKGPWKAKKIKNPNYKGKWKAPLIDNPEFKDDADLYVYPNLKYVGIELWQVKSGTLFDNVLVSDDPEYAKKLAEETWGKHKDAEKAAFDEAEKKREEEEAKDDPVDSDAEEGDDDDAADEADSDDADAKSETKEDATAAAEENVKDEL',\n '49390.A0A068VCW2': 'MGVDYYNILKVGRNATEDDVKKAYRRLAMKWHPDKNPTNKKEAEAKFKQISEAYEVLSDPQKRQTYDQYGEEGLKDMPPQGSGGGFQNGFNPRNAEDIFAEFFGSSPFGFGSAGPGRSMRFQSDGGGPFGGFGGGDNIFRTYSDGTGASMPKKPPPVESKLNCSLEELYTGSTRKMKISRTVVDVNGRMSTETEILSIEVKPGWKRGTKITFPDKGNEQFNQLPADLVFVIEEKPHNVYNRDGNDLIMKYTVTLAEALGGTTVNITTLDGRELSIPVNDIISPGYELVVDKEGMPIAKEPRNRGDLKINFEVKFPTKMTTEQRAAIKRALGG',\n '49390.A0A068VEE6': 'MASSKGIGIGGGAGGPKTTAPVTTELDKLSVEQLRAVKEQADLEVNLLQDSLNNIRTATARLDIASNALNDLSLRPQGKKMLVPLTASLYVPGTLDDADKVLVDVGTGYFIEKTMVEGKDYCERKINLLKSNYDQLLETFYSWLLLQQNSLRILILLRLGEKECPQAKAFLCAPSHAFEAFVLYSSHCHSRNHF',\n '49390.A0A068VEF6': 'MQIFMKTLIRKTITLEVESSSTIDNVKAKIQDKEGNPPDQQCLIFTDTSASSCFPNFSPINLPNFFPQLPFLLPLRDSFLVNGVAFKKTFSYSGFEQQPKKFVNPKILLLNIELELKSEKENVEIRLSDPSQYQSIVDAEWNIIYDKLDKCVKSGAKIILSRLAIGDLATQLYFNRDVFCAGRVIEEDLHRVATATGGTI',\n '49390.A0A068VEQ2': 'MQIFMKTLIRKTITLEVESSGTINNVKAKIQDKEGNPPDQQCLIFTDSSASSCFPNFSPINLPKFFSQLAFLLALRDSFLVNGVAFKKTFSYAGFEQQPKKFVNPKILLLNIELELKSEKENAEIRLSDPSQYQSIIDAEWNIIYDKLDKCVKSGAKIILSWLAIGDLATQYFADRDVFYAGRVIEEDLHRVAAATGGTIQTTVEEVQFCY',\n '49390.A0A068VF92': 'MVDFKEKRWCRKTLFDNILVSLQVKSGTLFDNVLVSDDLEYAKKLAEETWGKHKDAEKVAFDEAEKKREEEVLFINSPLLHDVLSTFEFHFCIVWTLDFLYTALFEQ',\n '49390.A0A068VF93': 'MATTARRPPPPPPASAAAAAAVSISSIPSILKAYSIPLILFGIALFFQLVVTPGSFPPSHYDVLGVKKYASVEEVTQAYEKLTSTWDSSVPVPSVFDAVKVQYAFELLTNELWKRDYDNFGIDEQSHVINQATEQYAGATVSEIKSPLMEPNSFDLAEHTFNVINSENFLSQFDSTKAWLIQVSLLFNMLPFYVMTKCD',\n '49390.A0A068VFC4': 'MHRLSGRSVSTILRAGGCRRCRNATASISSSNIFHKSAEENDENVRWYSVLTTRQINCGKPIKQLNFGSSHHLLRIRYESTAAASDSSSNPPPEKYEYQAEVSRLMDLIVNSLYSNKEVFLRELIRHALVLFSPFSVSLPAGLVIHGASFSHAAFVVVVGGKK',\n '49390.A0A068VFN4': 'MDLELGLKLRRVADEFCLADFQFYKDRTGPVFISTETDSKFFLTAHLKGHRKQNIKIEINEDGTRIIISGEMEIQETVMVEWRLYRKETEIRRFRKAFKIPDGVILDKIKAKYNADECILTISMPKKDKGIRGFDIEEVQEQELAREGSETLEIVPDEVPKQEDEMQAKDQEAEAEHAEGKLEKEEKSQGIEGDMERKHEQPEPLTEVIDQNHHKRDQVDGKESGTQEAEEEEESALVKPPDEVQEDRPSRIEKHRGRCKMCAPILAGSALLLSLVVFVIQFIRKKSHQGKRKE',\n '49390.A0A068VFQ1': 'MLLIRSLFGGRRGNVFDPYSLDVWDPFVGLAFPDASLANVPNTASETYAFARPRIDWKETPEAHVYKADLSGLRKEEVKVEVEECRVLQISGERRREQEEKNDKWQMVERRSGRFGRRFRLPENAKADQVRASMENGVLTVTVPKEEAKKPEVKAIEISG',\n '49390.A0A068VG01': 'MSLIPSIFGGRRSNVFDPFSLDIWDSFPFSDASLANVPNTARETSAFASSRIDWKETPEAHVFKADLPGLKKEEVKVEVEDGRVLQISGERSREQEEKNDKWHRIERSSGKFLRRFRLPENAKLDQVKAGMENGVLTITVPKEQVKKPGVKAIEISG',\n '49390.A0A068VGB2': 'MALVPSIFGGRRSNIFDPFSLDIWDPFEGFPFSRTLANFPSGTDRETAVFTNARVDWRETPEAHIVQADLPGLKKEEVKVEVEDGRILKISGERSREQEEKSDTWHRVERSSGKFIRSFRMPENAKTEEIKASMENGVLTVTVPKVEEKKPEVKAINISG',\n '49390.A0A068VGE4': 'MSMVPSFFGRRSSTPDEIWDPFQGWPFNSDFSPFSGQLRTTFPSSSSETASFAHASIDWKETPNAHVFKADVPGLRKEEVKVEVEDDRILQISGERKREIEDKGHTWHKVERSSGKFMRRFRLPENAKVEQVKASMENGVLTVTVPKAEIRKPDVKSIEICG',\n '49390.A0A068VGF3': 'MENQVVRRRVNIIASHFGSPEDLSAAATHLFPTGCSNSLNSVIRRCDSKMYFARQTSSSQPCFMRPVANKQICHTYGNYAESTPRSKSSGSLNKDLYAYEAPMFSRPSITEPSMQNVEELQWLQQACNFHQPAPDPPTFARPSPVDYHAKERTEASKVKGFEWMPKMDVAESGCNYVVTIELPGARASNIRVEVNNQNLRVTGYRSIEWGKVASCSIDSTSAYHRREISQGPYEIVWPLPKNVNKENISAELVEGLLLINVPKLSEARRQLKRVYI',\n '49390.A0A068VH68': 'MENFLLLLLRLLIFLLIFCFTSSEIIFEERFEDGWRDRWVLSDWKRSEGKAGTFKHTAGKWAADPDDKGLQTYNDARHYAISAKIPEFSNKNRTLVVQYSIKIEQDIECGGGYIKLLSGYVNQKKFGGDTPYSFMFGPDICGTQTKKLQVIVSYQGQNYPIKKEIECETDKLTHFYTFILRPDATYSILIDNRERESGSLYSDWDILPPPKIKDVHAKKPADWDDREYINDPNNVKPEGYDSIPKEIPDPKAKKPADWDDEEDGIWRAKKIPNPAYKGPWKPKRIKNPNYKGKWKIPWIDNPEFEDDPDLYVWKPIKYVGIEVWQVKAGSVYDNILICDDPQYAKEVVEEIWEKNRVAEKEAFEEAEKIRIAREEEDAKRADKDGGKKKSRGRRHHRRHDPDEYLDYDYHDEL',\n '49390.A0A068VHV6': 'MSSLDCFRIYNASDALDKLRFLSVTEPELLKDAVDLDIRIQTDKDNGIVTITDTGIGMTREELVDCLGTIAQSGTAKFLKALKESKDSGGDSNLIGQFGVGFYSAFLVSERVEVSTKSPKSDKQYVWEGEANSSSYTIREETDPAKLVPRGTRLTLYLKRDDKGFAHPERVQKLVKNYSQFVSFPIYTWQEKGYTKEVEVDEDPSEAKKDDQGDKTEKKKKTKTVVEKYWDWDLTNETQPIWLRNPKEVSTEEYNEFYKKTFNEYLEPLASTHFTTEGEVEFRSILYVPSIAPMGKDDIINPKTKNIRLYVKRVFISDDFDGELFPRYLSFIKGVVDSNDLPLNVSREILQESRIIRIMRKRLVRKAFDMINGIAMSENKDDYDKFWENFGKHIKLGILDDKENHKRLAPLLRFFSSQSEDVPISLDEYVDNMKPEQKNIYYIAADSVNSARNTPFLEKLLEKDLEVLFLVDPIDEVAVQNLKEFKDKQFVDISKEDLDLGEKNEEKEKEMKQEFGQICDWIKKRLGEKVAGVQISNRLSTSPCVLVSAKFGWSANMERLMKAQTMGDSSSLDFMRSRRIFEINPEHPIIKTLNAACQSNPNDEEALRAVDLLYDTAAVSSGFTPENPAQLGGKIYEMMSMALSAKWGTSAGEFKRQTTSSTYVPETIEAEVVEPAAEVQK',\n '49390.A0A068VHW9': 'MFFVYILIDQVMFLSLQHVINQATEQYAGATVSEIKSPLMEPNSFDLAEHTFNVINSENFLSQFDSTKAWLIQVFSFGSNRCANFSNNWKHIVTLLDGVANSGMVELGDVRLAAYLAEKKPSGHPFFKNGLPTLLAFPPGCSSSRCLHRYGGQLSVDAITDWLATSILGLPRILYYSKESMVQNFLAKSKPHKVRVIFFSRSGERATPFIRQAAKYYWTYAAFAFARWDEGDSSLWWNMFGVESAPAIVILKDPGVKPTIYYGMCLYLAGSINNSMFIDIMENNKYHVLPQLRSVTSMELGCDAQGYSRAGSEMRIWYCVILAGRLSQELNKMRETIRRVQETLNNNGGELNALDQDSLSTPAALAVKQKRLTFTWLDGEAQQKYCFFHVNSEDSYETCGTRRAMIDVPRLLIVRYERNETEDEVKIERQPRNMFEALHHSEPDPASQLVAKYNGPDESTEIISWISRTIEDGDSRNLPPFRTKCPELVPEDSDPLWQAGSEKIISSSKDLKYKITSFINQMHNQLGDPRIGPVLLLVALMLCGRTWLQRSQPTPKNEPNTSNESSDKDKFRQNRETRPRNNPTRPRNDLIPPSITDVEPKDAQQVQFSGSDSDN',\n '49390.A0A068VID4': 'MQIFMKTLIRKTITLEVESSDTIDNVKAKIQDKEGNPPDQQCLIFTDSSASSWILFSYASFEQQPKKFVNPKILLLNIELELKSEKENAEIRLSDPSQYQSIVDAEWNIIYDKLDKCVKSGAKIILSRLAIGDLATQYFADRDLFGAGRVTEEDLHRVAAATGGTIQTTVNNEVQFYCSVLDIIYALHLFSELVKYAIFIALFLFKKFRKL',\n '49390.A0A068VJ16': 'MESNIDEALTVKAYAEKRFVERDFAGARNCALKAQMLCPELEGIAQMVATFGVYTASEVKINGEFDFYAILGLNPSADKAKLKKQYRKMAVLLHPDKNKTVGADGAFKLVSEAWTVLSDSAKRNSYDHRRNYFAAHSTGVSGFDNYSKSSGSHQRLDTFWTVCTSCHVQYEYLRKYVNKKLSCKNCRGVFVAVETGVAPVNGSFPYCPWSFVPENGYASHGCGVTYMPTASAYCSGNGISGHHSGHGPGEYVSNVSFQWTSFTGHSAGVSDANGLSAVTEASHQVNGKVNRGKANGRHRMRNATGDVSLNSCTVYAEQPAPKVTRPYKKRKFDSGGNCASGISDSAKSVAEERLANANGSLKINAKPSTPSDTSLRRCSAAPAFDARQLLIDKARTVIRQKLEEIKLASAAAAAAQAEKKRKAEAEADKFSEAPKRTSMTSIRTELKNALSQSRYGLYMMKKMVCHVYIV',\n '49390.A0A068VJY5': 'MLRTSSEWVWTPALFMQLTRSIKTLQSFLQAAIFAGGVGTIATETKGTALIHKAQQALRGASSPLDISKVGELIKAIAGSGAKVIVSGAAVGEMALHFCERYKLMVLKISSKFELQRFCHTTGAVALVSILQSESINDTNTRI',\n '49390.A0A068VK96': 'MTNARGEVKYPIKGINILKAHGKSARDSYLLKGYALNTGRAAQGMPMRVAPARIACLDFNLQKTKMQMGVQVLVTDPRELEKIRQSEADMTKERIEKLLKAGANVVLTAKGIDDMALKYFVEAGAIAVRRVRKEDLRHVAKATGATVVSTFADMEGEETFDPSLLGHADEVVEEHVADDDMIMIKGTKTTSGVSLILRGANDFMLDEMDSALHDALCIVKRTLESTTVVAGGGAVEAALSVYLENLATTLGSREQLAIAEFAESLLIIPKVLAVNAAKDATELVARLRAYHHTAQTKADKKNLSRYSFLNPENCCLFQIYMSFCSYQIVISFPLSTALLEML',\n '49390.A0A068VKA4': 'MQIFMKTLIRKTITLEVESSGTIDNVKAKIQDKEGNPLDQQCLIFTDSSASSCFPNFPQLICLNFFPKYFFAKFFVLPWQLAFLLPLRDSFLVNGVAFKKTFSYAGFEQQPKKFVNPKILLLNIELELKSKKENAEIRLLDPSQYQSIVDAEWNIIYDKLDKCVKSGAKIMLSRLAIGDLATQYFADRGVFCAGRVTEEDLHRVAAATGGTIQTTVNNVIDEVQFCCSVLDIIYALHLFSELVKYAIFIALFLFRKFRKL',\n '49390.A0A068VLK5': 'MKTLIRKTITLEVESSGTIDNVKAKIQDKEGNPPDQQCLIFTDRSVSSCFPNFSPINLPKFFPQLAFLLPLRDSFLVNGVAFKKTFSYAGFEQQPKKFVNPKILLLNIELELKSEKENAEIRSLQYQSIVDAEWNIIYDKLDKCVKSGLKSFYLGWLLYFADRDVFCAGHVIEEDLHRVAAATSGTIQTTVNNVIDEVQFCCSVLDIIYALHLFSELVKYAIFIALFLFRKFRKL',\n '49390.A0A068VLT1': 'MAYSSSVKNKACWLLLLFVSEFLAGIALAAEGTQKQNLGTVIGIDLGTTYSCVGVYRNGNVEIIANDQGNRITPSWVAFTDTERLIGEAAKNQAALNPESTVFDVKRFIGRKFDDPEVQRDMKLLPYKVVNKDGKPYIDVKMKNGEMKLLSPEEVSAMVLQRMKQTAESYLGKEVKNAVVTVPAYFNDAQRQATKDAGTIAGLNVVRIINEPTAAAIAYALDGGVFEVLSTNGNTHLGGEDFDQRVMDYFVKLIKKKYNKDISNDKKALGKLRKECERAKRALSNQ',\n '49390.A0A068VM91': 'VSTFADMEGEETFDPSLLGHADEVVEEHVADDDVIMIKGTKTTSGVSLILRGANDFMLDEMDRALHDALCIVKRTLESTTVVAGGGAVEAALSVYLENLATTLGSREQLAIAEFAESLLIIPKVLAVNAAKDATELVARLRAYHHTAQTKADKKNLSRYSFLNPENCCLFQIYMSFCSYQIVISFLYQLHFWKCCSS',\n '49390.A0A068VMN0': 'MTKADLVNNLGTIARSGTKEFMEASQAGADVSMIGQFGVGFCSAYTTLHQNSPSRLQIFTEQKHGKPSLSP',\n '49390.A0A068VN26': 'MLRETMGKLCSKGFDKGISHRKVPPPVWCPLRCTLDELYNGVEKTIKFPGGRMKLLPDPGVIAPNADPETLVVEIPAGAKNGLKIVYPRRVILDDRKVPRDVIVDVIEEPHAEFHRQGNDLWAIRKIPLMEYVTNEALTIETLDKRLLTVPKIEPGCVIEIPNEGMPCWHGIGETGSIFVSFEVIYPKNLSLTREEKDELKKLLAKEENNV',\n '49390.A0A068VNA2': 'MSLIPSVFGGRRSNVFDPFSLDIWDPFEGFPFSNTSLANVPDTARDTSAFATARIDWKETPEAHVLQISGERSREQEEKNDKWHRVERSSGRFLRRFRLPENAKVDKVKASMENGVLTVTVPKEEVKKADVKAIEISG',\n '49390.A0A068VNL3': 'LSPYLVAFEPLLPSIPETSTLAPRIKPSWIAFAGSERLIREAEKNQLDVNVERTIFDVKIKDSKVKVFSLEEISVMVLTKMKEAAEAFLAKKIKDAVVTVPSIVQFLELLATKNAGIIAGLNVARTINEPRAAAVAYLTTN'}"
  },
  {
    "objectID": "posts/proteinbert/load_string_protein.html#proteinbert-embedding",
    "href": "posts/proteinbert/load_string_protein.html#proteinbert-embedding",
    "title": "Protein Embedding with ProteinBERT and STRING",
    "section": "ProteinBERT Embedding",
    "text": "ProteinBERT Embedding\nProteinBERT embed the protein sequences based on the larger sequence available plus 2. So, for this we need to get the value of the larger aminoacids sequence.\n\n\nCode\nsequences = list(filtered_protein_dict.values())\nprotein_names = list(filtered_protein_dict.keys())\n\nlongest_sequence_length = max(len(seq) for seq in sequences)\nlongest_sequence_length\n\n\n1210\n\n\nNow, we are ready to load the pre-trained ProteinBERT model and use it to embed the proteins that belong to the unfolded protein binding ontology.\nOn this code, first we use load_pretrained_model() function to load the model. Then, we define a heper function that will get the embedding from the proteins based on a batch size (this batch size dependes on your GPU or on your CPU+RAM). In this case, I’m using a batch of length equal to 2because that worked on my machine.\n\n\nCode\nfrom proteinbert import load_pretrained_model\nfrom proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\nimport tensorflow as tf\n\npretrained_model_generator, input_encoder = load_pretrained_model()\n\ndef get_embeddings(seq, seq_len=512, batch_size=1):\n\n    model = get_model_with_hidden_layers_as_outputs(pretrained_model_generator.create_model(seq_len=seq_len))\n    encoded_x = input_encoder.encode_X(seq, seq_len)\n    local_representations, global_representations = model.predict(encoded_x, batch_size=batch_size)\n\n    return local_representations, global_representations\n\n\nbatch_size = 2  # Adjust based on your GPU memory\nseq_len = longest_sequence_length+2\nglobal_embeds = []\nlocal_embeds = []\n\n\nfor i in range(0, len(sequences), batch_size):\n\n    batch_seqs = sequences[i:i + batch_size]\n    local_representation, global_representation = get_embeddings(batch_seqs, seq_len=seq_len, batch_size=batch_size)\n    global_embeds.extend(global_representation)\n    local_embeds.extend(local_representation)\n\n# Convert to numpy array if needed\nimport numpy as np\nglobal_embeds = np.array(global_embeds)\nlocal_embeds = np.array(local_embeds)\n\nprint(f'Global embeddings shape: {global_embeds.shape}')\nprint(f'Local embeddings shape: {local_embeds.shape}')\n\n\nWARNING:tensorflow:From c:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\keras-3.3.3-py3.10.egg\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\nWARNING:tensorflow:5 out of the last 5 calls to &lt;function TensorFlowTrainer.make_predict_function.&lt;locals&gt;.one_step_on_data_distributed at 0x0000016285E34700&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\nWARNING:tensorflow:6 out of the last 6 calls to &lt;function TensorFlowTrainer.make_predict_function.&lt;locals&gt;.one_step_on_data_distributed at 0x0000016285E35C60&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\n1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step\nGlobal embeddings shape: (158, 15599)\nLocal embeddings shape: (158, 1212, 1562)"
  },
  {
    "objectID": "posts/proteinbert/load_string_protein.html#build-a-graph-from-a-dataframe",
    "href": "posts/proteinbert/load_string_protein.html#build-a-graph-from-a-dataframe",
    "title": "Protein Embedding with ProteinBERT and STRING",
    "section": "Build a Graph from a Dataframe",
    "text": "Build a Graph from a Dataframe\nOnce we have the embedding for each protein sequence, we need to build or graph based on the interactions dataframe. For this, first we need to encode the protein names using LabelEncoder().\n\n\nCode\nlbl_protein = preprocessing.LabelEncoder()\n\n\ndf.node1_string_id = lbl_protein.fit_transform(df.node1_string_id.values)\ndf.node2_string_id = lbl_protein.fit_transform(df.node2_string_id.values)\n\nprint(df.node1_string_id.max())\nprint(df.node2_string_id.max())\n\n\n157\n157\n\n\nLet’s see the encoding:\n\n\nCode\ndf\n\n\n\n\n\n\n\n\n\n#node1\nnode2\nnode1_string_id\nnode2_string_id\nneighborhood_on_chromosome\ngene_fusion\nphylogenetic_cooccurrence\nhomology\ncoexpression\nexperimentally_determined_interaction\ndatabase_annotated\nautomated_textmining\ncombined_score\n\n\n\n\n0\nA0A068TKM9\nA0A068TNA3\n0\n7\n0.0\n0.0\n0.000\n0.0\n0.000\n0.122\n0.585\n0.000\n0.620\n\n\n1\nA0A068TKM9\nA0A068TLP4\n0\n1\n0.0\n0.9\n0.431\n0.0\n0.000\n0.000\n0.000\n0.000\n0.940\n\n\n2\nA0A068TLP4\nA0A068TKM9\n1\n0\n0.0\n0.9\n0.431\n0.0\n0.000\n0.000\n0.000\n0.000\n0.940\n\n\n3\nA0A068TLP4\nA0A068TNA3\n1\n7\n0.0\n0.0\n0.000\n0.0\n0.000\n0.122\n0.585\n0.000\n0.620\n\n\n4\nA0A068TMA4\nA0A068VEQ2\n2\n133\n0.0\n0.0\n0.000\n0.0\n0.316\n0.204\n0.000\n0.056\n0.441\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n8573\nA0A068VNL3\nA0A068VKA4\n157\n150\n0.0\n0.0\n0.000\n0.0\n0.316\n0.204\n0.000\n0.054\n0.439\n\n\n8574\nA0A068VNL3\nA0A068VLK5\n157\n151\n0.0\n0.0\n0.000\n0.0\n0.316\n0.204\n0.000\n0.054\n0.439\n\n\n8575\nA0A068VNL3\nA0A068VM91\n157\n153\n0.0\n0.0\n0.000\n0.0\n0.557\n0.204\n0.000\n0.057\n0.638\n\n\n8576\nA0A068VNL3\nA0A068VMN0\n157\n154\n0.0\n0.0\n0.000\n0.0\n0.342\n0.249\n0.225\n0.096\n0.607\n\n\n8577\nA0A068VNL3\nA0A068VN26\n157\n155\n0.0\n0.0\n0.000\n0.0\n0.300\n0.220\n0.350\n0.055\n0.619\n\n\n\n\n8578 rows × 13 columns\n\n\n\nAlso, we need to define a function that will use these encoded labels to build an edge index. An edge index is a matrix with shape 2 x number of edges\n\n\nCode\nimport torch\n\ndef load_edge_csv(df, src_index_col, dst_index_col, link_index_col):\n    \n    edge_index= None\n    src = [protein1 for protein1 in df[src_index_col]]\n    dst = [protein2 for protein2 in df[dst_index_col]]\n\n    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1,1)\n\n    edge_index = [[], []]\n    for i in range(edge_attr.shape[0]):\n        if edge_attr[i]:\n            edge_index[0].append(src[i])\n            edge_index[1].append(dst[i])\n    return edge_index\n\n\n\n\n\n\nCode\nedge_index = load_edge_csv(df=df, src_index_col=\"node1_string_id\", dst_index_col=\"node2_string_id\", link_index_col=\"combined_score\")\n\n\nNow, we are gonna use pytorch geometric to build our graph object. For this, we need to convert our edge index to a tensor.\n\n\nCode\nedge_index = torch.LongTensor(edge_index)\nedge_index\n\n\ntensor([[  0,   0,   1,  ..., 157, 157, 157],\n        [  7,   1,   0,  ..., 153, 154, 155]])\n\n\nAlso, we can set a label to the entire graph.\n\n\nCode\ny = torch.tensor([0]).to(torch.long)\ny\n\n\ntensor([0])\n\n\nWith all these, we can build or graph object.\n\n\nCode\nfrom torch_geometric.data import Data\n\ndata = Data(x=global_embeds,edge_index=edge_index, y=y)\ndata\n\n\nData(x=[158, 15599], edge_index=[2, 8578], y=[1])\n\n\nHere are some characteristics of our graph:\n\n\nCode\nprint(f\"Number of nodes: {data.num_nodes}\")\nprint(f\"Number of edges: {data.num_edges}\")\nprint(f\"Number of nodes labels: {data.y.unique().shape[0]}\")\n\n\n\nNumber of nodes: 158\nNumber of edges: 8578\nNumber of nodes labels: 1\n\n\nTo plot the graph, we can convert the pytorch geometric graph to a networkx graph object:\n\n\nCode\nfrom torch_geometric.utils import to_networkx\n\nG = to_networkx(data=data)\n\nprint(G)\n\n\nDiGraph with 158 nodes and 8578 edges\n\n\n\nVisualization of the Graph\nWe can see that is a directed graph. Now, let’s write a function to visualize the graph.\n\n\nCode\n%matplotlib inline\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# Visualization function for NX graph or PyTorch tensor\ndef visualize(h, color, epoch=None, loss=None, accuracy=None, node_size=300):\n    plt.figure(figsize=(7,7))\n    plt.xticks([])\n    plt.yticks([])\n\n    if torch.is_tensor(h):\n        h = h.detach().cpu().numpy()\n        plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n        if epoch is not None and loss is not None and accuracy['train'] is not None and accuracy['val'] is not None:\n            plt.xlabel((f'Epoch: {epoch}, Loss: {loss.item():.4f} \\n'\n                       f'Training Accuracy: {accuracy[\"train\"]*100:.2f}% \\n'\n                       f' Validation Accuracy: {accuracy[\"val\"]*100:.2f}%'),\n                       fontsize=16)\n    else:\n        nx.draw_networkx(h, pos=nx.spring_layout(h, seed=4572321), with_labels=False,\n                         node_color=color, cmap=\"Set2\", node_size=40, alpha=0.6)\n    plt.show()\n\n\n\n\nCode\nvisualize(G, color=\"cyan\")\n\n\nc:\\Users\\LENOVO\\miniconda3\\envs\\piero\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:437: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  node_collection = ax.scatter("
  },
  {
    "objectID": "posts/proteinbert/load_string_protein.html#visualize-the-embeddings",
    "href": "posts/proteinbert/load_string_protein.html#visualize-the-embeddings",
    "title": "Protein Embedding with ProteinBERT and STRING",
    "section": "Visualize the Embeddings",
    "text": "Visualize the Embeddings\nNow, you might ask where we gonna use the ProteinBERT embeddings. We can use the embeddings to different tasks for example: use a high dimensional reduction technique like PCA or t-SNE, use the embedding for a regression task or classification task, or use the embedding for link prediction using Graph Neural Networks (upcoming!).\nNow, let’s use the mebedding for visualization. Here, we’re gonna use t-SNE with a perplexity of 30 and as initialization we are gonna use PCA.\n\n\nCode\nfrom sklearn.manifold import TSNE\n\ntsne_components = TSNE(n_components=2, perplexity=30, init=\"pca\").fit_transform(global_embeds)\n\n\n\n\nCode\nplt.scatter(tsne_components[:,0], tsne_components[:,1],c=\"cyan\", cmap=\"tab20b\")\n\n\nC:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_14548\\3896625821.py:1: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  plt.scatter(tsne_components[:,0], tsne_components[:,1],c=\"cyan\", cmap=\"tab20b\")\n\n\n\n\n\n\n\n\n\nAs you can see, ProteinBERT do a great job predicting the embedding only from an aminoacids sequence. We can identify the structure of the graph we plotted before on this plot. Of course we can upgrade the embeddings using Graph Neural Networks (GNN) where each node (protein) will send information acording to the graph we just build. These upgraded embeddings, can be used to predict the class of a node or protein-protein interactions."
  },
  {
    "objectID": "posts/proteinbert/load_string_protein.html#references",
    "href": "posts/proteinbert/load_string_protein.html#references",
    "title": "Protein Embedding with ProteinBERT and STRING",
    "section": "References",
    "text": "References\n\n\nBrandes, Nadav, Dan Ofer, Yam Peleg, Nadav Rappoport, and Michal Linial. 2022. “ProteinBERT: a universal deep-learning model of protein sequence and function.” Bioinformatics 38 (8): 2102–10. https://doi.org/10.1093/bioinformatics/btac020.\n\n\nRajan, Lozano, and Perez. 2023. “BERT2Mult: Predicting ‘a priori’ protein-protein interactions with graph neural networks and language models.” https://medium.com/stanford-cs224w/bert2mult-predicting-a-priori-protein-protein-interactions-with-graph-neural-networks-and-f257c8b575a0."
  },
  {
    "objectID": "bioinformatics.html",
    "href": "bioinformatics.html",
    "title": "Bioinformatics Projects",
    "section": "",
    "text": "The analysis of RNA-Seq data involves two distinct parts. The first one needs the use of servers or HPC (high performance computers) and has to do with quality control. pre-processing, alignment-mapping (usually with the STAR software) and counting (can be done using RSEM software). The second one is called downstream analysis and this part involves differential gene expression, gene sets analysis, etc. To see how to do the downstream analysis click here\n\n\n\n\n\n\nNetwork analysis of genes and ontologies\n\n\n\n\n\n\n\n\n\n\nMethylated DNA between Cancer and Normal\n\n\n\n\n\nEpigenetics is the study of how your behaviors and environment can cause changes that affect the way your genes work. Unlike genetic changes, epigenetic changes are reversible and do not change your DNA sequence, but they can change how your body reads a DNA sequence (CDC,2024). To learn how to analyze 450k Illumina Arrays and Whole Genome Bisulfite Sequencing data click here\n\n\n\n\n\nIn recent years the integration of Omics data has become important to understand the biological procesess more broadly. To learn how to use the GWAS Catalog with ChIP-Seq data or how to retrieve and analyze data from The Cancer Genome Atlas (TCGA) click here\n\n\n\n\n\n\nNumber of predited mutation effect per gene\n\n\n\n\n\n\n\n\n\n\nKEGG\n\n\n\n\n\nAn example of a proper use of interactive plots on a RNA-Seq data report can be founded here.\n\nThis repository doesn’t have any code, is only to showcase what is possible using Quarto and Bioconductor"
  }
]